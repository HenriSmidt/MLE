{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])\n",
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.keys())\n",
    "\n",
    "data = digits[\"data\"]\n",
    "print(data.shape)\n",
    "images = digits[\"images\"]\n",
    "target = digits[\"target\"]\n",
    "target_names = digits[\"target_names\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">Same as the solution </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of img:  (8, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xd381e08>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# find all the indices of images that contain the digit 3 and take first\n",
    "index = np.where(target == 3)[0][0]\n",
    "\n",
    "# get the selected image\n",
    "img = images[index]\n",
    "assert 2 == len(img.shape)\n",
    "print('Shape of img: ', img.shape)\n",
    "plt.figure()\n",
    "plt.gray()\n",
    "plt.imshow(img, interpolation=\"nearest\") # also try interpolation=\"bicubic\" plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">Same as the solution </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2dXahu31Xex9x7/4P1Iwj9lCQ0hkpABI0EoQTEaltiDbEXvUhAobaQ3hgitkgitNBCL3ojeiGlIWotptoSDYikWqENqWBjPprWfJiSBiV/Exu9EKOFnLP3nr3YZ5zz7Od9xphjrvXu9+u8AxZrrbnmWvNjzd98xpxrvettvXc729nOdjp2se8MnO1sZ9uunaE+29lOzM5Qn+1sJ2ZnqM92thOzM9RnO9uJ2dVDXLS1trMp9dbaMAz3fTtb83Zln5fR8dlrjLazslaMn4L4vlr7wvu83N7eToVHx1Q6ozyqcmVPeo7xKVDvXd7gB4F6qUWNcARltFxcXGysLy4u7PLy8t627/v21dWVXVxc2NXV1b3Fj/nywgsvbMTBsBdeeMEuLy/tJS95yb1jvI6uh+n5tueR8+3l8QXLreqNYbm9vTUzewrV7e2t3dzcPF3jcn19fW95/PjxveXRo0d2fX1tjx49skePHj0N8+0vf/nLMgzPwev6Nqbt25zP29vbpwt3Er6N5V7TIRxqR3Aw7vcM0KNzoriobtE5leMzCrjEqo3FQcyOKwXeR2OsehCVdjCb3tJrHKsdBNSzN3LUQCoNKAMUVb2SZ+Uy43XUeUsaWAQkK0pVVSK414CPZR51wms7Wb7uTNxTtr1DXa3kyI30bQVp5qLzcW6IvsbwbLzLhjAvATlz/RR0HKa2R6CuVfBtArPUQxud+zzYXqGuumEjtc3CVRwFfxXsKA1f4zh2VMYZi1xtBTPu+3nZWBKvHU2YrbEKhNgJVj2kyv7avB2j7Q3qKqiZ8vI5CuZMrRlktc/hKu8RzJEnkDXEDKrRzG8Ul8GO0lpqM2Bk3s3sseyezNrImzom+PfufqNljb3idi9dIrBVGmpGfXT9qHxZ2c1itzl7zMRK7IZgR8CPZoZVXkblicbXHrYNiLK2kV3rmECdsZ0/0qpWcAZ0Bs0szApsfkyEcSoQjzwEDq9a9Fy3tZY+x/U0RrPleM4aG8FktuliVyDk873s6jpcDhU2stE5S665C9sp1GuBVtu4P4JXQcnH8JrR895I5aMyzii222hyK5oIixQ2S3d0XhSG5RopsjpnpNSzTyCiONy5ZWU6BdsZ1LNAjxpCpoQVVVYqzS+jeJhSb/WSB3cQUWeQ1QfayL1mtb64uNhwrT0sSy9S+WxGXVnUGfs6GgPzveC84r3wBfOStRkv+4ziHqoCV600pm6tvb619unW2mdaa2+fTaQCtGrwEcB8joI2gpcbCAOL17y8vHwal9NSUGf5UPWQKSduI7zR2DkDftQpjCbQKm67KlcEG25nQCqPaHTdSP2rbbBSrkO3IdSttUsz+0kz+24z+0Yze3Nr7RurCcxWZtQgqipcUWaE1bcV3JE6j2bIR8+21eubVavAWwV5NDmmgJ+5l9H9w30VB88deTqjuqzkrVq2Y7GKUn+bmX2m9/7Z3vsjM/sFM/veysUfEmhWy0hB1eJg+7a/Ux3BjPF94feuLy8vN9Q56nBG9WNmpR82YBwze/ruswIb34eeVW5Pd3Svq0COHv9l8I2UOOpI+fys8+Fzjs0qUL/MzD4H+y8+CbtnrbW3tNY+3Fr78JN9ebFR+FplHgHNAFaUmcPMTEKrOo+sLFXL3Gn8AYPHRbAZ5iUqPmsZhJHXgp4Oh6vrmJmME+Ulq+81AB8i/JWJMpXrjbvde3+nmb3TzKwVf3o5UmbcrkA+A7T/EkvBrX4Jhdf1c6NfSXm+1bhblYnqcUOVcbu1Fj7GcrAvLp497lELT5xF43I8xtt8D9U9jRRSgZjVDY6n3bCMWTvBiTIus+9XvBCPg9uHahWoXzSzV8D+y83s80sS45scrR8KaOVKM6C+z8Aj4KM0uSNQ+UVTjdYtGj8rhfCG7ubzBXy9qGGqTiR6Gw0tAzWDPFNjrK+bm5uNOmZIszajyqzqQHUChw6wsor7/SEz+4bW2te31l5iZm8ys1+eTUjdAN4f9ewMxwiuCLhIYV3Fo98sY4eAv21WrrnKX7SoOjEbK2g0ZnYQ+ffF0Xg7UueqWkf32ffRe4nuLYZX7r9SclWHnG4138dsQ6XuvV+31n7QzH7NzC7N7Kd775+YSSQCutrTRuqs4J4ZSzOgrNwKZNUZqDictyUQ43NmhLW1tvGYCVUa00CXnNUL4zK4s/ByuuyRIICq8+Z7imWJYPbruapGS+SCo43c62NS7dLLJ73395nZ+5YkUOk9dwm0A4xws9ucuedK3ZVbrvKZuZuizp82JKXK7GpznXJ9Krg9HZU2u96j8bTqrCr3kePiNTivbJkbzteddaezuHzs0IB/0DfKVAWrtW+PAN8m0OrTQOqzRtEx5ZrzdqTUmWpz44jcZAV2BrXnA+FW98jTV2PpCOwIpOg+ju4rh6FF42rf5zRZgaPOLAs/JGAr9mBQR72rihfBj8dHcFeA9vMQbgaUx8oeB1VbwaviYwNVZYlMTYpFM9yR243peRyl3H4tN/X2mOpoRvdz7cL5R5C5jVTSZqWOOjM/dmwgo+383W+lTr4/06szvCqMgWb4MJzH1pn7rbYjVVbKE9VBZGqMjUDzmqGI6tfDKx9gWDPGVvcYj6t8jvKM+0qlVV7WuuDHAvtOoI4ar1KtEcwIr4qTAc3bqNLKHVfuN7vgnC53FK6CKr+R8Ww0qzPWKa690bJnkNXraPJIzbhH95c9gigPuK1cb9/OJsvc2A2Pyqsmy9a44IcM+F5+ehn1pKMGyGAg3NmMNCqtAlq9VVZV5myiDPOhOi9lPEHmcVGBM1VWMGR1moE98ygrMsyXm9fLKF+qM8BrqHH1zc1NWO4ZF3xJOQ8F8geHuqLS2Y3M1JihiWDLwIzG05EyZ5NrKm9RWTwcG3v04oPv40sYI0VE1e69S09BKR/b6PFWVsZRmnhclcHvLXoqDDN3lKoe8HjVBT8kSGdtb2PqLN7Mws+S0fVW25HCqpdJ1BhbLVFnwypdAUk1OlZsrKcMcDXWxk5EpavC1fbIItiiTkC54Xh+VE43V+koTQY6gxaPHSPcO32kFYWrG87hkWJHDSKajc5c7dkw1Ynw8RlVdONGhEA62A4nz2pjvXFdu+rNdDKen1m15nxk91PludIG3NS4WpVHge3lG8Fe6QwOxXb6SCu6wSpM9eI8+YRhmTordzma6WZ3WsXL1BvVMGvAbJWGgkBGb4phuphWa8/cd8wj52HU6WTqxvvVRXXKuM1lQovG1SoPI2XmOMcAsLK9zn7jcdUIcZsbb1WduTNgtVaTZQy2ugZ7CdF6Bmy2qEHheJLHm5GLispecccxfyOlzs71fe68eTtTZ3VNHFurtCJR2abiHir0e/maaNT7RjdV3WR2b9lVVtsMtXp+rcLw8VU0dsf8eP5UvrGcyiog+/kKblVPeAzH2WbafZ/NmypXdM1KB87bqL7YeXG6o3F19e0yjHOMtrPZb3Vzo3jZjXewzDa/M4ZubzaOrobhMb8mh6mxcwR0Bs7MxIya+TUzqdpYhwg0gs0226CjToSPq04P8xdt4/lqTkDlY9RBjcpzzG74QfyVbQZ+BLg3SIR55DKrsXAWpq4Rjf8qCqTM4ao2HJ7UUUv2KmkVbM5zNAselSvzTqIOkLf9mXOUDoaxSqtzULFZub1cxwawsr1+93ukyGqJYI7UU0FZXRTcajtTaVVuZdkMrDrGDZHzEKk0bmdgq8ZdnQWPwjNPheNX2oYbewcIOMY/5WfTaDt/pBW5TXgsi49gM+QKem7slTAEIVJkzpNqeFXDd7oji8BW6TCw/N44v8+NYCsFm7WKgmaLut4oL5lnoOIuUeXReYfSKRyE+80WQZO5alk85TZnYa7SkadQbYyeJzYFTfSrKWVVpWZ1dqC5E2ntzmW/vLwsN/bRoy0F2Uxnh2Vh1UWLxvBVOxQQt2l7f6TFLhYfy45jHAYbt9eEZe40NzKc/HHjZ79q1pXPUV81GV2Lz0do+eebfi6/hloZKy8xvlakqNvwDDhcpX1qELPt/ffUfI7q0SOYlEL7Ps+uohpzWAYyhi8tVzaTWoFJQT56UQQVGYFmqP0YqjXmmTuRbVlUp9vsTFSas2U4xk6g8g8dP91a+2Jr7ePbTrwCinK3PBxB9rDKxFU0hq6kPwrn8SofY6iqC5r6lvfoY/0zHxvkSToVb5f2kKCfolW+Jvpvzez1axOavTEVdze7fuR6RWEK/szUzDB/AiiCJ1si+PjfOMzu4L65uSl3CqqDyGa0Z8PPdhhW+ZroB1prr3zojMxAz+qM20vhXmIIDY+TI6WudhiVeB5HPetG1xo7Bg7DfLsLjt5QJa8PbedOZM62NqZurb3FzN4yET8MV8eiZ6nRsSyNzJT7ieEjNYye/yqA8PqjCbbI1JgXwZ3pRFT86jWW2LZgza6jhhLbuvah2tag7gv+duehbeZmKwgxPFM7Pp9/NIEdFQJktvk2E+exCjar9WiCixW9YpUGXo2jhgQKuuj7adnxmfH/MUI7soN8Tv3QppTYtxlcBwZB5pcpzO6P+/n5MIONa1ZXPO55UtBFs+bsBbAKq7CZ+nJDmBgiNZbH8Iop2JeM/7O4S1X70OcajgZq9Toju7zKVONg9Y0aj8OsvgUWvWfM8RhuPMZAZ6qN6UQuO5f7Idzm2QYdfT98NIyZyUP2jfI11z1WqzzS+nkz+00ze3Vr7cXW2j/cRsJZ4xhVrlIJPhfBVI0Gj/OC5/H5GEf9V1V2vZubm41zOK0oXdU4Z11Vs/XP3DHdzF1eo9SjzlZdC8uuII/ylIVzeY/FKrPfb95FRlhZMuhVY0TV9tcdKwqtlggOvLa/yOKPlPy6+GJItKhXQtklVzP2XCeZC80Tjup6KnyJKXijOL6tOt1oOwurwKngjo7xdY7RduZ+L3EH8QZxo2ZQVTzVq+N5CJlq5Oxm848THGKz+8Cr595qXK0Ax3riOovqL6vbyuO7bQAeqeIIYIybbbu5N8Pp+LEM8gzubZT5UGyvY2qEMGuwaGqWWSkxjofNngGD34XG3+tGhh0GQox55/xX1LoCeBVGzmsUN3uTbgnQyiXGNceLtiueUwZ3pNhK0TNvQpXvGO3BoF6qzJFbhddkkBhodR2H3NWUf8WEqjyagML0edvX+IjJl2gmPHLRs2fzUVjWeSib6RjcRo+RMqBUvJELrs7lvLBaKyDV+VFeK+cequ199jtT6+hGKlVWSqx+fogNEtXRoXOwsWHhGB1BVukjwL7Pz4+jhd+UU293Leks8ZqRp8DxlI1c2AgW3s8gj7azzqI6w45xKgDz9rHYTqCebYiq4Tg8eB0G7ebmxq6uru7BjdAqVeZ0MndbdSQILKqz2jbLP7zgeUPIsVPx45GNOozI7VZqPrpfCjxWyZkfmGSTZO5q+6QkH1dpYb4U0FwWVb5jtQeFOlJfN1YfpYbcoyLcuI1A+zWyyTBWZc7fSKUZZF6b2Qb0ao2Qex6jiT+l1r5mlR+NndUx/smpx6s08AykCtgYF7d5PO0dMz7+y8BW+cvyWbVKx7Av26n7zZDjftQBqJvMk2Gs1qoR8zaqMOfHj/nxm5ubp98rQ2j566IejzsdPI9dc08L08Qymj2bWY/qiUHF7eoxZVW15k5xBLAaK0cq7XEiYKOOYbRkZeLtSOEP1Q5mTI37qIYqbKTW7GZH7jbnAwHjR1Rmdg9a7BAwDBU4UmdPh1WSZ+pVHWQARiBnj9dQ6SPQlVpHIPPxEXAzz6kjOCtgZ3k+ZNVdYg8OddYQOQ6us5uo4I6A9jB+xmx21xjQZXeQ0QWOQFaudTTGjsrHnkI0ez8CmfcjuDOoI49mZAoIdb9GUGZwqwV/R+7XGLUZzIsqR6bSx2R7e/kk2o8UGm+y2bOJLzyHgb68vLTr62u7urorJo+jLy4u7Pr6Wr4N5oCqME8L3XDlmmMYp4Hliww7AO5UorEwq3O0ZpX2azLknD9+NhwtDtlosiwDmsFlq4zJOa9R3rEdKsviHBr4e3G/EWCzfMIMz1EKhqD7tRxoBNvHpNxhsLuNrnM0w20Wu9xqLM6egHo1FPMfNTiMw9ujsXQGdHWMjfeCbTT7HEE/Ao07AKXyI0grneihgbnGdv5Ii2H1MLP77zJnN1iBjG44Ao1rj+vXUiBHbrSZhXF9jZ0Aq7z/HxeWA/PFhp0ed4IYx9dqwXxEx5UrHuVD3dcKxAikgpMVG7fxMZa73fxoa2b8XVHpaM3bh2o7faNMhanjCmw/zo1hBDKv+XmxW6TS+JgpAxlVWcGNZcSGgedEww5l2Via3enqcb5u1oCzhl5R5wqM+PiKDcHP0pxVaQVyZocI+d5mv1VlROoUqTd2ADNA8/UV3HxMjad5Eg1VGRsmvjyi1JYV19OrgJ2pcHTMr6/Sj+6HyntFpUcLjpujsbW6vtuoY8B8V1Sa7RChHdnOXj6JtrP4eDMQHO7JzZ5BYGYp0JHLzWtUaXbDs5lvhhtfJMG12eZ4uDqJlilw5JIj4DxphvH5fkT3lYGYVeBIZVV4ZWa7sozKMlLpYwF850rNQKt9s1y1+Xkuw21mKdAehmk76H4NfjOM3XB+qQTD0OWOYEaI/NrccfF5fi7vj1QaIVbpR+PpkfH9UKBVXjrxD0cg8KPHWhXAuf6roGP51hzfl+3tObWC1w3DEGY8j+HmcVcGtB9nV9S3Pc9+PgMejad5Jj2DE8uKHgGmlYGdjakjuLHcI6jZa4osg0ltq0mxKL7H4+N4naqCc35V/rOyHirAyvb6mmgWj7ezNaqmmd0DjZ9deyNHuL2BsHorwHGfX0pBuD1vkUJjGqii2KB9thzPR1Pu85LZbl6jZxTdnwiWihuMgGeKPjpfpcfhKr9Z3jmMt7OwQ7Eh1K21V5jZvzOzv2Jmt2b2zt77T8wkwjBXVICP85rdXwZbgahmsB3uDGjc93SwPPw6KeeVVdXX7L6PGp+qn0ilI3grKj0CmvcrSqkWNRkWvdwSKXMlD5Gdgiorqyj1tZn94977R1trX2NmH2mt/Xrv/ZNrE8+UO3KTUBlHYKNSRy72kn13YV2ZzTZfNFFl8HPczcZ8ovJnjaoKLk+GRX/NG7nemSllxPNmQfZF/YUQ1pNZ7HarfM1Af0qAVz48+AUz+8KT7S+11j5lZi8zsymoHQpe4/HIWDnUtnqujO42KjiCjvseNgLczWHsvT9NL8o/rvnRGKo1lmvUoCrudRaugI7q3OuYLYO2ouAR5Awz14dS9ChfI4vaViX+IdrUmLq19koze42ZfVAcu/e3O5kKo3kFZXFV42K19m10axngEayopNk5mKbZM4+A/wbWzWGPZrmrLuPInVYwY7zsuTXWNXe+mCeGD7cVmKNtPp9BjK6d5SEDPAN4tH8sVoa6tfbVZvaLZvZDvfc/4eNd/O2OUuNIrWcrkHttbMQ4m+xLpM6RWo/O8XTUiy1P6uDpGvOAk3iZmmWmgOW0ZlQa70E2no7qno8tgRA9rpHCq23OW1afs8ocnXuoVoK6tfaC3QH97t77L207E0rVs8qLGh7Drc6bgdnDMH84Wx4BzWmiwqPLrR7r+DpTa96O4PVjGfh87ZlGm6lk1GGpJVJuN3wMhulGdVYpw0zHdWxWmf1uZvZTZvap3vuPzSaggMXwSK0jt9As/5sdPz5SJ1bdqlrjo7AMaHTl+cWVCAKuA3VNX1eWGZXGtGfVOgOa9ysg45o9AZ4oi+ps5BFk5amU+ZCtotSvM7PvN7Pfbq197EnYj/be31dNhMHNIPdtNmxoVUXxa6rFjymQzSx1vR3YkUfAP/CIlMrzqiai1LV9vWbBa/G1scNVdZp5FBxWKV8EdqU+Ku726Nxq+LFYZfb7N8xs/h3CgkVqrdSjeq3MveR4uG12H2SGnmesMT4aKrRf191tVKjoTSllEXxqO3O1I9fd8zFjSqnxcVykjlGnwI+tsvSqeTtVaEe2ly+fzKh1pdFF18NjSqWj7ZEb7oYfGfQ1f9XU8zByL5W6ofELLwpSdr2x/jiOOjaqY96OXGB2ryPYs+uNwB653zN2apAfzIcHI+hn4I6uzfsVsH3J3HD1azD+5tnsOHqJaivgeZ2pfaUefT3Kc+R5KJBHL9pk1ztbbHt793uk1ggz3tTZ8XSWdhXsyO12sB1kPxfdbwX00oZadbV5P4vj9aHqb2QVBebrKJD3DW21TR2L7V2pzTYhiwB0mwV91JkoyDF8BDa/b45qjYrNDVopIJtys6Nn4rg9UuaK663c4cx9jvb5Wirums5u1kbtJTp+LPDv9ffUGWC4HbnjsxU8unYUF029weZrvCbCwL+2qridbCovFXDXuN1sM1COvJJtwqHKqMRAnXcMkM7a3v/1MoJLqbdZ/RnqjDKrsCzv+EstPA/hxnjZWHRpo4pcarPNf66M1LtqKs+zSj1zPDI1/Kicg20nSr/q/R1DR7Dz/9KqhGdrM90Tz4JfyQ8eR1BQnfl9brNnL0jgjzSUkuH1OWypLQE3g3IEbzSEGO1HVvE2VHzs3FTb4PxX1fwY7aD+oQO3R2C7VW/KbD5wn9PI8qaGChUlU4+2dmmc16gD4mN8fA3MFXjNNl/dnXW/q+HHqtZ7/ZpoFbJtAL7kRuA5qhG7SmN4pNDq1cZobM2zytuyzNMZpTUaPlTe/pqx6G09nJg0Gyt15BH6OZnHp/ZH4Ydg8QvUW7So8BU3TylItI5cXD4WLdF1MFzlL5vVXmORa1s5ZxQ2CsdF/eAkymfFsrFxa89m9xls/mWaAlqFq/RZ5TkPUX4r4fu2nUBtVrvhI9VYCvhDLZw3/lG/2bPxtcqf2q6aKqvb6BVU1VlF5VLpeRozHYhZDo467oD7guG4nUGu4nF6pwb23p9Ts4uE+8qN4jC1HlnVxcryiyqGioJgqF+TjdzUqKPCa0fj78zbycpbhTzKU1aOkY3gi8DFcXUEKrctlcesDR2rK74zpTarN4BqQ4qUOYrDcbNzo8ZdUWmz+OMBlTzxNRTIWXmiNKvlyjyKqjqPXGx0s81s4+lCtHhcDs++ohqlHyn1sSv2TqE2WzbOnGl40Xq08LVUfkcgsZJWy8ThI9g4bvS1kLWLqoOobqJ40XgZwxhOhBeNwfUwdX5ljL1tsA/Fdg51ZKMGsgv1zs6rqqsqV6UT4A4hU94IPFzWgB7lLSvLjFXcbPwaqn9LXUGfgVz9SMS2wD4U2PcC9dKeP1PNSthoHYEdneOm3OSonB5Wdc+jhX+fXYm7FPCoLFUbAZWpbQQz/8/3SLFHgJ8S2Af3nJrDs3217Y3Pt3nNpo5H+eJ0fFHXHoGJx0bn8Cd8sjBspPzRh6zuR50Bx8H8RhbBosDlWW6G2Bd/j94nIf0nr+za4yek8Ac30X1V7ShqG1hude+jtrYr2+vs9wzYZpsVz8ciyDPY0bKbkXU0burFE/VFjwgcBFV9cRQ/+I+fSvLFGzECzi9q+KLqIOt4KkAriLn+WD2VKnvZ+M8YHFAFN98bfGUXz5t5SeZYwR663621r2it/VZr7X+21j7RWvvnu8iYqpDMHVTqNwobXZOvP6NaCDQ/qx59dE/F5WthB6C2o+N8TRWmvAAsHw8xVIP2NQKG6pvBzcf8XIcZOw93w9FNz9z3KC3Mk9rGNW+r/ShsF1ZR6i+b2Xf23v+03X0q+Ddaa/+p9/7ft5GBSPWiY5FKq2MV9c56YLTRkAC3HQ71qqPqFG5vb+/9Dlu51ZGqoyKj+415Vi5o5CFxp8J5VR1RVF/Rol4m8XD800F2ub0cqOb8z6bqvYCsHrj8lbZUaS9YD7tW7MqHB7uZ/emT3ReeLFvN5RqweT+6GWbxOFudq/LB18SGjT+7xMal3FeGFa8RKa4v3oi9geJniPlvf7Bc/CMI1eHwUEF1MBVjRWOFRDcbAcZ4OMzwPDjIZmbX19cbv1O/urqy6+vrsDNlV5w7MXXODNgRwLsGu/ox/0sz+4iZ/TUz+8ne+/Bvd2btocHG7YdQ6kz5osXMnsKoxsjZgv+dnam0A+1hvmQNOcqrH8/qRgGNecomyHAsrdY4l4BjaoQ7+h57NrbGeYjIC6u2m0MAuwR17/3GzL6ltfa1Zvbe1to39d4/TnE2/nZn1ipKGVU4n69uBsZZo9S+Vi6pUgEG0d1GVJ4IWmykvvg+/u8X59uVDPOIUKlzuHxqXM3eBRq70tjRRADzvqeBLjamp5RYdVAKbKxrNWmG9y2yYwB7ava79/7HrbX3m9nrzezjg+iLLAMrOp6BmcG7RKn5OiOgVcNCt1KpNM5ysyIz0L5E/7iJ+UQXHBU0ip8pdmbROFrtM+wIuAPM7rjZHdy4z4rdWtvoAPB+4L1SncISxeY62BfYlb/d+Ytm9vgJ0H/OzP6mmf2rh8yUUmU+PgIbz6+AHV1X5QmVz4/h9RTgmeIxyByGSq0AiQD1POP4Hs+N6jjyRpS3gsbXVaqt3GysL35kx+leX18/Pdfs/tiaIVauOIOt6kB19tExLv8ulHhkFaX+OjP72XY3rr4ws//Ye/+Vh83WnY0gy8DmfQWxOje7Kdw7Rw1eAY3KipNcmQrztgKYy4sz1+zi4pgyAzuC2jscjBPVE6owAosdi5ocM4t/OorbmGdU2uvr6436cdi50+ey+nXYNa+2K09v5Pk9NPyV2e//ZXf/Sb0Xq6pnFH/kdqv1KC8Z2NGYGtUyejSFiuwdQeS2MuCY78ePH9vV1dXT9HDB/M+CzcfQlGuvlBrVmtPxtXKpOQ88+82uOR67urraePaO56k6iOpDeYOHBvbef09dMQUvH98W2JhelpcIbHbBfR/hRnjRPcR9BMDLjmoT5Q2hYJVm5fQ0R3XLyllRaQW2cr15koy9Hrfb21u7urrayCd2TPxILjJ1jCfP1EQa5ilrT6pOdgn2UUDtNuOOj/YxTEGPccz0TVRxFdD4LDkKV7PaCFw2063Sx/zxnwtgmnKxyH4AACAASURBVCPvRF0b68Xzk8Hs52F6OH72MISb0+j9bjzN4R7G25XyYB2bbYI96kA9TiYUWEe7AvuooDZbB7YKj1TcLXK3PEwt6kUUPGZmT193xBdIsJEh3N5Y2WXG/EX5uby8vDeLjBNuFTc8ujbWCVum1L33py+JsFfhbjMrJEPsQwsMU9uZ+TV5WBC549l1qsDuCuyjg9psOdgjRWbV9nA3NVbKFm8g2PP7gsBeXFw8XTPIaNE4T6WL2/h+dDZptgRslUel0qjUDDPXs9ndvIAKb609nTPAfC5VbDScoVfPslVn7+GRMOwD7KOE2iwfZ8+CrYBW12d30NeRQiO8GO7XZcD52bNaVB1wfnhM7Wt8Ho7KmaXD9cENT0GnVDp6xMdwo+GEnzrGeZwFW71H4OGqg5vp7DOwI9sW2EcLtVvFxeb9Edhmm40ZTbng2LP7cfyRBgPr42t/BKOgjcqL6eK25wMXzxM+/8WXLrJn31gPWfoej8ejqNb8nnZULt5msDE/CLYfw7AR2Pwc2zs/N4Sb0+a8V9pTBfJtgH30UJutBzu6pln+cga64B6OKo2uN/4Cy89Fhca0MnXGdD1NdrdZCdn9RRecGyHOsGcdTdbwlFLjOWq4gNAz4Goc7cZv0nl8Nwab0/JrYKekvAwvV2SRUu/C3WY7CajN1oFdccOjNHmNDdUN4WbY2Q3Hc7J0GWIP5+e6DDNC7cCrso8UW9VN1ClFbjgawscTZa7A6pFWlKcMbHzzLHLBvZ6yiTPV8SuQI8AfCviTgdpsrL6VcytueDTOZAVi+FrbnADLXMSKq50ptrv/+EzYy8dvm6kOzWfovcwVsNWLJmju8qqxNNYFPsJzY3c7Mk9bueK9P5t99/xweVi1GW6Mh2VQ+6rje2iwTwrqyKpueKbUfD5f39es0nwuPrJB1cbHVqOymG3+35aCHd/MwvepeQzJ7ri74PgiDCp4lCcus1JuT5vfyWbYIst+uMJ5Uo/OPE31OaTRxNlofK3gHo2v1f5aOzmo17jh2TlRpavxLc/yqnH0GtU2s40xKAPt2zhJxu549OMJBBuVKwMbTbmtChZlFbDxDbeZYxiO76O74UcMs+GDlykyhncp2EthPzmozbY/vjaLZ8Nxf6TYZvb0ZRDedkM3kZ+R9n43i47AIsj+KiWHOcAMNQPOYHtDxjrjt9Ayl9OPsSubmZ8zek7Pk4tYTzyxpu6RSkNNoqFns+bFlArYypaAfZJQm20XbD9mFk+WmOn3hxkU/Iml2X133A0b2+PHj++dr37gwEBjp4JhPGHm29F72PxeuA8VvGwVY7WuwF11xVmVGVjlieBkXfS5YX6dlWfEsVycLpd7BDafMxMe2clCbVafOFPxlvSqfp6vlVL7W2Ns6scICmL1+Ep9tBDDlCr7NVmpMS3VGeA8gJfHDeuI38ZC1cZ6iixTbDT1ggpf+/HjxxsTc/6RBQU3b2MHh8cyVzwSCyxfFr7GThrqyDLYKwqfVbofU68Zuimw/VVR3vZrZUpdCVPnstuNx13l3RhKD2OvRBnXJ6plxRTY2AHhTy3Zg8FymT2rS/6CSja+Hql11pb8eCYO23bDTx7qbbrhFdXG8Ey1EWwEiL/k4Q3Qt/nlkmqYp8PxWIU8v96x8Iy5l59dcwVppmYz42yvCzcc+/J94GMMuXK5uSNG19vPUxNm1fH1qG35NUbtqwr2yUNtttuJs+jZpkrfwxxaHF+j2xu5zsodxwk0DuMPJ7BqsXpHhmXCZTTeVmCrOoyM5xrwXF6bPQMc65QVPusg/BpcHr7HkUeGxsA+JNjPBdRmDwO2WVzJ3LjwfWs81w2fn0aA+3bmjkeqzXnjc6P8syuLeeHGjqrtx6OxNZa7OnmG+fWJNPVrL1U+rFO/j6zSngdUajV5NnLBlXuNx6oTZ5GN4j83UGf2EGBzQ2U3lF1aPB+hYcAdFL8mKrNPjvn1RuBjB5Cdw/lDYxixHiP1ihR7ZpzNeWI1rpQLhxc45EFzJY++Ja6gVpOuGJ6BvGRylq0Mdbv78OCHzez3e+9vmE7pACxSa3VsW4rNM6pRz45x8FEMwszjbX6mis+9sVHz22cYn+tA1UtmWJ4I7uw83M9UW0GqlBvfa0dVVo/rcL6g8pjL08KxNcYdvZiSudlrx9FoM0r9NjP7lJm9dCqFA7N9gV1tBL5dcceVy61cavWzx1FD4XJxedwjwPziDLE6LzI8hztAhMnzFM0B8As0yttQwKvJMuU9sCcRlXftxNlShXar/u3Oy83se8zsX5rZDy9O7UDsIcHOTDUCBlSNnT0eA56dgwsr9YyKq8k0zEc0K44W1TXXa3YdzJsqN455GW5W6Yobjp0q1olyw72e1kycqbpZ6oZXlfrHzexHzOxroght5X9p7doeCuzqDYhmyT0NVwv8oL+fZ7Y5SaW++eWWKfXo4wV+bTbMk1vmPmfqpVxxX/OCHSAC6FBW3HC8jscbueG+Hb0fPnrawW0C25Pvb0OlzWr/0PEGM/ti7/0jrbXviOL1LfyX1q5tV4qN47CoIagJNNyOJs8ytcZ9zg8qdZRnvw7+2kmpGasiQ8lWHW9zXXH+I/eblTma9GN3XLnhM0odddKqzAiz72fDuRnYK0r9OjN7Y2vt75jZV5jZS1trP9d7/75SCgduDwH27FhbNQYG1SHDRqbUOprF9XfI/XqeLz/G5cZrjiZ+2BBKNcGUNU6uX1z8ONYXrhnSSJVRxb1uo0dk2Zia88ieCs6BjOqwAnAV7Mo/dLzDzN7x5KLfYWb/5FSAdtsF2CPLenrfdnfc47PrzKqrPgygFOPq6ir9nbJ3CJGrHrmWVcWOGjaeyyDjODp6ScfL5mkw0Aw+vkvgYazUWGb2IGYnzrgtYR3MCgTa+Tn1E+PGxMcqYM+mtw133Oz+ODv7jXb2sgleB+Ngh6DKwD8Ewc4mGxtHdcI2Umv0YhxMBWt1sgzzr/5ZU42vRxNnmes9C2wl3uxf2b7fzN4/c86xWaTaFbBxm2Gv3DDljleef6pn2Gi435r+prjZ3QcK1Kd3zWqPxaIOSI2LZyxTawYcFRfH/hjfgVdjcPW1FJ94i8bXeN9UB7TGFVf7Izsr9YStBXvG1Exq1OMrQ9ebYcpmvB1sHn9zut7o8ZGXh3NcNXnGZamMtZeoNUM7enUU41ZmwjMb3cNo2DIjBMrOUAtbO8bG7TXKbZa7cZkra/bsL2pau/8dND83UuxIldVMObr8WB4HTTVqVlmVlrJomKLUmt8eQ2gjRXfQeVhRnQlXQyosd9RWVLnXqPUZ6i3bDNjZ+WoChl9qqLzkELninsfZv6hhFUcXFSelMI/Y+COvI7OozhTQ7JozvAg6TpZlnUGk1LjN+cB7qOZJWJWj8i4RgjPUW7CKes8Czg3FwxTImbKZ5WNstZ+53NHndf0cnjhj91+54RXAsc4iF5y3cUyNaovA8uw4wq88FlV2Hl8rmDnfnmbmqZzd7yOwCtjqRuK+AluB7u41ut8ebrb5/Dl7Hs2mYGbXm8PY2BvB8OwchDdywVF9HbZMpdXMOI7VZ8fXkRs+O75eqtZnqIXNuIZLjcH2MEyfx3R4rodnhj8CcUM3mZ9Nq4/lq8dcnIaZyfyxYjss7I6PFFt1ekrx0Y32vPM767jGV0oZWsy7eqwVKTW73gw4l4HveVbXWAeZnaEmG1XYEuBHEyQYzg0Yj7sh5NEEVmstfKHEwVbHK2FRg1MTZsrQs4gec1UU27dHas1qy+Nt9aydXXE/xnArtx+9CDUp6NujsTWW9TxRtsCq47pK+GifTYE+uoGZGrrbiY9mHHJvUNEE2Uynhe+Yu6nfeavyVMDODOHx/Ui1GTCEM3r85XlmtR+54aPJM6XcEdznMfUKW6rOKnyN0iuX3MP5GgpqHmfz/1GhO65cc0xPHYsg9nOiyaXb29twZhyhzMbYqnGPXHAF80iJ0QPiYzj5Frnhfiz6NReDnbnh2X3P7LmHeuTmrQmfVWxlIxXPFJsnyNSfzqm8+bZyxZXCj/4HzH9/zR9WMLuvlPh6Z9XlVBNm6vkzq6wCHCFVLrx620y54WqMrcD2uhiVdVaxn1uotwXz0jAFEdsI6EixI6VluNBwptxdaOwUOC7nhR/1cL7RM+BjCmwsI5tSs8z9Zi+CAfSwSKXNNpU52ldjbLWvlLriglcAfy6hngV6FtKl56E7qeJGbjnDrQB3pb66upLqrcbZ7m5Giu3nu6Fi8n9tjzoxVkY13uSy+v7oDTPlgrOKI8R+veg32Uqpq3Bn7njmgs+o9XMF9VqYdwX3rPGNZ6ix4bDyZuPs7G0zBjcqA6eJgGN+MX8K4qy+IrVmmJeMs6OZdPYEPD8zQGOeq8ONqJ7Rnhuo17jUa/eXpBOpdWZVVxzhGY2zZ2bJR/mPFBvhVg17VAes1vyMODo2O87GYzwhl6k1lj3qsGbBzuy5gLoK9Mz+NkCvpjELODYO3EaQ3a2O3HGzZ+Ns5dryj0M8zLf9OtHPEjE/vvbGrH4BxYAo9TbT30lT7rMfj8bZrMgIeAaz5wHzl82EY7m5XGq7AvzJQ70Gpur26NiasG2B7efOuOMInMondhIepsbSyt3EBo2AYz6z8iqwR2PraNLMF57dxjW72qjWCLPHxzjRs3SuJ+WhLFHtk4a6AvQIorXb1XxU8rcG7EgdlVpmY+CsfvxxlDfo29vbjefQCBGqF+aXyxCVmRs9psuvrfILIpgP5VbjbDxDHKk1utLRWJvvoyrD2f0ObCkwuL0mLMtHBmUWX/XuI2OwOczMNv7fGtNQ43HsBFTHYPYMcNVZ8BtWalEuONdB5IJjPhmw0Zg6e8OMn6VzJ8AAq/RVB4l5zuYVqi549WP+v2tmXzKzGzO77r2/tnLeoVkV4sqxbcA9e2ypaiuX29cIn1+PQWwtHyNzHPXcGX/EgddgmGfqKCq7GsMizL5mNzxzuX07U2tWbLPN/+3GPPH+thR7Rqn/Ru/9jxalsmMbNYAZaGfX2XYWtrQMVbiVK47KjSAroFHJUX1Q7XifOw+lyJ4+bnOeZ8tqpv/YXo2LlQsejZuxw+IOg8M8D5lCR/dYDTlmAD8593tbQC89Nkqzkt9K3KgcM9dTbq4aY/va1Q8bOSuz+lhApsYMXlReVVa/toqnvAI1YRY9u45cboSdgcd8sEJ7GE4q+jpS68hG97gKdTez/9zu/nnj3/S7f+PghPb+tzuz6ubbVXBnwH4IqKNzorzyElmk4pmCK5Vjtc3Gy6rRqwZdqXOMy2N3VVZf8+SYyp9yuTGcOw01aeZ5iTwPVeaoLpSKs1Whfl3v/fOttb9kZr/eWvud3vsHqLIO7m93RmBV4a2AncG8BNysLFH4ttJTj7H4WXIEc+ZiR5NfqixROHdQWGZPix8j4Xk8AYY/vIhc7Mi9RmB5HkGp9qjtYDmqqq2sBHXv/fNP1l9srb3XzL7NzD6Qn7Vbi9Qr2h4BOruvtit5i2x0QyvlVUqdpc1upHozKsurGiP7dUaf02VDd3dUFlVXPARAeJUbrtxyVFZ0udUrpcobQpVXpjqrpSCjVf4g76vM7KL3/qUn23/bzP7F6pT3YDNAz4ara+Ga8zCymZsbpRGp2kxeVD7U+HgbjdHzpPI520GZbb5dpsb5eM0ovppDiF508XSVOvsxFb5Nqyj1Xzaz9z5J/MrM/n3v/Ve3npMVVlUtdSwDtwL3DNSzN3AJKFH63OhUvjhcWTaxtTTPnD/cH9W3r9Fl5bEx5w/hjMbSON5moPFVWgWt+lHKqOy8zy74jIpX/iDvs2b2zaWrHZjNKNg2Fr72LNjRTZsFJevU2K1VgHqYgjwDmtPOzkFIovxW6hvPU7PN0bvn7F5jGL+y6tdSz9/VOsqnSnNkMzC7PZePtGYaDje+KtQK6CV5d1uj2m4K6BFc0XVVx8jH+RxPwyGP7gMerwCd5ZmvieN+D+d3s71u/BiPm2c7HL8ev50X1QHfawyrQH70UI9usFJQ3J+FuAq3WezmZjZ6zKMaRmYKIMwb5w/zPKpDPE8dzzq46NpVYCKPgd+GU8+rsaw4E+7gzkDM5c6AzjokVacPOvt9LFbpwaMbkoGrFC1rbAruUT4jeDluNpsazVKrvChVwnBUVV/zNbNOYATA0jieX65jfpwVXQ/rb0Z9uXxch9G9yhQ66wjW2ElB7ZYpQxQvWrhxj6B3U2GVPOP5Zvojg2ZasbO0FMwersbQaq3qgkFT52K6I4CjNDy+fzstK+9ojBulzfXD9cRvg3G9cyep3Ppd2FFDXamoUcPim6ngjdZm9xtZNGat5tVNgaxeaOC41XoYqbWXKQNMwR7VFXYamO7o+ny+50tB0tp9dzUD2q8bTZT5NnYMWFYOr9quwD5qqNGi3lMdw/DspqvGqRpbpOJuPK7NjNUYocPjI9Vmq46tEWheIoCxLiNA+bpRnUadBwNdqcsR2Fknj2XK4iDk/oILKvoonw8B+slA7TYDcBQ+ApqVLNtGU+NSpbT87nKk3Oq62fvTnBfMo+qwVPnVNsfPVLgSHnlGs1Bj+TNwebsKI8eZOV9dD7fXvMxzclCjRZU702tjgzXbVDIOi0DJ8sgWqbL6Ib5bpRFgo8O0lCKqesJyXl5ehuo9GraoOub0lBewBGpWa7we1kulnayxh1DkyI4W6hlQRr10BrNq8LNgYxojy1S5AnvFojE1A+VlHbnMmWeTgZ1dlzsSBXqlLkf3GOt7pLRRG5rtuDndKN5SO1qo0WZutMebUWpsXNGY06wGNufZLH42XYEZj6trqXpyY7hHwLFS8zHljns6UVxOu+p+V6y12ueG+V7NToAdmp0E1MrUzWcXDMMyoJeA7duYFsKXQT0Dc+aCR78r5jqIPBKl1Oh2M8iqTlScCOLKvZjxePDcWW9mm1Z9gWhbP4o5WajdIpeJj6kGyWEKbAU49/yzCsP/tujrKuxuDDOHZ/lUinl5efkUUtzOAK665mrJIGfLXq1k4/u/xtQv1qJ42f427eSgzm5S1kCy8Fmwze6rnVntldHqLHfFDefrqfQYblbECDaElyfMVLzINc9c6xHQ7Olw+fBd6RnLXO+lAFdsmz9jPXqo1U1WN5LDKsrNkzSReimwI5dR5ddN3VgFcqTIo4bBZcZ95RqPQEVYr66uUrWOwrK6Ham0q3GkylE41qV67q/iqOMqzO9NdN0oL9u0o4S60vtmDWFGDUYNnMFmpWZ33C1yjZVScAOL3PPofDZUaK4HP1Zxvxlu5Y6PXPII4MgNx3z7Nir1kt8fR3UZgcwv/qiONjp/F3aUUC81BXfk9uHXJCOwFdCVsTXnBQ1hz4CNGiD/r3JWDyo/lTEvAz0aW2dj5pFKq/uG60ipM4VWYezlqAUNv83G17q9vd24V7sC2uzEoM4UXDVk3I9UGrcZbAZajS+z62emoMWvWeKx6myqSjNzdStq7dtXV1ch4KpjGKl0xf0emaorhFS5yngsW6t7xMZwj/LGx5faSUEdWdTjR3BHLqgadyrXMwLCjd1fZRGwGewYPlMfDExVraPOjOGeGWdHnd8MzGwILytvRZUziEfnevreGezCJa/+7c7Xmtm7zOybzKyb2T/ovf/m1nOzBeObr/YzpfYwVmncjlxxBp07iBm15okyDxvBzttZ/XBHo5RSlc8nxSK1rrjhmRJHnc2Md1OFV6lztF89NnK3I2WOzqveW7eqUv+Emf1q7/3vtdZeYmZfWTxvL6ZctQzuSLlUQ+dGbnZf2UavVS5VnkgtIvXI6iaqg5Fac9kQbnS/fcHyZ4++Mpe7WjcML25nUPJ6Zrm5uQmvwXkxsw3XPfKuZiFmq3wi+KVm9u1m9vefJPLIzB5Np/SAVr35Kh5DhqqsIPc42QQZQsAN1s/POhw3dXOXKnRUD5wntURq6+VzuDmuAhzhHqk01r2qo8gNxv0IVq9LjuOu8miJOlV2tTOwR/dsKdwVpX6Vmf2hmf1Ma+2bzewjZva23vufYaS2h7/dWQLzyM3LXG91TDXmyAXnF1Jm3HDf9ln5WYVW9RGV3+z++9pYhqurq43OTE2eRePqzK1f4s1EIDN4CPDNzc29fQVsBHyk9Are0VhadUrbsArUV2b2rWb21t77B1trP2Fmbzezf0qZPLi/3TEbN4zKcQV2pGgK8GwiyA3HzmiVme3MfYvKqsDh/EWTZQpqNUGmxtCVMTXny8vkYRX3moFFAL1e+Vi2uKvtHYI6HgGcueUK7uweVqwC9Ytm9mLv/YNP9t9jd1AflY1c78jVjvb5WDSGVnCbxZ86GsGeATx68QSvVVXrCGx2s6twq7rgTi7qaCN3u7IwfCOglRpnKu71r1Sdj43ArYRn0Fc+5v8HrbXPtdZe3Xv/tJl9l5l9cnTeIVoEsdsI5Mj1VoqdKdVImVSjVjexGqauWVFqNXSIQI3gHk2K+XCC7wuXCcNHqjwaC+P+9fX1Bug3NzcbC3YIvI6uHY3h8T5FY28+VrnHbtXZ77ea2bvb3cz3Z83sB4rn7dUydV5yrciFVirNjdlMf2dLdSpRPqObOVLo7PrK81DlwmPquXME9OhNO5Wuskyl1aOokSuNLnUE90i9PS/RxFg0po5gxXI+tPttvfePmdlrF6eyA8saxAjkqEGhUnE8bvijMaKa9eXzVV4rcKPajcrJ2yOl5s4sc8MjVY68lWyOAcvqx7KxNI99M5DV2s/JxsxKtaN4PH5X0EcqvRb25+KNssgUQOhiuzHYmQutGm11JjwCe63xuJzTifIRDRsyjySaTMtc8FF5I5eVXV41mXVzc2PX19cbIDOguO+qnak3poNxFMi8n8G8RqHdjg7qaoOvqPMoHjfw7PxsfK1g4ONu3Kms8UBUvGib5w+2qdgK4FmXG/fVZFWk0Ar8bEytXHM15lYqr1x0v47newbmpZAfHdSZVZVudJwB5nMzkD2OmlRTQPB1OI0IwopFHRFuR5BVFXtGuSOVVoBX3G4es44mu7IJsNGC6s1eQQS355sfd0VqzeXEusD1yE4K6qWWdQZKrZXCZI2eYY/c8AhmNSTI8hvtj6DG9KqKHUGttpe63b4dAa1UdAngkRs+Gq+zovO+yn8G9Fp7bqCuNCKPVw2P3EkVlrnhDD+65BXVroKMptz8kWpHUPLrsNHYuQq2q3QEdaTOEcTKba4oMU98ocuuOhIFc1WhlasdTZ6NwH9uoN62KVcbw/kYNnbcxzgjtzTzKJSaZ8qswqqdlKcXzQ9Uy6by6aZc0czVHk2A8eRXFIYKrc5Ht9vhjpSax9i8zeXLFJzrJbOTh7rislavka0VzKy8qGxK1RQgmE40iZZBP3ssKlPFJR8pedZJsEUNPVLnaBILlZUhHam3isswqzE1uunR+B/LhuXN6qJqJwf1EmiVRZNl2SSap5819mwsysc9vREQ24IcyxepdlZGjlf1PNCycbQCGqFU8PLxTJEjFVdAZ+69mo3PXPCsA4vqJrOTg3rGZjqAKC420MwNx22Mq+A2i9/mwmvMAO42q/ZZOhHI2fFtAp09usrgrs50q3H1Ule7AnNmM2r9XEO91jIl9O1snDn6oELV5eV0I7WdWWfnR2nOdDa8XQV6BPjsLHc0rs46AlZrNaG2FGwGXMF8nijboSkgokVNMi15pjt6xr0Wag7DNDnOzLUjixq+UmIFcgXs6+vrp8vNzY09fvxYuujRvoKY3e3Ie8jA5noYbUd2hnqBqcaplFLFYQiilzSiMbhff6TaVZVVZVHDiBn4R6qMNpogwvFpNqYeAc6KXJkow0dXvs/ut4/N1Ti6AnIG+OwEmdvJQd375l+wZHG3bRFI2fNajqcAN9OPkda45nxsBOOabbZInbLGz8rHkDGImWvNE2Wo3HgdfAHFweU0RhNjMwrNdbME8pOD+tBNgTf64cOMS65cc0zXt9U6216yH5l3vLjm4x4WjaNRxXksqwCeHW9HY2bsSLKZbuWCj8bW3IlxnVTt5KFm5a5Wzu3t7fDxlVvUuEePo9S+UvMq2FGaVfd7pLIRtCOYWW1GQPs6U2l2u0cTV5WJMo6nHmc5xBgejfWrEGd1wPVXsZOHepc2UjkcF0duuVLpDGyz3C3HtNaMfdfWSwQ2GgM9Ujs8zuPf0XhajasxXE2IzQJdUWkse9XVHkH+XEE9M95eapXrK+AykBXY7Jpnbjmmw/mLnq1XylQZE97e3sprVBQa97PZbzymJsCiNbrqCDZeL1P+pUBzuWfc7opqPzdQrwV6yYSF2eaEGbvYCkozK4FdHWv79TAfmDfezsJmJnd6f/aXQArurMEqGDK3m0FVLndlXK0m3dSxtQodqbVaj+qerfIx/1eb2X+AoFeZ2T/rvf94KYUjMtWTevgSY6A8bDSmjv4XuwI2u+XVMfVsh5cprRozX1xcPAUb6yJSLtxWaqYAUuCyex2523z+7PPoNUBnSh3Vd2aVr4l+2sy+5clNuDSz3zez95ZT2IPNqvJSaCObSTuCfDS2jmbHzcY/vsA8zoynZ0BWwDrY6phKK1oiVzyCXc1UI5zohiv3G137hwBa1e9Sz9Bs3v3+LjP7P73335s8bydWhXnbECvLFDFzyfkXTSOXfMYNH0Gt9s1ymKP1qI4RbAUthyuAIpWO1DqKg5NsfD1050dAR0MGVUZVb6q+l7TVWajfZGY/rw60PfztzrGYcsMrj7swjvruNsZR/9sVud+zLnc0ycVQjhS49y7d8CjujFKPVDpbMC6P2dUYPko3gpnLE9Uhrnl7xspQt7tvfr/RzN6hjvcD/dudbZrfrCWf5MWwSKkjlzpzuR3omZlws/w/siM4PYwnvbjBztRHZNy4GZzRmHoEcjSrnXkFVZeb84p1xNtY1irQo3qeUervNrOP9t7/78Q5W7eqi125TmS3t/UXT6rGUPF25ipnsKpfeql4eB1MP3K/lUuI5yDgHI5KD1pIvgAABVVJREFUxefjdSNXP1O3TLk9PwqykcIy7NhRZGo8A3RVlaO2WVXuGajfbIHrfbY5U+Nr3lcQV4AezYKPoOY8umFDRHg9DYYYz4+AHo0lKy74KE42W83j7mhMnY2btw10ZDOueAnq1tpXmtnfMrN/VL7ynq2q6KPKWjqucYsUOlJtjqMW9QZZ9VXSKtRcBw4hwshws2qrcz1flXG1n19RbuVys3or19otUmoFczQptm+Fdqv+7c7/M7M/P3Xlsw0tcrGzcXem5BWgFdi87cbwKqDREFZ2yaNxOqel1M6Pj1xvdQyvp1xpjqPyUF24PPsA2uw5eqNs3zYaU2OcCNhMkZWbvlapldp6eNTYEGxU56UezwhcFcbAO7ge18ykqiuwlwKeAa06gKjsS+wM9Z4tgitS5mgbx9CZQkdKjftrAOTrYUfAHdvS649AyzqBSFmVYq+FGfO8K6DNjhDqNY3iECwbX0cNv+KSZ278LNRLzFUZrxUpe5SOgkkdwzBWV3VsBsKqMnNeorxFeVf7o/CqHR3U3Hh2me6uTUGufpjh+3zONqHGeld1gcdw0myN681pRdu4H63ZnfZjCtaRYvP1Vdwon0vDZ+zooD4mi+AZPS9WcEXjYaXSUZzqmBrDGOaRys5CPNtBK1VVoGLcyNVmZc/WnAflwkf55P2HBNrMbLtvWJxttY0a+cwEVxSncg0Vt5Kmuu42xtKzDT5yydnUJBrHj1x1dWw0ZNiFnZX6gGyk0Cpe5E6rOCNvYGk+qyq9RpU5PFLQbJ1Z9Nx8CZAzCr4mncjOSr1Dm23US8AbjZPXXnMXZYhsGw1/dI1KR7AvBa7aQyn1H5nZ702e8xeenDe0Q69UYeWyHZmdy7U/+6vRgXYoYLTWPtx7f+2+8/EQdqplO5frMO3sfp/tbCdmZ6jPdrYTs0OC+p37zsAD2qmW7VyuA7SDGVOf7Wxn244dklKf7Wxn24KdoT7b2U7MDgLq1trrW2ufbq19prX29n3nZxvWWntFa+2/ttY+1Vr7RGvtbfvO0zattXbZWvsfrbVf2Xdetmmtta9trb2ntfY7T+7dX993nmZt72PqdvcHAf/b7j6X9KKZfcjM3tx7/+ReM7bSWmtfZ2Zf13v/aGvta8zsI2b2d4+9XG6ttR82s9ea2Ut772/Yd362Za21nzWz/9Z7f1e7+4LuV/be/3jf+ZqxQ1DqbzOzz/TeP9t7f2Rmv2Bm37vnPK223vsXeu8ffbL9JTP7lJm9bL+52o611l5uZt9jZu/ad162aa21l5rZt5vZT5mZ9d4fHRvQZocB9cvM7HOw/6KdSON3a6290sxeY2Yf3G9OtmY/bmY/Yma1rwcej73KzP7QzH7mydDiXa21r9p3pmbtEKBWb/yfzHO21tpXm9kvmtkP9d7/ZN/5WWuttTeY2Rd77x/Zd14ewK7M7FvN7F/33l9jZn9mZkc3x3MIUL9oZq+A/Zeb2ef3lJetWmvtBbsD+t2991/ad362ZK8zsze21n7X7oZK39la+7n9Zmlr9qKZvdh7d4/qPXYH+VHZIUD9ITP7htba1z+ZmHiTmf3ynvO02trdbw5/ysw+1Xv/sX3nZ1vWe39H7/3lvfdX2t29+i+99+/bc7a2Yr33PzCzz7W7v282u/tDyKOb2Nz7RxJ679ettR80s18zs0sz++ne+yf2nK1t2OvM7PvN7Ldbax97Evajvff37TFPZxvbW83s3U8E5rNm9gN7zs+07f2R1tnOdrbt2iG432c729m2aGeoz3a2E7Mz1Gc724nZGeqzne3E7Az12c52YnaG+mxnOzE7Q322s52Y/X/CqDEmsU2QxAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, interpolation=\"bicubic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">Same as the solution </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for 3 and 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered gold labels: \n",
      " 9\n",
      "Filtered image flatten: \n",
      " [ 0.  0.  5. 15.  7.  0.  0.  0.  0.  0. 14. 16. 16.  5.  0.  0.  0.  0.\n",
      " 13. 14. 14. 15.  0.  0.  0.  0.  3. 11. 14. 16.  3.  0.  0.  0.  0.  0.\n",
      "  6. 16.  2.  0.  0.  0.  0.  0.  4. 16.  7.  0.  0.  0.  0.  1. 11. 16.\n",
      "  6.  0.  0.  0.  4. 15. 16. 10.  0.  0.]\n",
      "Filtered image matrix: \n",
      " [[ 0.  0.  5. 15.  7.  0.  0.  0.]\n",
      " [ 0.  0. 14. 16. 16.  5.  0.  0.]\n",
      " [ 0.  0. 13. 14. 14. 15.  0.  0.]\n",
      " [ 0.  0.  3. 11. 14. 16.  3.  0.]\n",
      " [ 0.  0.  0.  0.  6. 16.  2.  0.]\n",
      " [ 0.  0.  0.  0.  4. 16.  7.  0.]\n",
      " [ 0.  0.  0.  1. 11. 16.  6.  0.]\n",
      " [ 0.  0.  4. 15. 16. 10.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits_to_filter = [3, 9]\n",
    "filtered_target_9 = []\n",
    "filtered_target_3 = []\n",
    "filtered_target = []\n",
    "filtered_images_9 = []\n",
    "filtered_images_3 = []\n",
    "filtered_images = []\n",
    "filtered_data_9 = []\n",
    "filtered_data_3 = []\n",
    "filtered_data = []\n",
    "\n",
    "indices = None\n",
    "\n",
    "for digit in digits_to_filter:\n",
    "    # find all the indices of images that contain the digit\n",
    "    indices = np.where(target == digit)[0]\n",
    "    # get the images and target labels\n",
    "    imgs = images[indices]\n",
    "    target_labels = np.full((len(indices),), digit)\n",
    "    data_filter = data[indices]\n",
    "    # add the images and target labels to the filtered lists\n",
    "    if digit == 9:\n",
    "        filtered_images_9.append(imgs)\n",
    "        filtered_data_9.append(data_filter)\n",
    "        filtered_target_9.append(target_labels)\n",
    "    else:\n",
    "        filtered_images_3.append(imgs)\n",
    "        filtered_data_3.append(data_filter)\n",
    "        filtered_target_3.append(target_labels)\n",
    "\n",
    "filtered_images = filtered_images_3 + filtered_images_9\n",
    "filtered_data = filtered_data_3 + filtered_data_9\n",
    "filtered_target = filtered_target_3 + filtered_target_9\n",
    "\n",
    "# concatenate the images and target labels and shuffle the list\n",
    "filtered_images = np.concatenate(filtered_images, axis=0)\n",
    "filtered_target = np.concatenate(filtered_target, axis=0)\n",
    "filtered_data = np.concatenate(filtered_data, axis=0)\n",
    "print('Filtered gold labels: \\n', filtered_target[205])\n",
    "print('Filtered image flatten: \\n', filtered_data[205])\n",
    "print('Filtered image matrix: \\n', filtered_images[205])\n",
    "plt.imshow(filtered_images[205], interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">Filtering could have been easier as shown in the solution with a mask = np.logical_or(3,9)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 64) (146,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "X_all = filtered_data \n",
    "y_all = filtered_target\n",
    "X_train , X_test , y_train , y_test = model_selection.train_test_split(filtered_data, filtered_target,\n",
    "test_size = 0.4, random_state = 0)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">Same as the solution </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate visualization, you should construct a 2-dimensional feature space with any formula over the 64 original pixels you can come up with. You may, for example, choose two pixels that seem to have a big in\u001d",
    "uence for the distinction between 3's and 9's. To identify suitable pixels, you may want to look at the average images for the two classes \u0015 pixels that tend to be bright in one class and dark in the other are good candidates. You can also use some clever linear or non-linear combination of multiple pixels into 2 features, for example: f ̃ = 0.3f + 42 f13 and f ̃ = f − f .\n",
    "1 23 f64 2 33 62 Of course, the quality of your features determines the achievable error and therefore is a limiting factor for the quality of your predictions. Your dimension reduction procedure should be callable\n",
    "through a function features2d:\n",
    "features = features2d(x)\n",
    "where x is a #instances × 64 matrix and features has shape #instances × 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average values over all 3 images:\n",
      "[ 0.   0.1  5.7 11.8 11.3  5.9  1.6  0.1  0.   2.4 12.7  9.6 10.1 11.4\n",
      "  2.6  0.1  0.   3.7 12.5  5.6  8.3 14.1  3.2  0.   0.   2.  10.4 12.2\n",
      " 13.2 14.1  3.8  0.   0.   0.2  2.9  5.2  5.1 11.6  4.8  0.   0.   0.2\n",
      "  0.5  0.6  2.5  9.7  5.8  0.   0.   0.7  6.1  5.   5.8 10.5  5.2  0.1\n",
      "  0.   0.1  5.7 12.  13.1  8.9  2.1  0.1]\n",
      "Average values over all 9 images:\n",
      "[ 0.   0.6  8.4 14.2 14.2  7.5  0.8  0.   0.   4.2 12.7  9.  11.3 12.\n",
      "  2.1  0.   0.   2.2  3.7  3.1 12.   9.3  0.8  0.   0.   0.3  1.5  8.9\n",
      " 14.3  5.6  0.1  0.   0.   0.1  1.   5.6 12.  11.3  2.2  0.   0.   0.4\n",
      "  1.4  1.   4.4 12.1  6.3  0.   0.   0.9  7.1  6.2  8.3 13.   5.9  0.1\n",
      "  0.   0.5  9.3 14.7 14.   8.7  1.4  0.1]\n",
      "List of 10 most different coordinates between 3 and 9:\n",
      "[29 36 18 26 21 30 58 20 27  4]\n"
     ]
    }
   ],
   "source": [
    "# compute the average values over all 3 images and over all 9 images separately\n",
    "avg_3 = np.round(np.mean(filtered_data_9[0], axis=0), 1)\n",
    "avg_9 = np.round(np.mean(filtered_data_3[0], axis=0), 1)\n",
    "\n",
    "print(\"Average values over all 3 images:\")\n",
    "print(avg_3)\n",
    "\n",
    "print(\"Average values over all 9 images:\")\n",
    "print(avg_9)\n",
    "\n",
    "# compute the difference between the two averages\n",
    "diff = np.abs(avg_3 - avg_9)\n",
    "\n",
    "# find the coordinates of the maximum difference\n",
    "max_diff_coords = np.argpartition(-diff.flatten(), 10)[:10]\n",
    "\n",
    "print(\"List of 10 most different coordinates between 3 and 9:\")\n",
    "print(max_diff_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">Flattening the diff array is unnecessary since it is a 1D array</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Features with max diff pixels as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., 12.],\n",
       "       [ 2., 15.],\n",
       "       [12., 13.],\n",
       "       [ 3.,  9.],\n",
       "       [ 2., 15.],\n",
       "       [ 6., 10.],\n",
       "       [ 8., 12.],\n",
       "       [ 2., 15.],\n",
       "       [12., 13.],\n",
       "       [12., 15.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the 2D features based on two pixels\n",
    "\n",
    "def features2d(x):\n",
    "    # compute the 2D features based on two pixels\n",
    "    pixel1 = max_diff_coords[0]  # choose the first pixel\n",
    "    pixel2 = max_diff_coords[1]  # choose the second pixel\n",
    "    features = np.zeros((len(x), 2))\n",
    "    features[:, 0] = x[:, pixel1]\n",
    "    features[:, 1] = x[:, pixel2]\n",
    "    return features\n",
    "\n",
    "# test the function with some example data\n",
    "X_all_2d = features2d(X_all)\n",
    "X_all_2d[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">Finding the most relevant pixels and using them to calculate the features is not what the solution did but was also allowed. But why not use more of them instead of just 2. Maybe the name X_all_2d is not ideal because X is used for the matrix with the pixel data of the instances</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Features from max differences per number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def get_diff_pairs(lst):\n",
    "    # Generate all combinations of index pairs\n",
    "    index_pairs = list(combinations(range(len(lst)), 2))\n",
    "    \n",
    "    # Calculate the absolute differences for each index pair\n",
    "    differences = [(i, j, abs(lst[i] - lst[j])) for i, j in index_pairs]\n",
    "    \n",
    "    # Sort the differences in ascending order\n",
    "    sorted_differences = sorted(differences, key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    return sorted_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_diff_indice_tuples(diff_tuples, avg_list, threshold = 5):\n",
    "    # Find the indices where the corresponding elements in the second list have a low difference\n",
    "    indices = [candidate for candidate in diff_tuples if np.abs(avg_list[candidate[0]] - avg_list[candidate[1]]) <= threshold]\n",
    "    # for i in indices:\n",
    "        # print('Diff number one: ', i[2])\n",
    "        # print('Diff number two: ', avg_list[i[0]] - avg_list[i[1]])\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 10 most different pairs between 3 and 9:\n",
      "[(0, 21, 14.1), (0, 29, 14.1), (8, 21, 14.1), (8, 29, 14.1), (16, 21, 14.1), (16, 29, 14.1), (21, 23, 14.1), (21, 24, 14.1), (21, 31, 14.1), (21, 32, 14.1)]\n",
      "[(55, 63, 0.0), (48, 56, 0.0), (47, 56, 0.0), (47, 48, 0.0), (42, 62, 0.0), (40, 56, 0.0), (40, 48, 0.0), (40, 47, 0.0), (39, 56, 0.0), (39, 48, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "diff_pairs_three = get_diff_pairs(avg_3)\n",
    "diff_pairs_nines = get_diff_pairs(avg_9)\n",
    "print(\"List of 10 most different pairs between 3 and 9:\")\n",
    "print(diff_pairs_three[:10])\n",
    "print(diff_pairs_nines[::-1][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features nine:  [(29, 35, 8.899999999999999), (21, 58, 8.399999999999999)]\n",
      "Features three:  [(26, 53, 11.5), (36, 51, 5.8)]\n",
      "Best feature for 3:  [(26, 53), (36, 51)]\n",
      "Best feature for 9:  [(29, 35), (21, 58)]\n"
     ]
    }
   ],
   "source": [
    "features_nine = find_max_diff_indice_tuples(get_diff_pairs(avg_3), avg_9, 0.1)[:2]\n",
    "features_three = find_max_diff_indice_tuples(get_diff_pairs(avg_9), avg_3, 0.1)[:2]\n",
    "best_features_nine = [candidate[:2] for candidate in features_nine]\n",
    "best_features_three = [candidate[:2] for candidate in features_three]\n",
    "print('Features nine: ', features_nine[:10])\n",
    "print('Features three: ', features_three[:10])\n",
    "print('Best feature for 3: ', best_features_three)\n",
    "print('Best feature for 9: ', best_features_nine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., 12.],\n",
       "       [ 2., 15.],\n",
       "       [12., 13.],\n",
       "       [ 3.,  9.],\n",
       "       [ 2., 15.],\n",
       "       [ 6., 10.],\n",
       "       [ 8., 12.],\n",
       "       [ 2., 15.],\n",
       "       [12., 13.],\n",
       "       [12., 15.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def features2d_combined_diff(x):\n",
    "    features = np.zeros((len(x), 2))\n",
    "    features[:, 0] = np.abs(x[:, best_features_nine[0][0]] - x[:, best_features_nine[0][1]])\n",
    "    features[:, 1] = np.abs(x[:, best_features_three[0][0]] - x[:, best_features_three[0][1]])\n",
    "    return features\n",
    "\n",
    "\n",
    "# test the function with some example data\n",
    "X_all_2d_combined_diff = features2d_combined_diff(X_all)\n",
    "X_all_2d[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">This part could be explained a bit better because I am not sure why you do this and what exactly it does </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot with simple feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assume X_all is your instances x 2 feature list and Y_all is your list of gold labels\n",
    "X1 = X_all_2d[:,0]  # extract the first feature from X_all\n",
    "X2 = X_all_2d[:,1]  # extract the second feature from X_all\n",
    "\n",
    "# create a scatter plot with two different markers for the two classes\n",
    "plt.scatter(X1[y_all==9], X2[y_all==9], marker='o', color='blue', label='Class 9')\n",
    "plt.scatter(X1[y_all==3], X2[y_all==3], marker='s', color='red', label='Class 3')\n",
    "\n",
    "# set the labels for the x and y axes\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "# add a legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">Same as the solution </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot with combined feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dfZBcVZ3/8fc3M0EIJIgwuGQCE5ICdJKQAUZEBWokUZH1YSmXqlBRYVUiCQ/yqx+7wmYLqRVEVlf0txIwuCjKyK4rIKxLeFiVh10XZfJICGsCIQkJCAMIQaJAZr6/P+6dpDO53emePt33dM/nVdU1fe/cOf29p+/Mme5z+3PN3RERERluTN4FiIhInDRAiIhIJg0QIiKSSQOEiIhk0gAhIiKZWvMuIKSDDjrIJ0+enHcZIiINY+nSpS+4e1vW95pqgJg8eTJ9fX15lyEi0jDMbGOx7+ktJhERyaQBQkREMmmAEBGRTBogREQkkwYIERHJpAFCREQyaYAQEZFMGiBERCSTBoghEyaA2e63CRMqayerjaFbpWJsK2RNofo8ZF0x1hRSjMcUhOv3kM9fSAH7asECaG1NfrS1NVmulab6JHVVXn21svVSvRj7PMaaRoNQ/d7kz9+CBXDddTuXBwZ2Li9aFP7x9ApCRKRBLF5c2fpqaYAQEWkQAwOVra+WBggRkQbR0lLZ+mppgBARaRDz5lW2vloaIIaMH1/ZeqlejH0eY02jQah+b/Lnb9EimD9/5yuGlpZkuRYT1ADm7rVpOQfd3d2u60GIiJTPzJa6e3fW9/QKQkREMmmAEBGRTBogREQkkwYIERHJVLMBwsxuNLPnzWx1wbrLzWyLma1Ib6cV+dlTzey3ZvaEmV1SqxqjF2NuTqxZRTFmTQG9vTB5MowZk3zt7R1RM3r+Gl2DZk3V8hXE94FTM9Zf4+5d6e2u4d80sxbgWuDDQCdwppl11rBOqUSTZ92E1NubnJ++cSO4J1/nzatikAhBz18+GjRrqmYDhLs/CLw0gh89HnjC3de7+xvAvwAfD1qcSB0sXAjbtu26btu2ZL1II8hjDuJ8M1uVvgV1QMb324GnC5Y3p+symdk8M+szs77+/v7QtYqM2KZNla0XiU29B4jrgKlAF/As8I8Z22S96Vj003zuvtjdu929u62tLUyVIgEcdlhl60ViU9cBwt2fc/cBdx8EbiB5O2m4zcChBcuTgGfqUZ9ISFdeCePG7bpu3LhkvUgjqOsAYWaHFCyeDqzO2OwR4AgzO9zM9gLmAHfWoz4pQ5Nn3YQ0d26S09/RkZxo0tGRLM+dm2NRev7y0aBZUzW7opyZ3QL0AAeZ2WbgS0CPmXWRvGW0Afh8uu1E4Lvufpq7bzez84F7gBbgRnd/rFZ1Ri1kTlaotrZuDdMOxLl/gbPJ5s4NNCDo+Wtsofo95PNXBoX1iYiMYgrrExGRimmAEBGRTBogREQkkwaIIaEyTkJmyoTMXdH+lafZM4Fiff5iFGlfBcv3KkPNzmJqODFm1ISsSfsnoanPyxeor4byvYYiXIbyvaA2p0/rFYSISIOod76XBggRkQZR73wvDRAiIg2i3vleGiBERBpEvfO9NEAMiTGjJmRN2j8JTX1evkB9Ve98L0VtiIiMYoraEBGRimmAEBGRTBogREQkkwYIERHJpAEitJD5LTFmwYTM34m1r0KJMWsqVjEenyEFrGvBAmhtTX68tTVZrhVlMY0WoXJzlL9TPmVNla/Zj89AdS1YANddt3N5YGDn8qJFI6ytBL2CEBFpEIsXV7a+WhogREQaxMBAZeurpQFCRKRBtLRUtr5aGiBERBrE0LUfyl1frZoNEGZ2o5k9b2arC9Z9zcz+18xWmdntZvbWIj+7wcweNbMVZqbsjBBC5eYof6d8ypoqX7Mfn4HqWrQI5s/f+YqhpSVZrsUENdQwi8nMTgb+APzA3aen6z4I/MLdt5vZ1QDu/sWMn90AdLv7C5U8prKYREQqk0sWk7s/CLw0bN297r49XXwYmFSrxxcRkerkOQfxGWBJke85cK+ZLTWzku+umdk8M+szs77+/v7gRYqIjFa5DBBmthDYDvQW2eR97n4s8GHgvPTtqkzuvtjdu929u62trQbVioiMTnUfIMzsLOAjwFwvMgHi7s+kX58HbgeOr1+FIiICdR4gzOxU4IvAx9x9W5Ft9jWz8UP3gQ8Cq7O2DUpZMGXr7YXJk2HMmORrb7HXgXWsKVgWU6z5SQGzpoI9fyE1e5YWgfq93v3k7jW5AbcAzwJvApuBzwJPAE8DK9Lb9em2E4G70vtTgJXp7TFgYbmPedxxx/mIQfFbHu2EFqium292Hzdu1x8fNy5Zn1dNQduKsaaAbQV9/kKK8fcmYE3B+r0G/QT0eZG/qbrk6JBSI3AlfRSqndAC1TV5MmzcuPv6jg7YsCGfmoK2FWNNAdsK+vyFFOPvTcCagvV7DfpJlxyVYDZtqmy9xEXPXz4atd81QEhFDjussvUSFz1/+WjUftcAIRW58koYN27XdePGJeslfnr+8tGo/a4BYoiyYMoyd26SPd/Rkbwd2tGRLM+dm19NQTV5flLQ56/ZBXz+GrXfNUktIjKKaZJaREQqpgFCREQyaYAQEZFMGiBERCSTBoghoXJXQmalxJgL1Oz7F1iUuUehNHufx7h/da5JZzENUVRDfduJua1AenuTawVvK4ilHDeuMU5vLEuz93mE+1fvqA0NEEP0B7S+7cTcViDR5h6F0ux9HuH+KYtJpEk0av5OI1Ofh6UBQqRGGjV/p5Gpz8PSACFSI42av9PI1OdhaYAYEmFuTrPnAjX7/jVq/k7Zmr3PI9y/etekSWoRkVFMk9QiIlIxDRAiIpJJA4SIiGTSACEiIplqOkCY2Y1m9ryZrS5Y9zYzu8/M1qVfDyjys2el26wzs7NqWWdQseYLNXuuTKi2YuynVKiMIeVDlS+6vqr38enuNbsBJwPHAqsL1v0DcEl6/xLg6oyfexuwPv16QHr/gD093nHHHee5Sz7wnn1rlrZCiXH/Yuwnd7/5Zvdx43YtZ9y4ZH0e7UQr4PMXZV/V4PgE+rzI39San+ZqZpOBn7n79HT5t0CPuz9rZocA97v7UcN+5sx0m8+ny99Jt7ul1GNFcZprrPlCzZ4rE2PWVEChMoaUD1W+KPtqFGQxvd3dnwVIvx6csU078HTB8uZ03W7MbJ6Z9ZlZX39/f/BiRWIQKmNIWUXlU1/FO0mdNUxmDo/uvtjdu929u62trcZlieQjVMaQsorKp77KZ4B4Ln1rifTr8xnbbAYOLVieBDxTh9pEohQqY0hZReVTX5UYIMxshpk9bGZPm9niwrONzOw3VTzmncDQWUlnAXdkbHMP8EEzOyB93A+m6+IXa75Qs+fKhGorxn4iXMaQ8qHKF2VfxZLFZGb/BVwBPAx8Dvgr4GPu/qSZLXf3Y/bYuNktQA9wEPAc8CXgp8CPgcOATcAZ7v6SmXUD57r759Kf/Qzwt2lTV7r79/b0eFFMUouINJBSk9StJX5uP3e/O73/dTNbCtxtZp+iyHzAcO5+ZpFvzcrYto9kIBpavhG4sZzHERGR8EoNEGZm+7v7KwDu/ksz+wRwK8nnE0REpImVmqS+Gnhn4Qp3X0Xy3/9ttSxKRETyV/QVhLv/qMj6TcA5NatIJIA333yTzZs386c//SnvUqKz9957M2nSJMaOHZt3KRK7Yh+xbsRbFFEbzS7wR/1vvtm9o8PdLPlaTYxBYVuLF6/39ev7fXBwsLJGHnmk+K0JDA4Oen9/v69fv776xsaPzz4Oxo8fUXNBjoXANYUU6lgP+TvjXjpqo9QchEhN9fbCvHmwbVuyvHFjsgyVn0o4vK329j/x0kuTmTDBOPDAcDU3OjPjwAMPJEjqwKuvVra+hGDHQsCaQgq1fyF/Z8qhS45KZSLNuhne1pIlj3PQQe9kr73g6KMraKjU8dOdeSZgQ3r88cd55zvfuecNS4nxWFCWVsWqymIysyPN7OdDkd1mdrSZ/d3IShHZKWTWTbGfeeONytsK5Xe/+x1z5sxh6tSpdHZ2ctppp7F27Vo2bNjA9OnTa/KYGzduZNasWRx99NH09PSwefPmmjxOaM2ee9SoWVrlRG3cAFwKvAk7zmSaU5tyZDQJmXVT7Gf22qvytkJwd04//XR6enp48sknWbNmDV/5yld47rnnavq4F198MZ/+9KdZtWoVl112GZdeemlNHy+UZs89atQsrXIGiHHuPjxaY3stipHRJWTWTVZbY8ZAe2YG8O52XBjm+OOY/NEZ9C6p7qM+v/zlLxk7diznnnvujnVdXV2cdNJJu2y3YcMGTjrpJI499liOPfZYfvWrXwHw7LPPcvLJJ9PV1cX06dN56KGHGBgY4Oyzz2b69OnMmDGDa665ZrfHXbNmDbNmJZ9Dff/7388dd2Ql2cSn2XOPGjZLq9js9dANWAJMBZaly38JLNnTz+Vx01lMddAgZzHde+8af+GF8n9utwvD7L3db/77J0d8FtO3vvUtv+iiizK/99RTT/m0adPc3f21117zP/7xj+7uvnbtWh86hr/+9a/7FVdc4e7u27dv961bt3pfX5/Pnj17Rzu///3vd2v7zDPP9G9+85vu7n7rrbc64C9kdMSaNWsq2p9MOoupIo14FlM5A8QU4D+BbcAW4L+Ajj39XB43DRAypJI/gB0d2X9TOjpG/vjlDhAvv/yyf/KTn/Tp06f7zJkzfZ999nF39wceeMCnTp3qX/rSl3z58uXu7v7SSy/5lClT/Pzzz/clS5b4wMDAbm1v2bLFTz/9dO/q6vILL7zQ29vb/eWXX95tuyADhDSFUgNEybeYzGwM0O3us4E24B3ufqK7Z8yjizSmWkz8TZs2jaVLl+5xu2uuuYa3v/3trFy5kr6+Pt5IZ9VPPvlkHnzwQdrb2/nUpz7FD37wAw444ABWrlxJT08P1157LZ/73Od2a2/ixIncdtttLF++nCvT9x3233//ke+IjGolBwh3HwTOT++/5u75nkwsUgO1mPg75ZRTeP3117nhhht2rHvkkUd44IEHdtnulVde4ZBDDmHMmDH88Ic/ZGBgAEjORjr44IM555xz+OxnP8uyZct44YUXGBwc5BOf+ARf/vKXWbZs2W6PO7QNwFVXXcVnPvOZke+EjHrlTFLfZ2YXm9mhZva2oVvNKxOpk1pM/JkZt99+O/fddx9Tp05l2rRpXH755UycOHGX7RYsWMBNN93ECSecwNq1a9l3330BuP/+++nq6uKYY47h1ltv5Qtf+AJbtmyhp6eHrq4uzj77bK666qrdHvf+++/nqKOO4sgjj+S5555j4cKFI98JGfX2+EE5M3sqY7W7+5TalDRy+qCcDKn0g2C9vbBwYfK20mGHJYND01xEJ0OQD8pJU6jqg3LufnjGLbrBoWoTJiSfwhx+mzAh78rCCLh/O04JHZN87e0NXm3lhu/Xxo3Jp6LL/Idh7tzkk6iDg7B0KcyYkfzoqlXw4ou1Lb1cL76Y1FNVXcuWJQ1s3Fj9cZ51PA3dRiDIcRX49zjGY33BAmhtTXartTVZrpU9ZjGZ2aez1rv7D8KXk6NIM1yCCbR/9c6CqbcXX0z2KX0bnzfe2BltkGemU7C6hhoYrkmyiqLMhwpowQK47rqdywMDO5cXLQr/eOXMQbyr4HYScDnwsfClSCNYuHDnL8yQbduS9c1gy5bd/4YODibr8xRrXaHEeFzFWNPixZWtr9YeX0G4+wWFy2a2P/DD2pQjsWv2zJxi2U15ZjqVevy86wolxuMqxprSk9zKXl+tcl5BDLcNOCJ0IdIYmj0zp1h2U16ZTnt6/LzrCiXG4yrGmlpaKltfrXLSXP/dzO5Mbz8DfgvcWZtyJHbNnpnT3p5MSBaqJNOpVmKtK5QYj6sYaxqaAyl3fbXKeQXxdeAf09tVwMnu/sWRPqCZHWVmKwpuW83somHb9JjZKwXbXDbSxyvb+PGVrW80gfZv7tzk/c6OjuQsio6OZLkZJqghmfDt6Nj5n/leeyXLI5mgDhn3XW5d119/PTNmzKCrq4sTTzyRNWvW7LrB8FFmSM7HebDjKuDvcYzH+qJFMH/+zlcMLS3Jci0mqIGyspiuLmfdSG5AC/A7hmU7AT3AzyptT1lMMiTvrKHBwUE/4YQT/Lrrrtuxbvny5f7ggw/uksUU2iuvvLLj/h133OEf+tCHMrfLu38kHow0iyn1gYx1Hw4wNgHMAp50ZTtJnmrwGZi84r4nFNT82muvYSP8TIIIlDiLyczmAwuAKWa2quBb44H/DvT4c4BbinzvPWa2EngGuNjdHytS5zxgHsBhzTJTKvVVg8/ArF69muOOO26P2x188MHcd9997L333qxbt44zzzyTvr4+fvSjH/GhD32IhQsXMjAwwLZt21ixYgVbtmxh9erVALz88suZbV577bV84xvf4I033uAXv/jFiPdBpNQriB8BHyWZkP5owe04d/9ktQ9sZnuRfJ7i3zK+vYzkbaeZwD8BPy3Wjrsvdvdud+9ua2urtiyRunrzzTc555xzmDFjBmecccaOOYN3vetdfO973+Pyyy/n0UcfZfz48UyZMoX169dzwQUXcPfdd+/yaqHQeeedx5NPPsnVV1/NFVdcUc/dkSZTdIBw91fcfYO7n5m+BfRHwIH9zCzEv+ofJrkI0W7XYHT3re7+h/T+XcBYMzsowGOK1EVecd+F5syZw09/WvR/K5E9Kuc014+a2TrgKeABYAPJVeaqdSZF3l4ysz+z9M1TMzs+rbO2iTih3oeONQsmxqypGGsaZqSZR6eccgqvv/QSNyxcuCMT6pGbbuKB73wH0reIoLK47+XLX6Cvb5COjk8wZ86Xefjh3eO+161bt+P+f/zHf3DEEY3zkaUYc49iNHv2rr8us2fX8MGKzV77zjOKVgIHAsvT5fcDi/f0c3tocxzJH/z9C9adC5yb3j8feCx97IeB95bTblVnMYW6lGbAS3JmXgpz3AgvMRj4UqFB1LCmis7SKVHHI4+4L13qZV++tNCWu+7yM2bP9int7d55+OF+2vve52tvvdWfuuOOHWcxrV271mfMmOHvfve7/ZJLLvF9993X3d2///3v+7Rp07yrq8tPPPFEf+ih9d7bu8KPOuoYP+KImX7EETP9m9+8yzds2PUxL7zwQu/s7PSZM2d6T0+Pr169uvr+qYOgx3oTmzUr+1CdNWvkbVLiLKZy4r773L07nTA+xt0Hzew37n588NGqSlXFfZc622MPfVSTdkj+ixoKZCvU0ZEkj1YkYF3B1LCmiuKsJ0zInJAeGDee5Q9sBZLPHRx9dIVFlDoWuzPTlevRFBBf3HfQY72J1eJXplTc9x6zmICXzWw/4CGg18yeB7aPrBSpRIxZME1p69Ydd4v9IW6WzKNY6ViPUzmfg/g4Sf7SRcDdwJMkZzNJjcWYBdPsmj3zKFY61uNUzgWDXgMOBXrc/Sbgu4D+n6qDGLNgml2smUfFzuBuljO7dayXZ9asytZXq5yzmM4BfgJ8J13VTonPJTSsUBkusWbBxJg1VeOa9jS/liVkFlPR3KNi60vo6Nh9MGhrS9ZXaiT9Umsx5h7F6D//c/fBYNasZH0tlDNJvQI4Hvi1ux+TrnvU3WfUpqSR0zWpZchTTz3F+PHjOfDAAxU3UcDdefHFF3n11Vc5/PDD8y5HIlDtJPXr7v7G0C+ZmbWSfGBOJFqTJk1i8+bN9Pf3511KdPbee28mTZqUdxnSAMoZIB4ws78F9jGzD5DkM/17bcsSqc7YsWP1H7JIlcp5M/QSoB94FPg8cBfwd7UsSkRE8lcqzfUwd9/k7oPADelNRERGiVKvIHacqWRmt9ahFqmxUFk3TZ0PRdhMoAULoLU12a3W1mQ5hrZCCVlTdMcnAfcv4LE+bdquTUybNsKaylEsg4M0e2n4/ZhvuqJccaGybpo9Hyrk/s2fn71r8+fn21YoIWuK8fgM2ueBjvXOzuwmOjtHUNOO0kaQxWRmy9z92OH3Y6bTXIsLlXXT7PlQIfevtRXScNZdtLTA9grDakK2FUrImmI8PoP2eaBjvd5ZTKUGiAHgNcCAfUjiNkiX3d3jyWROaYAobsyY7APIDAYH69/Ojh8qJqcBIuT+hdy9CLsqaE0xHp9B+7xBB4hSFwxqcfcJ7j7e3VvT+0PL0Q0OUlqorJtmz8wJuX8tLZWtr1dboYSsKcbjM8Y+r7fKP/MvDSlU1k2zZ+aE3L958ypbX6+2QglZU4zHZ4x93tlZ2fqqFZucaMSbJqlLu/lm944Od7Pk60gvxhKqHR8/PnvGbfz4ETYYRrD982RCs6Ul2a2WluomlUO2FUrImqI7Pj3g/gU81odPVFczQe0+wknqRqQ5CBGRyoxoDkJEREY3DRAiIpJJA4SIiGTSACEiIplyGyDMbIOZPWpmK8xst5llS/w/M3vCzFaZWW0/yR1jLtAoqClkbk4QMfZ5Krq+ImxNTZ3FFLCuumZyFTu9qdY3YANwUInvnwYsIfnk9gkkV7Sr3WmuEeYCNXtNQXOdQomxzz3OvgpZU7NnMYWqqxaZXMR4mquZbQC63f2FIt//DnC/u9+SLv8W6HH3Z4u1WdVprs2eZRBKwJqC5jqFEmOfE2dfhayp2bOYQtVVi0yuWE9zdeBeM1tqZlmfTWwHni5Y3pyu24WZzTOzPjPr0+UlG8umTZWtH81i7KuQNYVqK2RNWX+IS60vJVRdIWsqR54DxPs8SYj9MHCemZ087PtZ/8rt9i+cuy929253725ra6tFnVIjzZ7rFFKMfRWypmbPYgpVV73zoXIbINz9mfTr88DtwPHDNtkMHFqwPAl4pj7VST00e65TSDH2Vciamj2LKVRddc+HKjY5UcsbsC8wvuD+r4BTh23z5+w6Sf2bPbVb1SR1jLlAo6CmkLk5QcTY56no+srD1tTUWUwB6wqdyUVsk9RmNoXkVQMk18X+kbtfaWbnArj79WZmwLeBU0muRfFX7l5yBlpZTCIilSk1Sd1a72IA3H09MDNj/fUF9x04r551iYjITvoktYiIZNIAISIimTRAiIhIJg0QBYJkpYTM8om1rYCiyxeKtJ8gXAZPsD6PNJcrumMq1ZD7V+z0pka8VXOaa7AMl5BZPrG2FUiM+UIx9pN7uAyeoH0eYS5XlMdUwLpqsX/EdpprrVRzmmuwDJeQWT6xthVIjPlCMfYThMvgCdrnEeZyRXlMEff+lTrNVQNEasyY7GPaDAYHK2go1j/qEf7hC9bnIUXYTxCurKB9HrCvQtUV5TFF3PsXa1hfVGLMuml26vPyhcrgibXPY8xiCqlR908DRCrGrJtmpz4vX6gMnlj7PMYsppAadv+KTU404q2qLCYPlJUSMssn1rYCii5fKNJ+cg+XwROszyPN5YrumErFun9oklpERLJoDkJERCqmAUJERDJpgBARkUwaIEREJJMGiBqINQsmlJD7FypfKHRdocRYUzCjIIspxmN99uxdu3v27JHXtEfFTm9qxFu1p7mGEGsWTCgh9y9UvlDoukKJsaagmjyLKcZjfdas7HZmzaq8piHoNNf6iTULJpSQ+xcqXyh0XaHEWFNQTZ7FFOOxXoskGGUx1VGsWTChhNy/kAd7jP0eY01BNXkWU4zHer0HCM1BBBZrFkwoIfcvVL5QqcfPs99jrClWMWYVxXqs15MGiMBizYIJJeT+hcoXCl1XKDHWFKsYs4piPNZnzapsfdWKTU7U6gYcCvwSeBx4DPhCxjY9wCvAivR2WTltxzBJ7R5vFkwoIfcvVL5Q6LpCibGmYEZBFlOMx/rwiepqJqjdI5ukNrNDgEPcfZmZjQeWAn/h7msKtukBLnb3j1TSdgxzECIijSSqOQh3f9bdl6X3XyV5JdFe7zpERKS0XOcgzGwycAzw64xvv8fMVprZEjObVqKNeWbWZ2Z9/f39NapURGT0yW2AMLP9gFuBi9x967BvLwM63H0m8E/AT4u14+6L3b3b3bvb2tpqV7CIyCiTywBhZmNJBoded79t+Pfdfau7/yG9fxcw1swOqnOZIiKjWt0HCDMz4J+Bx939G0W2+bN0O8zseJI6X6xflVWINJ8mpCizbgL2u/Yvn7bqmjFUjhh/lwPXtEfFTm+q1Q04EXBgFTtPYz0NOBc4N93mfJJTYFcCDwPvLaftKE5zjTCfJqRYs25C9bv2L5+2apExVLUYf5cD1rSzyYhOc62lKE5zjTCfJqRYs25C9bv2r3wh26pFhETVYvxdrkFHKYupniLMpwkp1qybUP2u/StfjFlFQcX4u1znAUJRGxGLMcsn1qybULR/+bTV7Bq1rzRARCzGLJ9Ys25C0f7l01bdM4bqLMZjoSzFJica8RbFJHWk+TQhRZl1E7DftX/5tBU6Y6hqMf4uB67JXZPUIiJShOYgRESkYhogREQkkwYIERHJpAFCREQyaYAoMG3arvEm04qGjJcWLFOm3rkrOQiZ5dPevms3tY/wKiMha1qwAFpbk3paW5PlGNoKIvDx2ez7pyymBj7NtbMz++yxzs7K2gmaKVOD3JWYhMzymTgxu5smTsyvpvnzs2sayaUmQ7YVTMDjs9n3T1lMEajmNNdQn2AP+kn4KPMHwokxyydkTa2tMDCw+/qWFti+Pb+2ggl4fDb7/jVqFpPeYpLcbNpU2fp6CFlT1h+8Uuvr1VaMmn3/YjzWy6EBQnITYz5NyJpaWipbX6+2YtTs+xfjsV4ODRCpzs7K1hfT7JkyIYXMp5k4sbL19ahp3rzK1terrRg1+/4piymCW7VZTMMnqiudoB4SLFOmBrkrsQmZ5TN8orrSCepa1DR/vntLS1JPS0t1k64h2woi8PHZ7PunLKacKYtJRKQymqQWEZGKaYAQEZFMGiBERCSTBggREcmUywBhZqea2W/N7AkzuyTj+28xs39Nv/9rM5tcj7qCZSgFFDIXKIiI86FizLoJ+fxFdywQ4f7F+vxF/HtTUrHTm2p1A1qAJ4EpwF7ASqBz2DYLgOvT+3OAfy2n7WpOcw2aoRRIyFygYCLNh4ox6ybk8xfjsRDl/kX6/MX6e5OUVtcH7Z4AAAgYSURBVPw01zwGiPcA9xQsXwpcOmybe4D3pPdbgRcgOSW31K2aASLG56+jI7uejo78aoqyozxgXwXcv5DPX4zHQpT7F+nzF+vvTVJa8QEij7eY2oGnC5Y3p+syt3H37cArwIFZjZnZPDPrM7O+/v7+GpSbn0bNb8lDjH0VsibtX/3FWFO95TFAZMUR+gi2SVa6L3b3bnfvbmtrq7q4mDRqfkseYuyrkDVp/+ovxprqLY8BYjNwaMHyJOCZYtuYWSuwP/BSLYuKMUOpYfNbchBjX4WsSftXfzHWVHfF3nuq1Y1kTmE9cDg7J6mnDdvmPHadpP5xOW1Xm8UULEMpoJC5QEFEnA8VY9ZNyOcvumPBI9y/WJ+/iH9viC2LycxOA75JckbTje5+pZn9fVronWa2N/BD4BiSVw5z3H39ntpVFpOISGVKZTG11rsYAHe/C7hr2LrLCu7/CTij3nWJiMhO+iS1iIhk0gAhIiKZNECIiEgmDRAiIpJJA4SIiGTSACEiIpk0QIiISKZcPihXK2bWD2wM0NRBJAmyMVFN5YuxLtVUvhjrauaaOtw9M8iuqQaIUMysr9gnC/OimsoXY12qqXwx1jVaa9JbTCIikkkDhIiIZNIAkW1x3gVkUE3li7Eu1VS+GOsalTVpDkJERDLpFYSIiGTSACEiIpk0QBQws1PN7Ldm9oSZXZJ3PQBmdqiZ/dLMHjezx8zsC3nXNMTMWsxsuZn9LO9aAMzsrWb2EzP737S/3hNBTf8nfd5Wm9kt6cWw8qjjRjN73sxWF6x7m5ndZ2br0q8HRFDT19Lnb5WZ3W5mb61nTcXqKvjexWbmZnZQDDWZ2QXp36zHzOwfQj+uBoiUmbUA1wIfBjqBM82sM9+qANgO/F93fydwAnBeJHUBfAF4PO8iCnwLuNvd3wHMJOfazKwduBDodvfpJFdQnJNTOd8HTh227hLg5+5+BPDzdDnvmu4Dprv70cBa4NI61wTZdWFmhwIfADbVuyAyajKz9wMfB45292nA10M/qAaInY4HnnD39e7+BvAvJJ2fK3d/1t2XpfdfJfmj155vVWBmk4A/B76bdy0AZjYBOBn4ZwB3f8PdX863KiC5auM+ZtYKjAOeyaMId3+Q5PK9hT4O3JTevwn4i7xrcvd73X17uvgwMKmeNRWrK3UN8DdA3c/sKVLTfOCr7v56us3zoR9XA8RO7cDTBcubieAPcSEzm0xyne5f51sJkFxT/G+AwbwLSU0B+oHvpW97fdfM9s2zIHffQvJf3SbgWeAVd783z5qGebu7PwvJPyLAwTnXM9xngCV5FwFgZh8Dtrj7yrxrKXAkcJKZ/drMHjCzd4V+AA0QO1nGumjOATaz/YBbgYvcfWvOtXwEeN7dl+ZZxzCtwLHAde5+DPAa9X/LZBfpe/ofBw4HJgL7mtkn86ypUZjZQpK3V3sjqGUcsBC4LO9ahmkFDiB56/mvgR+bWdbfsRHTALHTZuDQguVJ5PR2wHBmNpZkcOh199vyrgd4H/AxM9tA8lbcKWZ2c74lsRnY7O5Dr65+QjJg5Gk28JS797v7m8BtwHtzrqnQc2Z2CED6NfhbFCNhZmcBHwHmehwf1JpKMsivTI/5ScAyM/uzXKtKjvnbPPEbklfzQSfPNUDs9AhwhJkdbmZ7kUwm3plzTaT/Efwz8Li7fyPvegDc/VJ3n+Tuk0n66Rfunut/xu7+O+BpMzsqXTULWJNjSZC8tXSCmY1Ln8dZxDWpfydwVnr/LOCOHGsBkjMJgS8CH3P3bXnXA+Duj7r7we4+OT3mNwPHpsdcnn4KnAJgZkcCexE4cVYDRCqdGDsfuIfkl/jH7v5YvlUByX/rnyL5L31Fejst76IidQHQa2argC7gK3kWk76a+QmwDHiU5Pctl8gGM7sF+B/gKDPbbGafBb4KfMDM1pGcnfPVCGr6NjAeuC891q+vZ00l6spVkZpuBKakp77+C3BW6FdcitoQEZFMegUhIiKZNECIiEgmDRAiIpJJA4SIiGTSACEiIpk0QIikzGyg4FTiFWm0SaVtvNXMFoSvbkf77zCz/zGz183s4lo9jgjoNFeRHczsD+6+X5VtTAZ+lqa3VvJzLe4+UMZ2BwMdJMF6v3f34AmeIkP0CkKkhPSaF18zs0fSaxR8Pl2/n5n93MyWmdmjZjaU/PtVYGr6CuRrZtZjBdfLMLNvm9nZ6f0NZnaZmf0XcIaZTTWzu81sqZk9ZGbvGF6Puz/v7o8Ab9Z852XUa827AJGI7GNmK9L7T7n76cBnSVJY32VmbwH+28zuJUn+Pd3dt6YXj3nYzO4kCQic7u5dAGbWs4fH/JO7n5hu+3PgXHdfZ2bvBhaRRimI5EEDhMhOfxz6w17gg8DRZvaX6fL+wBEkeTxfMbOTSULS2oG3j+Ax/xV2pPW+F/i3gkDOt4ygPZFgNECIlGbABe5+zy4rk7eJ2oDj3P3NNOUz63Ki29n1rdzh27yWfh0DvJwxQInkRnMQIqXdA8xPI9cxsyPTCxHtT3JNjDfTSz92pNu/ShI2N2Qj0GlmbzGz/UkSXXeTXuPjKTM7I30cM7OZtdklkfLoFYRIad8FJpPk/xvJVev+guRCNv9uZn3ACuB/Adz9RTP77zRhc4m7/7WZ/RhYBawDlpd4rLnAdWb2d8BYkoTOXa5gll6DoA+YAAya2UVAZ94XkZLmpNNcRUQkk95iEhGRTBogREQkkwYIERHJpAFCREQyaYAQEZFMGiBERCSTBggREcn0/wHTs6MgnWP0JwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assume X_all is your instances x 2 feature list and Y_all is your list of gold labels\n",
    "X1_comb = X_all_2d_combined_diff[:,0]  # extract the first feature from X_all\n",
    "X2_comb = X_all_2d_combined_diff[:,1]  # extract the second feature from X_all\n",
    "\n",
    "# create a scatter plot with two different markers for the two classes\n",
    "plt.scatter(X1_comb[y_all==9], X2_comb[y_all==9], marker='o', color='blue', label='Class 9')\n",
    "plt.scatter(X1_comb[y_all==3], X2_comb[y_all==3], marker='s', color='red', label='Class 3')\n",
    "\n",
    "# set the labels for the x and y axes\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "# add a legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">Good that you tried a different feature function, but I am not sure if it is much better. Also its hard to see that some squares are plotted on top of circles. So maybe use a cross like the solution.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest mean descision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_mean(training_features, training_labels, test_features):\n",
    "    # Compute the means of each class in the training set\n",
    "    class3_mean = np.mean(training_features[np.argwhere(training_labels == -1)], axis=0)\n",
    "    class9_mean = np.mean(training_features[np.argwhere(training_labels == 1)], axis=0)\n",
    "    predicted_labels = []\n",
    "    \n",
    "    # Assign each test instance to the class with the closest mean\n",
    "    for i in range(len(test_features)):\n",
    "        test_instance = test_features[i]\n",
    "        dist1 = np.linalg.norm(test_instance - class3_mean)\n",
    "        dist2 = np.linalg.norm(test_instance - class9_mean)\n",
    "        if dist1 < dist2:\n",
    "            # Abbend -1 for class 3\n",
    "            predicted_labels.append(-1)\n",
    "        else:\n",
    "            # Abbend 1 for class 9\n",
    "            predicted_labels.append(1)\n",
    "    return np.array(predicted_labels), np.array([class3_mean, class9_mean])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">Looks correct</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation of the data\n",
    "X_train_2d = features2d(X_train)\n",
    "X_test_2d = features2d(X_test)\n",
    "X_train_2d_combined_diff = features2d_combined_diff(X_train)\n",
    "X_test_2d_combined_diff = features2d_combined_diff(X_test)\n",
    "y_train = np.where(y_train == 3, -1, np.where(y_train == 9, 1, y_train))\n",
    "y_test = np.where(y_test == 3, -1, np.where(y_test == 9, 1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.11981566820276497\n",
      "Test error: 0.15753424657534246\n",
      "Training error combined diff: 0.21658986175115208\n",
      "Test error combined diff: 0.273972602739726\n"
     ]
    }
   ],
   "source": [
    "# train the classifier and predict the labels for the test data\n",
    "predicted_labels_test, class_means = nearest_mean(X_train_2d, y_train, X_test_2d)\n",
    "predicted_labels_train = nearest_mean(X_train_2d, y_train, X_train_2d)[0]\n",
    "predicted_labels_test_comb ,class_means_comb =  nearest_mean(X_train_2d_combined_diff, y_train, X_test_2d_combined_diff)\n",
    "predicted_labels_train_comb = nearest_mean(X_train_2d_combined_diff, y_train, X_train_2d_combined_diff)[0]\n",
    "\n",
    "# calculate the errors on the training and test data\n",
    "train_error = np.mean(predicted_labels_train != y_train)\n",
    "test_error = np.mean(predicted_labels_test != y_test)\n",
    "\n",
    "train_error_combined_diff = np.mean(predicted_labels_train_comb != y_train)\n",
    "test_error_combined_diff = np.mean(predicted_labels_test_comb != y_test)\n",
    "\n",
    "# print the errors\n",
    "print(f\"Training error: {train_error}\")\n",
    "print(f\"Test error: {test_error}\")\n",
    "\n",
    "print(f\"Training error combined diff: {train_error_combined_diff}\")\n",
    "print(f\"Test error combined diff: {test_error_combined_diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">Same as the solution.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descision boundary implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_static_weights(x_i, beta, bias):\n",
    "    y_pred = np.sign(np.dot(x_i, beta) + bias)\n",
    "    return y_pred\n",
    "\n",
    "def classify_with_boundary(features, beta, bias):\n",
    "    # Compute the means of each class in the training set\n",
    "    predicted_labels = [int(predict_static_weights(x_i, beta, bias)) for x_i in features]\n",
    "    \n",
    "    return np.array(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.12442396313364056\n",
      "Test error: 0.1643835616438356\n",
      "Training error combined diff: 0.25806451612903225\n",
      "Test error combined diff: 0.2465753424657534\n"
     ]
    }
   ],
   "source": [
    "# define a more sophisticated decision boundary using beta (β) and b\n",
    "beta = np.array([1, -1])\n",
    "b = -0.5\n",
    "\n",
    "# apply the decision boundary to the 2D features\n",
    "train_prediction = classify_with_boundary(X_train_2d, beta, b)\n",
    "test_prediction = classify_with_boundary(X_test_2d, beta, b)\n",
    "train_prediction_comb = classify_with_boundary(X_train_2d_combined_diff, beta, b)\n",
    "test_prediction_comb = classify_with_boundary(X_test_2d_combined_diff, beta, b)\n",
    "\n",
    "# calculate the errors on the training and test data\n",
    "train_error_b = np.mean(train_prediction != y_train)\n",
    "test_error_b = np.mean(test_prediction != y_test)\n",
    "train_error_b_comb = np.mean(train_prediction_comb != y_train)\n",
    "test_error_b_comb = np.mean(test_prediction_comb != y_test)\n",
    "\n",
    "# print the errors\n",
    "print(f\"Training error: {train_error_b}\")\n",
    "print(f\"Test error: {test_error_b}\")\n",
    "print(f\"Training error combined diff: {train_error_b_comb}\")\n",
    "print(f\"Test error combined diff: {test_error_b_comb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">Same as the solution </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(features, labels):\n",
    "    # Step 1: Find maximum values for each dimension\n",
    "    max_x = np.max(features[0])\n",
    "    max_y = np.max(features[1])\n",
    "\n",
    "    # Step 2: Create an empty matrix\n",
    "    matrix = np.zeros((int(max_x + 1), int(max_y + 1)))\n",
    "\n",
    "    # Step 3-4: Assign labels to matrix elements\n",
    "    for idx, feature in enumerate(features):\n",
    "        matrix[int(feature[0]-1), int(feature[1]-1)] = labels[idx]\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a matrix for grid/image\n",
    "predicted_labels_test_matrix = to_matrix(X_test_2d, predicted_labels_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "X1 = X_test_2d[:,0]\n",
    "X2 = X_test_2d[:,1]\n",
    "\n",
    "# Plot feature test data in the 2D space as overlay\n",
    "colors = ['blue' if label == -1 else 'red' for label in y_test.flatten()]\n",
    "ax.scatter(X1, X2, c=colors)\n",
    "\n",
    "# Plot class means as overlay\n",
    "ax.scatter(class_means[0][0][1], class_means[0][0][0], marker='x', color='red', label='Class 3 mean')\n",
    "ax.scatter(class_means[1][0][1], class_means[1][0][0], marker='x', color='blue', label='Class 9 mean')\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_title('Decision Regions')\n",
    "\n",
    "# Display the image and scatter overlay\n",
    "ax.imshow(predicted_labels_test_matrix)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">Something went wrong here. I am not sure what the to_matrix function is supposed to do. But the idea was to calculate the distance to each mean for a point. If it is closer to the mean of 3 it is in the decision region of 3. Since your means are never used this can not work.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30.96398703 -17.43960147]\n",
      " [-17.43960147  32.79595494]]\n",
      "[[ 46.79606397 -31.12277042]\n",
      " [-31.12277042  44.50320441]]\n"
     ]
    }
   ],
   "source": [
    "def fit_lda(training_features, training_labels):\n",
    "    # compute the class means\n",
    "    class_means = []\n",
    "    \n",
    "    for label in np.unique(training_labels):\n",
    "        class_means.append(np.mean(training_features[training_labels == label], axis=0))\n",
    "        \n",
    "    class_means = np.array(class_means)\n",
    "    \n",
    "    # compute the covariance matrix\n",
    "    covmat = np.cov(training_features.T)\n",
    "    print(covmat)\n",
    "    \n",
    "    # code from the sample solution\n",
    "    global_feat = training_features - np.array(class_means)[training_labels]\n",
    "    cov = np.dot(global_feat.T, global_feat)/training_features.shape[0]\n",
    "    print(cov)\n",
    "    \n",
    "    # compute the prior probabilities\n",
    "    p = []\n",
    "    for label in np.unique(training_labels):\n",
    "        p.append(len(training_features[np.argwhere(training_labels == label)]) / len(training_labels))\n",
    "        \n",
    "    return class_means, covmat, p\n",
    "\n",
    "filtered_X_train = X_train[:, np.var(X_train, axis=0) > 0.001]\n",
    "\n",
    "mu, covmat, p = fit_lda(X_train_2d, y_train)\n",
    "mu2, covmat2, p2 = fit_lda(filtered_X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">Using np.argwhere is unnecessary. Also using the np.cov function results in different covariance matrix than using the code from the solution.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_N_one = len(y_test[np.argwhere(y_test == 1)])\n",
    "len_N_neg_one = len(y_test[np.argwhere(y_test == -1)])\n",
    "\n",
    "def predict_lda(mu, covmat, p, test_features):\n",
    "    predicted_labels = []\n",
    "    for x_i in test_features:\n",
    "        beta = np.dot(np.linalg.inv(covmat), (mu[0] - mu[1]).T)\n",
    "        bias = -0.5 * np.dot(mu[0] - mu[1], beta) + np.log(len_N_one / len_N_neg_one)\n",
    "        predicted_labels.append(np.sign(np.dot(x_i, beta) + bias))\n",
    "        \n",
    "    return predicted_labels\n",
    "\n",
    "pred_labels_2d = predict_lda(mu, covmat, p, X_test_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">Calculating beta and b in the for loop is unnecessary and ineffecient. You could use the priors p instead of calculating len_N_one. You could calculate the error of the predicted labels here for the training and test set. This could also be done for the case with all pixels.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a matrix for grid/image\n",
    "predicted_labels_test_matrix = to_matrix(X_test_2d, pred_labels_2d)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "X1 = X_train_2d[:,0]\n",
    "X2 = X_train_2d[:,1]\n",
    "\n",
    "# Plot feature test data in the 2D space as overlay\n",
    "colors = ['blue' if label == -1 else 'red' for label in y_train.flatten()]\n",
    "ax.scatter(X1, X2, c=colors)\n",
    "\n",
    "# Plot class means as overlay\n",
    "ax.scatter(class_means[0][0][1], class_means[0][0][0], marker='x', color='red', label='Class 3 mean')\n",
    "ax.scatter(class_means[1][0][1], class_means[1][0][0], marker='x', color='blue', label='Class 9 mean')\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_title('Decision Regions')\n",
    "\n",
    "# Display the image and scatter overlay\n",
    "ax.imshow(predicted_labels_test_matrix)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">Same as before the to_matrix seems to be wrong.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == 1 and y_pred[i] == 1:\n",
    "            tp += 1\n",
    "        elif y_true[i] == 0 and y_pred[i] == 0:\n",
    "            tn += 1\n",
    "    return (tp + tn) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets import load_digits\n",
    "#from sklearn.model_selection import KFold\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "#import numpy as np\n",
    "#\n",
    "#digits = load_digits()\n",
    "#\n",
    "## Load your feature data and corresponding labels\n",
    "#X = X_all_2d\n",
    "#y_true = digits.target[(digits.target == 3) | (digits.target == 9)]\n",
    "#mu, covmat, p = fit_lda(X_all_2d, y_true)\n",
    "#y_pred = predict_lda(mu, covmat, p, X_all_2d)\n",
    "#\n",
    "## Define the number of folds for cross-validation\n",
    "#kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#\n",
    "## Iterate over the folds and compute the performance metrics\n",
    "#accuracy_scores = []\n",
    "#\n",
    "#for train_idx, test_idx in kfold.split(X):\n",
    "#    X_train, X_test = X[train_idx], X[test_idx]\n",
    "#    y_train, y_test = y_true[train_idx], y_pred[test_idx]\n",
    "#    \n",
    "#    # Train the classifier on the training data\n",
    "#    mu, covmat, p = fit_lda(X_train, y_train)\n",
    "#    \n",
    "#    # Evaluate the classifier on the test data\n",
    "#    y_pred_test = predict_lda(mu, covmat, p, X_test)\n",
    "#    \n",
    "#    # Compute the performance metrics\n",
    "#    accuracy_scores.append(accuracy_score(y_test, y_pred_test))\n",
    "#\n",
    "## Print the mean and standard deviation of the performance metrics\n",
    "#print('Accuracy:', np.mean(accuracy_scores), np.std(accuracy_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:\n",
    "bold\">I assume this was not finished</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 15., 16., 15.,  1.,  0.,  0., 10., 16., 11.,  8.,\n",
       "       16.,  5.,  0.,  0., 12., 10.,  1., 10., 15.,  1.,  0.,  0.,  0.,\n",
       "        0.,  8., 16., 11.,  1.,  0.,  0.,  0.,  0.,  1., 10., 16., 10.,\n",
       "        0.,  0.,  0.,  0.,  2.,  0.,  7., 16.,  0.,  0.,  0.,  8., 13.,\n",
       "        5., 15., 12.,  0.,  0.,  0.,  5., 15., 16., 14.,  3.,  0.])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217,)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_svm_labels(y):\n",
    "    y_svm = y.copy()\n",
    "    y_svm = np.where(y_svm==3, -1, np.where(y_svm==9, 1, y_svm))\n",
    "    return y_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change labels to -1 and 1 for convenience\n",
    "y_svm_train = create_svm_labels(y_train)\n",
    "y_svm_test = create_svm_labels(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svm(training_features, training_labels, reg_lambda=100, learning_rate=0.002, max_epochs=100, min_error_rate=0.005):\n",
    "    beta = np.random.normal(size=training_features.shape[1])\n",
    "    b = 0\n",
    "    N = len(training_labels)\n",
    "    regularization_factor = reg_lambda / N\n",
    "\n",
    "    prev_error_rate = float('inf')\n",
    "    consecutive_count = 0\n",
    "    losses = []\n",
    "    error_rates = []\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        error_count = 0\n",
    "        loss = 0\n",
    "\n",
    "        for i, X in enumerate(training_features):\n",
    "            beta_update, b_update = 0, 0\n",
    "            if training_labels[i] * (np.dot(X, beta) + b) < 1:\n",
    "                beta_update = beta - regularization_factor * training_labels[i] * X\n",
    "                b_update = - training_labels[i]\n",
    "                error_count += 1\n",
    "                loss += 1 - training_labels[i] * (np.dot(X, beta) + b)\n",
    "            else:\n",
    "                beta_update = regularization_factor * beta\n",
    "            beta-= learning_rate * beta_update\n",
    "            b += learning_rate * b_update\n",
    "\n",
    "        error_rate = error_count / N\n",
    "        losses.append(loss)\n",
    "        error_rates.append(error_rate)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Error rate: {error_rate}\")\n",
    "\n",
    "        if error_rate <= min_error_rate:\n",
    "            print(\"SVM Converged!\")\n",
    "            break\n",
    "        elif error_rate >= prev_error_rate:\n",
    "            consecutive_count += 1\n",
    "            if consecutive_count >= 3:\n",
    "                learning_rate /= 10\n",
    "                print(f\"Adjusting learning rate to {learning_rate}\")\n",
    "                consecutive_count = 0\n",
    "        else:\n",
    "            consecutive_count = 0\n",
    "        prev_error_rate = error_rate\n",
    "\n",
    "    return beta, b, losses, error_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Error rate: 0.47465437788018433\n",
      "Epoch 2, Error rate: 0.30414746543778803\n",
      "Epoch 3, Error rate: 0.16589861751152074\n",
      "Epoch 4, Error rate: 0.1336405529953917\n",
      "Epoch 5, Error rate: 0.09216589861751152\n",
      "Epoch 6, Error rate: 0.055299539170506916\n",
      "Epoch 7, Error rate: 0.03686635944700461\n",
      "Epoch 8, Error rate: 0.059907834101382486\n",
      "Epoch 9, Error rate: 0.04608294930875576\n",
      "Epoch 10, Error rate: 0.04608294930875576\n",
      "Epoch 11, Error rate: 0.07373271889400922\n",
      "Epoch 12, Error rate: 0.03225806451612903\n",
      "Epoch 13, Error rate: 0.07373271889400922\n",
      "Epoch 14, Error rate: 0.03686635944700461\n",
      "Epoch 15, Error rate: 0.055299539170506916\n",
      "Epoch 16, Error rate: 0.055299539170506916\n",
      "Epoch 17, Error rate: 0.09216589861751152\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 18, Error rate: 0.05069124423963134\n",
      "Epoch 19, Error rate: 0.027649769585253458\n",
      "Epoch 20, Error rate: 0.027649769585253458\n",
      "Epoch 21, Error rate: 0.02304147465437788\n",
      "Epoch 22, Error rate: 0.018433179723502304\n",
      "Epoch 23, Error rate: 0.02304147465437788\n",
      "Epoch 24, Error rate: 0.027649769585253458\n",
      "Epoch 25, Error rate: 0.02304147465437788\n",
      "Epoch 26, Error rate: 0.018433179723502304\n",
      "Epoch 27, Error rate: 0.018433179723502304\n",
      "Epoch 28, Error rate: 0.02304147465437788\n",
      "Epoch 29, Error rate: 0.03225806451612903\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 30, Error rate: 0.05069124423963134\n",
      "Epoch 31, Error rate: 0.03225806451612903\n",
      "Epoch 32, Error rate: 0.03225806451612903\n",
      "Epoch 33, Error rate: 0.027649769585253458\n",
      "Epoch 34, Error rate: 0.027649769585253458\n",
      "Epoch 35, Error rate: 0.03225806451612903\n",
      "Epoch 36, Error rate: 0.027649769585253458\n",
      "Epoch 37, Error rate: 0.027649769585253458\n",
      "Epoch 38, Error rate: 0.03225806451612903\n",
      "Epoch 39, Error rate: 0.027649769585253458\n",
      "Epoch 40, Error rate: 0.03225806451612903\n",
      "Epoch 41, Error rate: 0.027649769585253458\n",
      "Epoch 42, Error rate: 0.027649769585253458\n",
      "Epoch 43, Error rate: 0.027649769585253458\n",
      "Epoch 44, Error rate: 0.03225806451612903\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 45, Error rate: 0.027649769585253458\n",
      "Epoch 46, Error rate: 0.027649769585253458\n",
      "Epoch 47, Error rate: 0.027649769585253458\n",
      "Epoch 48, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 49, Error rate: 0.027649769585253458\n",
      "Epoch 50, Error rate: 0.027649769585253458\n",
      "Epoch 51, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 52, Error rate: 0.027649769585253458\n",
      "Epoch 53, Error rate: 0.027649769585253458\n",
      "Epoch 54, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 55, Error rate: 0.027649769585253458\n",
      "Epoch 56, Error rate: 0.027649769585253458\n",
      "Epoch 57, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 58, Error rate: 0.027649769585253458\n",
      "Epoch 59, Error rate: 0.027649769585253458\n",
      "Epoch 60, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 61, Error rate: 0.027649769585253458\n",
      "Epoch 62, Error rate: 0.027649769585253458\n",
      "Epoch 63, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 64, Error rate: 0.027649769585253458\n",
      "Epoch 65, Error rate: 0.027649769585253458\n",
      "Epoch 66, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 67, Error rate: 0.027649769585253458\n",
      "Epoch 68, Error rate: 0.027649769585253458\n",
      "Epoch 69, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 70, Error rate: 0.027649769585253458\n",
      "Epoch 71, Error rate: 0.027649769585253458\n",
      "Epoch 72, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 73, Error rate: 0.027649769585253458\n",
      "Epoch 74, Error rate: 0.027649769585253458\n",
      "Epoch 75, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 76, Error rate: 0.027649769585253458\n",
      "Epoch 77, Error rate: 0.027649769585253458\n",
      "Epoch 78, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 79, Error rate: 0.027649769585253458\n",
      "Epoch 80, Error rate: 0.027649769585253458\n",
      "Epoch 81, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 82, Error rate: 0.027649769585253458\n",
      "Epoch 83, Error rate: 0.027649769585253458\n",
      "Epoch 84, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 85, Error rate: 0.027649769585253458\n",
      "Epoch 86, Error rate: 0.027649769585253458\n",
      "Epoch 87, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 88, Error rate: 0.027649769585253458\n",
      "Epoch 89, Error rate: 0.027649769585253458\n",
      "Epoch 90, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 91, Error rate: 0.027649769585253458\n",
      "Epoch 92, Error rate: 0.027649769585253458\n",
      "Epoch 93, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 94, Error rate: 0.027649769585253458\n",
      "Epoch 95, Error rate: 0.027649769585253458\n",
      "Epoch 96, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 97, Error rate: 0.027649769585253458\n",
      "Epoch 98, Error rate: 0.027649769585253458\n",
      "Epoch 99, Error rate: 0.027649769585253458\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 100, Error rate: 0.027649769585253458\n"
     ]
    }
   ],
   "source": [
    "beta, b, losses, error_rates = fit_svm(X_train, y_svm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(losses, training_errors):\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.plot(losses, color='tab:red', label='Loss')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    ax2.set_ylabel('Training Error')\n",
    "    ax2.plot(training_errors, color='tab:blue', label='Training Error')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # add legend\n",
    "    h1, l1 = ax1.get_legend_handles_labels()\n",
    "    h2, l2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(h1+h2, l1+l2, loc='upper right')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training(losses, error_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validate_svm(training_features, training_labels):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    best_reg_lambda = None\n",
    "    best_error_rate = float('inf')\n",
    "\n",
    "    for reg_lambda in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        error_rate_sum = 0\n",
    "\n",
    "        for train_index, test_index in kf.split(training_features):\n",
    "            X_train, X_test = training_features[train_index], training_features[test_index]\n",
    "            y_train, y_test = training_labels[train_index], training_labels[test_index]\n",
    "            beta, b, losses, error_rates = fit_svm(X_train, y_train, reg_lambda=reg_lambda)\n",
    "            error_count = 0\n",
    "\n",
    "            for i, X in enumerate(X_test):\n",
    "                if y_test[i] * (np.dot(X, beta) + b) < 1:\n",
    "                    error_count += 1\n",
    "            error_rate = error_count / len(y_test)\n",
    "            error_rate_sum += error_rate\n",
    "\n",
    "        avg_error_rate = error_rate_sum / 5\n",
    "        print(f\"Reg lambda: {reg_lambda}, Average error rate: {avg_error_rate}\")\n",
    "\n",
    "        if avg_error_rate < best_error_rate:\n",
    "            best_error_rate = avg_error_rate\n",
    "            best_reg_lambda = reg_lambda\n",
    "\n",
    "    print(f\"Best regularization factor: {best_reg_lambda}, Best error rate: {best_error_rate}\")\n",
    "    return best_reg_lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Error rate: 0.2832369942196532\n",
      "Epoch 2, Error rate: 0.2832369942196532\n",
      "Epoch 3, Error rate: 0.28901734104046245\n",
      "Epoch 4, Error rate: 0.28901734104046245\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.28901734104046245\n",
      "Epoch 6, Error rate: 0.2947976878612717\n",
      "Epoch 7, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.30057803468208094\n",
      "Epoch 9, Error rate: 0.30057803468208094\n",
      "Epoch 10, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.30057803468208094\n",
      "Epoch 12, Error rate: 0.30057803468208094\n",
      "Epoch 13, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.30057803468208094\n",
      "Epoch 15, Error rate: 0.30057803468208094\n",
      "Epoch 16, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.30057803468208094\n",
      "Epoch 18, Error rate: 0.30057803468208094\n",
      "Epoch 19, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.30057803468208094\n",
      "Epoch 21, Error rate: 0.30057803468208094\n",
      "Epoch 22, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.30057803468208094\n",
      "Epoch 24, Error rate: 0.30057803468208094\n",
      "Epoch 25, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.30057803468208094\n",
      "Epoch 27, Error rate: 0.30057803468208094\n",
      "Epoch 28, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.30057803468208094\n",
      "Epoch 30, Error rate: 0.30057803468208094\n",
      "Epoch 31, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.30057803468208094\n",
      "Epoch 33, Error rate: 0.30057803468208094\n",
      "Epoch 34, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.30057803468208094\n",
      "Epoch 36, Error rate: 0.30057803468208094\n",
      "Epoch 37, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.30057803468208094\n",
      "Epoch 39, Error rate: 0.30057803468208094\n",
      "Epoch 40, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 41, Error rate: 0.30057803468208094\n",
      "Epoch 42, Error rate: 0.30057803468208094\n",
      "Epoch 43, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.30057803468208094\n",
      "Epoch 45, Error rate: 0.30057803468208094\n",
      "Epoch 46, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.30057803468208094\n",
      "Epoch 48, Error rate: 0.30057803468208094\n",
      "Epoch 49, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.30057803468208094\n",
      "Epoch 51, Error rate: 0.30057803468208094\n",
      "Epoch 52, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.30057803468208094\n",
      "Epoch 54, Error rate: 0.30057803468208094\n",
      "Epoch 55, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.30057803468208094\n",
      "Epoch 57, Error rate: 0.30057803468208094\n",
      "Epoch 58, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.30057803468208094\n",
      "Epoch 60, Error rate: 0.30057803468208094\n",
      "Epoch 61, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.30057803468208094\n",
      "Epoch 63, Error rate: 0.30057803468208094\n",
      "Epoch 64, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.30057803468208094\n",
      "Epoch 66, Error rate: 0.30057803468208094\n",
      "Epoch 67, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.30057803468208094\n",
      "Epoch 69, Error rate: 0.30057803468208094\n",
      "Epoch 70, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.30057803468208094\n",
      "Epoch 72, Error rate: 0.30057803468208094\n",
      "Epoch 73, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.30057803468208094\n",
      "Epoch 75, Error rate: 0.30057803468208094\n",
      "Epoch 76, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.30057803468208094\n",
      "Epoch 78, Error rate: 0.30057803468208094\n",
      "Epoch 79, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.30057803468208094\n",
      "Epoch 81, Error rate: 0.30057803468208094\n",
      "Epoch 82, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.30057803468208094\n",
      "Epoch 84, Error rate: 0.30057803468208094\n",
      "Epoch 85, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.30057803468208094\n",
      "Epoch 87, Error rate: 0.30057803468208094\n",
      "Epoch 88, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.30057803468208094\n",
      "Epoch 90, Error rate: 0.30057803468208094\n",
      "Epoch 91, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 92, Error rate: 0.30057803468208094\n",
      "Epoch 93, Error rate: 0.30057803468208094\n",
      "Epoch 94, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.30057803468208094\n",
      "Epoch 96, Error rate: 0.30057803468208094\n",
      "Epoch 97, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.30057803468208094\n",
      "Epoch 99, Error rate: 0.30057803468208094\n",
      "Epoch 100, Error rate: 0.30057803468208094\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Epoch 1, Error rate: 0.5260115606936416\n",
      "Epoch 2, Error rate: 0.5260115606936416\n",
      "Epoch 3, Error rate: 0.5260115606936416\n",
      "Epoch 4, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.5260115606936416\n",
      "Epoch 6, Error rate: 0.5260115606936416\n",
      "Epoch 7, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.5260115606936416\n",
      "Epoch 9, Error rate: 0.5260115606936416\n",
      "Epoch 10, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.5260115606936416\n",
      "Epoch 12, Error rate: 0.5260115606936416\n",
      "Epoch 13, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.5260115606936416\n",
      "Epoch 15, Error rate: 0.5260115606936416\n",
      "Epoch 16, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.5260115606936416\n",
      "Epoch 18, Error rate: 0.5260115606936416\n",
      "Epoch 19, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.5260115606936416\n",
      "Epoch 21, Error rate: 0.5260115606936416\n",
      "Epoch 22, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.5260115606936416\n",
      "Epoch 24, Error rate: 0.5260115606936416\n",
      "Epoch 25, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.5260115606936416\n",
      "Epoch 27, Error rate: 0.5260115606936416\n",
      "Epoch 28, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.5260115606936416\n",
      "Epoch 30, Error rate: 0.5260115606936416\n",
      "Epoch 31, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.5260115606936416\n",
      "Epoch 33, Error rate: 0.5260115606936416\n",
      "Epoch 34, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.5260115606936416\n",
      "Epoch 36, Error rate: 0.5260115606936416\n",
      "Epoch 37, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.5260115606936416\n",
      "Epoch 39, Error rate: 0.5260115606936416\n",
      "Epoch 40, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 41, Error rate: 0.5260115606936416\n",
      "Epoch 42, Error rate: 0.5260115606936416\n",
      "Epoch 43, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.5260115606936416\n",
      "Epoch 45, Error rate: 0.5260115606936416\n",
      "Epoch 46, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.5260115606936416\n",
      "Epoch 48, Error rate: 0.5260115606936416\n",
      "Epoch 49, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.5260115606936416\n",
      "Epoch 51, Error rate: 0.5260115606936416\n",
      "Epoch 52, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.5260115606936416\n",
      "Epoch 54, Error rate: 0.5260115606936416\n",
      "Epoch 55, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.5260115606936416\n",
      "Epoch 57, Error rate: 0.5260115606936416\n",
      "Epoch 58, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.5260115606936416\n",
      "Epoch 60, Error rate: 0.5260115606936416\n",
      "Epoch 61, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.5260115606936416\n",
      "Epoch 63, Error rate: 0.5260115606936416\n",
      "Epoch 64, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.5260115606936416\n",
      "Epoch 66, Error rate: 0.5260115606936416\n",
      "Epoch 67, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.5260115606936416\n",
      "Epoch 69, Error rate: 0.5260115606936416\n",
      "Epoch 70, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.5260115606936416\n",
      "Epoch 72, Error rate: 0.5260115606936416\n",
      "Epoch 73, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.5260115606936416\n",
      "Epoch 75, Error rate: 0.5260115606936416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.5260115606936416\n",
      "Epoch 78, Error rate: 0.5260115606936416\n",
      "Epoch 79, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.5260115606936416\n",
      "Epoch 81, Error rate: 0.5260115606936416\n",
      "Epoch 82, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.5260115606936416\n",
      "Epoch 84, Error rate: 0.5260115606936416\n",
      "Epoch 85, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.5260115606936416\n",
      "Epoch 87, Error rate: 0.5260115606936416\n",
      "Epoch 88, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.5260115606936416\n",
      "Epoch 90, Error rate: 0.5260115606936416\n",
      "Epoch 91, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 92, Error rate: 0.5260115606936416\n",
      "Epoch 93, Error rate: 0.5260115606936416\n",
      "Epoch 94, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.5260115606936416\n",
      "Epoch 96, Error rate: 0.5260115606936416\n",
      "Epoch 97, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.5260115606936416\n",
      "Epoch 99, Error rate: 0.5260115606936416\n",
      "Epoch 100, Error rate: 0.5260115606936416\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Epoch 1, Error rate: 0.3850574712643678\n",
      "Epoch 2, Error rate: 0.3850574712643678\n",
      "Epoch 3, Error rate: 0.39080459770114945\n",
      "Epoch 4, Error rate: 0.39080459770114945\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.39655172413793105\n",
      "Epoch 6, Error rate: 0.39655172413793105\n",
      "Epoch 7, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.39655172413793105\n",
      "Epoch 9, Error rate: 0.39655172413793105\n",
      "Epoch 10, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.39655172413793105\n",
      "Epoch 12, Error rate: 0.39655172413793105\n",
      "Epoch 13, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.39655172413793105\n",
      "Epoch 15, Error rate: 0.39655172413793105\n",
      "Epoch 16, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.39655172413793105\n",
      "Epoch 18, Error rate: 0.39655172413793105\n",
      "Epoch 19, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.39655172413793105\n",
      "Epoch 21, Error rate: 0.39655172413793105\n",
      "Epoch 22, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.39655172413793105\n",
      "Epoch 24, Error rate: 0.39655172413793105\n",
      "Epoch 25, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.39655172413793105\n",
      "Epoch 27, Error rate: 0.39655172413793105\n",
      "Epoch 28, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.39655172413793105\n",
      "Epoch 30, Error rate: 0.39655172413793105\n",
      "Epoch 31, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.39655172413793105\n",
      "Epoch 33, Error rate: 0.39655172413793105\n",
      "Epoch 34, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.39655172413793105\n",
      "Epoch 36, Error rate: 0.39655172413793105\n",
      "Epoch 37, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.39655172413793105\n",
      "Epoch 39, Error rate: 0.39655172413793105\n",
      "Epoch 40, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 41, Error rate: 0.39655172413793105\n",
      "Epoch 42, Error rate: 0.39655172413793105\n",
      "Epoch 43, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.39655172413793105\n",
      "Epoch 45, Error rate: 0.39655172413793105\n",
      "Epoch 46, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.39655172413793105\n",
      "Epoch 48, Error rate: 0.39655172413793105\n",
      "Epoch 49, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.39655172413793105\n",
      "Epoch 51, Error rate: 0.39655172413793105\n",
      "Epoch 52, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.39655172413793105\n",
      "Epoch 54, Error rate: 0.39655172413793105\n",
      "Epoch 55, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.39655172413793105\n",
      "Epoch 57, Error rate: 0.39655172413793105\n",
      "Epoch 58, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.39655172413793105\n",
      "Epoch 60, Error rate: 0.39655172413793105\n",
      "Epoch 61, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.39655172413793105\n",
      "Epoch 63, Error rate: 0.39655172413793105\n",
      "Epoch 64, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.39655172413793105\n",
      "Epoch 66, Error rate: 0.39655172413793105\n",
      "Epoch 67, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.39655172413793105\n",
      "Epoch 69, Error rate: 0.39655172413793105\n",
      "Epoch 70, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.39655172413793105\n",
      "Epoch 72, Error rate: 0.39655172413793105\n",
      "Epoch 73, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.39655172413793105\n",
      "Epoch 75, Error rate: 0.39655172413793105\n",
      "Epoch 76, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.39655172413793105\n",
      "Epoch 78, Error rate: 0.39655172413793105\n",
      "Epoch 79, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.39655172413793105\n",
      "Epoch 81, Error rate: 0.39655172413793105\n",
      "Epoch 82, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.39655172413793105\n",
      "Epoch 84, Error rate: 0.39655172413793105\n",
      "Epoch 85, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.39655172413793105\n",
      "Epoch 87, Error rate: 0.39655172413793105\n",
      "Epoch 88, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.39655172413793105\n",
      "Epoch 90, Error rate: 0.39655172413793105\n",
      "Epoch 91, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 92, Error rate: 0.39655172413793105\n",
      "Epoch 93, Error rate: 0.39655172413793105\n",
      "Epoch 94, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.39655172413793105\n",
      "Epoch 96, Error rate: 0.39655172413793105\n",
      "Epoch 97, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.39655172413793105\n",
      "Epoch 99, Error rate: 0.39655172413793105\n",
      "Epoch 100, Error rate: 0.39655172413793105\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Epoch 1, Error rate: 0.5287356321839081\n",
      "Epoch 2, Error rate: 0.5287356321839081\n",
      "Epoch 3, Error rate: 0.5287356321839081\n",
      "Epoch 4, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.5287356321839081\n",
      "Epoch 6, Error rate: 0.5287356321839081\n",
      "Epoch 7, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.5287356321839081\n",
      "Epoch 9, Error rate: 0.5287356321839081\n",
      "Epoch 10, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.5287356321839081\n",
      "Epoch 12, Error rate: 0.5287356321839081\n",
      "Epoch 13, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.5287356321839081\n",
      "Epoch 15, Error rate: 0.5287356321839081\n",
      "Epoch 16, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.5287356321839081\n",
      "Epoch 18, Error rate: 0.5287356321839081\n",
      "Epoch 19, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.5287356321839081\n",
      "Epoch 21, Error rate: 0.5287356321839081\n",
      "Epoch 22, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.5287356321839081\n",
      "Epoch 24, Error rate: 0.5287356321839081\n",
      "Epoch 25, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.5287356321839081\n",
      "Epoch 27, Error rate: 0.5287356321839081\n",
      "Epoch 28, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.5287356321839081\n",
      "Epoch 30, Error rate: 0.5287356321839081\n",
      "Epoch 31, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.5287356321839081\n",
      "Epoch 33, Error rate: 0.5287356321839081\n",
      "Epoch 34, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.5287356321839081\n",
      "Epoch 36, Error rate: 0.5287356321839081\n",
      "Epoch 37, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.5287356321839081\n",
      "Epoch 39, Error rate: 0.5287356321839081\n",
      "Epoch 40, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 41, Error rate: 0.5287356321839081\n",
      "Epoch 42, Error rate: 0.5287356321839081\n",
      "Epoch 43, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.5287356321839081\n",
      "Epoch 45, Error rate: 0.5287356321839081\n",
      "Epoch 46, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.5287356321839081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Error rate: 0.5287356321839081\n",
      "Epoch 49, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.5287356321839081\n",
      "Epoch 51, Error rate: 0.5287356321839081\n",
      "Epoch 52, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.5287356321839081\n",
      "Epoch 54, Error rate: 0.5287356321839081\n",
      "Epoch 55, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.5287356321839081\n",
      "Epoch 57, Error rate: 0.5287356321839081\n",
      "Epoch 58, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.5287356321839081\n",
      "Epoch 60, Error rate: 0.5287356321839081\n",
      "Epoch 61, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.5287356321839081\n",
      "Epoch 63, Error rate: 0.5287356321839081\n",
      "Epoch 64, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.5287356321839081\n",
      "Epoch 66, Error rate: 0.5287356321839081\n",
      "Epoch 67, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.5287356321839081\n",
      "Epoch 69, Error rate: 0.5287356321839081\n",
      "Epoch 70, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.5287356321839081\n",
      "Epoch 72, Error rate: 0.5287356321839081\n",
      "Epoch 73, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.5287356321839081\n",
      "Epoch 75, Error rate: 0.5287356321839081\n",
      "Epoch 76, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.5287356321839081\n",
      "Epoch 78, Error rate: 0.5287356321839081\n",
      "Epoch 79, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.5287356321839081\n",
      "Epoch 81, Error rate: 0.5287356321839081\n",
      "Epoch 82, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.5287356321839081\n",
      "Epoch 84, Error rate: 0.5287356321839081\n",
      "Epoch 85, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.5287356321839081\n",
      "Epoch 87, Error rate: 0.5287356321839081\n",
      "Epoch 88, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.5287356321839081\n",
      "Epoch 90, Error rate: 0.5287356321839081\n",
      "Epoch 91, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 92, Error rate: 0.5287356321839081\n",
      "Epoch 93, Error rate: 0.5287356321839081\n",
      "Epoch 94, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.5287356321839081\n",
      "Epoch 96, Error rate: 0.5287356321839081\n",
      "Epoch 97, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.5287356321839081\n",
      "Epoch 99, Error rate: 0.5287356321839081\n",
      "Epoch 100, Error rate: 0.5287356321839081\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Epoch 1, Error rate: 0.5344827586206896\n",
      "Epoch 2, Error rate: 0.5344827586206896\n",
      "Epoch 3, Error rate: 0.5344827586206896\n",
      "Epoch 4, Error rate: 0.5344827586206896\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.5402298850574713\n",
      "Epoch 6, Error rate: 0.5402298850574713\n",
      "Epoch 7, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.5402298850574713\n",
      "Epoch 9, Error rate: 0.5402298850574713\n",
      "Epoch 10, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.5402298850574713\n",
      "Epoch 12, Error rate: 0.5402298850574713\n",
      "Epoch 13, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.5402298850574713\n",
      "Epoch 15, Error rate: 0.5402298850574713\n",
      "Epoch 16, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.5402298850574713\n",
      "Epoch 18, Error rate: 0.5402298850574713\n",
      "Epoch 19, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.5402298850574713\n",
      "Epoch 21, Error rate: 0.5402298850574713\n",
      "Epoch 22, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.5402298850574713\n",
      "Epoch 24, Error rate: 0.5402298850574713\n",
      "Epoch 25, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.5402298850574713\n",
      "Epoch 27, Error rate: 0.5402298850574713\n",
      "Epoch 28, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.5402298850574713\n",
      "Epoch 30, Error rate: 0.5402298850574713\n",
      "Epoch 31, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.5402298850574713\n",
      "Epoch 33, Error rate: 0.5402298850574713\n",
      "Epoch 34, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.5402298850574713\n",
      "Epoch 36, Error rate: 0.5402298850574713\n",
      "Epoch 37, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.5402298850574713\n",
      "Epoch 39, Error rate: 0.5402298850574713\n",
      "Epoch 40, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 41, Error rate: 0.5402298850574713\n",
      "Epoch 42, Error rate: 0.5402298850574713\n",
      "Epoch 43, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.5402298850574713\n",
      "Epoch 45, Error rate: 0.5402298850574713\n",
      "Epoch 46, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.5402298850574713\n",
      "Epoch 48, Error rate: 0.5402298850574713\n",
      "Epoch 49, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.5402298850574713\n",
      "Epoch 51, Error rate: 0.5402298850574713\n",
      "Epoch 52, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.5402298850574713\n",
      "Epoch 54, Error rate: 0.5402298850574713\n",
      "Epoch 55, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.5402298850574713\n",
      "Epoch 57, Error rate: 0.5402298850574713\n",
      "Epoch 58, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.5402298850574713\n",
      "Epoch 60, Error rate: 0.5402298850574713\n",
      "Epoch 61, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.5402298850574713\n",
      "Epoch 63, Error rate: 0.5402298850574713\n",
      "Epoch 64, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.5402298850574713\n",
      "Epoch 66, Error rate: 0.5402298850574713\n",
      "Epoch 67, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.5402298850574713\n",
      "Epoch 69, Error rate: 0.5402298850574713\n",
      "Epoch 70, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.5402298850574713\n",
      "Epoch 72, Error rate: 0.5402298850574713\n",
      "Epoch 73, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.5402298850574713\n",
      "Epoch 75, Error rate: 0.5402298850574713\n",
      "Epoch 76, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.5402298850574713\n",
      "Epoch 78, Error rate: 0.5402298850574713\n",
      "Epoch 79, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.5402298850574713\n",
      "Epoch 81, Error rate: 0.5402298850574713\n",
      "Epoch 82, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.5402298850574713\n",
      "Epoch 84, Error rate: 0.5402298850574713\n",
      "Epoch 85, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.5402298850574713\n",
      "Epoch 87, Error rate: 0.5402298850574713\n",
      "Epoch 88, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.5402298850574713\n",
      "Epoch 90, Error rate: 0.5402298850574713\n",
      "Epoch 91, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 92, Error rate: 0.5402298850574713\n",
      "Epoch 93, Error rate: 0.5402298850574713\n",
      "Epoch 94, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.5402298850574713\n",
      "Epoch 96, Error rate: 0.5402298850574713\n",
      "Epoch 97, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.5402298850574713\n",
      "Epoch 99, Error rate: 0.5402298850574713\n",
      "Epoch 100, Error rate: 0.5402298850574713\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Reg lambda: 0.001, Average error rate: 0.4192389006342495\n",
      "Epoch 1, Error rate: 0.5375722543352601\n",
      "Epoch 2, Error rate: 0.5375722543352601\n",
      "Epoch 3, Error rate: 0.5433526011560693\n",
      "Epoch 4, Error rate: 0.5375722543352601\n",
      "Epoch 5, Error rate: 0.5375722543352601\n",
      "Epoch 6, Error rate: 0.5375722543352601\n",
      "Epoch 7, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 0.0002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Error rate: 0.5375722543352601\n",
      "Epoch 9, Error rate: 0.5375722543352601\n",
      "Epoch 10, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 11, Error rate: 0.5375722543352601\n",
      "Epoch 12, Error rate: 0.5375722543352601\n",
      "Epoch 13, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 14, Error rate: 0.5375722543352601\n",
      "Epoch 15, Error rate: 0.5375722543352601\n",
      "Epoch 16, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 17, Error rate: 0.5375722543352601\n",
      "Epoch 18, Error rate: 0.5375722543352601\n",
      "Epoch 19, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 20, Error rate: 0.5375722543352601\n",
      "Epoch 21, Error rate: 0.5375722543352601\n",
      "Epoch 22, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 23, Error rate: 0.5375722543352601\n",
      "Epoch 24, Error rate: 0.5375722543352601\n",
      "Epoch 25, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 26, Error rate: 0.5375722543352601\n",
      "Epoch 27, Error rate: 0.5375722543352601\n",
      "Epoch 28, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 29, Error rate: 0.5375722543352601\n",
      "Epoch 30, Error rate: 0.5375722543352601\n",
      "Epoch 31, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 32, Error rate: 0.5375722543352601\n",
      "Epoch 33, Error rate: 0.5375722543352601\n",
      "Epoch 34, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 35, Error rate: 0.5375722543352601\n",
      "Epoch 36, Error rate: 0.5375722543352601\n",
      "Epoch 37, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 38, Error rate: 0.5375722543352601\n",
      "Epoch 39, Error rate: 0.5375722543352601\n",
      "Epoch 40, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 41, Error rate: 0.5375722543352601\n",
      "Epoch 42, Error rate: 0.5375722543352601\n",
      "Epoch 43, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 44, Error rate: 0.5375722543352601\n",
      "Epoch 45, Error rate: 0.5375722543352601\n",
      "Epoch 46, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 47, Error rate: 0.5375722543352601\n",
      "Epoch 48, Error rate: 0.5375722543352601\n",
      "Epoch 49, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 50, Error rate: 0.5375722543352601\n",
      "Epoch 51, Error rate: 0.5375722543352601\n",
      "Epoch 52, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 53, Error rate: 0.5375722543352601\n",
      "Epoch 54, Error rate: 0.5375722543352601\n",
      "Epoch 55, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 56, Error rate: 0.5375722543352601\n",
      "Epoch 57, Error rate: 0.5375722543352601\n",
      "Epoch 58, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 59, Error rate: 0.5375722543352601\n",
      "Epoch 60, Error rate: 0.5375722543352601\n",
      "Epoch 61, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 62, Error rate: 0.5375722543352601\n",
      "Epoch 63, Error rate: 0.5375722543352601\n",
      "Epoch 64, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 65, Error rate: 0.5375722543352601\n",
      "Epoch 66, Error rate: 0.5375722543352601\n",
      "Epoch 67, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 68, Error rate: 0.5375722543352601\n",
      "Epoch 69, Error rate: 0.5375722543352601\n",
      "Epoch 70, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 71, Error rate: 0.5375722543352601\n",
      "Epoch 72, Error rate: 0.5375722543352601\n",
      "Epoch 73, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 74, Error rate: 0.5375722543352601\n",
      "Epoch 75, Error rate: 0.5375722543352601\n",
      "Epoch 76, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 77, Error rate: 0.5375722543352601\n",
      "Epoch 78, Error rate: 0.5375722543352601\n",
      "Epoch 79, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 80, Error rate: 0.5375722543352601\n",
      "Epoch 81, Error rate: 0.5375722543352601\n",
      "Epoch 82, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 83, Error rate: 0.5375722543352601\n",
      "Epoch 84, Error rate: 0.5375722543352601\n",
      "Epoch 85, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 86, Error rate: 0.5375722543352601\n",
      "Epoch 87, Error rate: 0.5375722543352601\n",
      "Epoch 88, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 89, Error rate: 0.5375722543352601\n",
      "Epoch 90, Error rate: 0.5375722543352601\n",
      "Epoch 91, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 92, Error rate: 0.5375722543352601\n",
      "Epoch 93, Error rate: 0.5375722543352601\n",
      "Epoch 94, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 95, Error rate: 0.5375722543352601\n",
      "Epoch 96, Error rate: 0.5375722543352601\n",
      "Epoch 97, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 98, Error rate: 0.5375722543352601\n",
      "Epoch 99, Error rate: 0.5375722543352601\n",
      "Epoch 100, Error rate: 0.5375722543352601\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 1, Error rate: 0.4624277456647399\n",
      "Epoch 2, Error rate: 0.4624277456647399\n",
      "Epoch 3, Error rate: 0.4624277456647399\n",
      "Epoch 4, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.4624277456647399\n",
      "Epoch 6, Error rate: 0.4624277456647399\n",
      "Epoch 7, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.4624277456647399\n",
      "Epoch 9, Error rate: 0.4624277456647399\n",
      "Epoch 10, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.4624277456647399\n",
      "Epoch 12, Error rate: 0.4624277456647399\n",
      "Epoch 13, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.4624277456647399\n",
      "Epoch 15, Error rate: 0.4624277456647399\n",
      "Epoch 16, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.4624277456647399\n",
      "Epoch 18, Error rate: 0.4624277456647399\n",
      "Epoch 19, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.4624277456647399\n",
      "Epoch 21, Error rate: 0.4624277456647399\n",
      "Epoch 22, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.4624277456647399\n",
      "Epoch 24, Error rate: 0.4624277456647399\n",
      "Epoch 25, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.4624277456647399\n",
      "Epoch 27, Error rate: 0.4624277456647399\n",
      "Epoch 28, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.4624277456647399\n",
      "Epoch 30, Error rate: 0.4624277456647399\n",
      "Epoch 31, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.4624277456647399\n",
      "Epoch 33, Error rate: 0.4624277456647399\n",
      "Epoch 34, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.4624277456647399\n",
      "Epoch 36, Error rate: 0.4624277456647399\n",
      "Epoch 37, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.4624277456647399\n",
      "Epoch 39, Error rate: 0.4624277456647399\n",
      "Epoch 40, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 41, Error rate: 0.4624277456647399\n",
      "Epoch 42, Error rate: 0.4624277456647399\n",
      "Epoch 43, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.4624277456647399\n",
      "Epoch 45, Error rate: 0.4624277456647399\n",
      "Epoch 46, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.4624277456647399\n",
      "Epoch 48, Error rate: 0.4624277456647399\n",
      "Epoch 49, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.4624277456647399\n",
      "Epoch 51, Error rate: 0.4624277456647399\n",
      "Epoch 52, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.4624277456647399\n",
      "Epoch 54, Error rate: 0.4624277456647399\n",
      "Epoch 55, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.4624277456647399\n",
      "Epoch 57, Error rate: 0.4624277456647399\n",
      "Epoch 58, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.4624277456647399\n",
      "Epoch 60, Error rate: 0.4624277456647399\n",
      "Epoch 61, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.4624277456647399\n",
      "Epoch 63, Error rate: 0.4624277456647399\n",
      "Epoch 64, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.4624277456647399\n",
      "Epoch 66, Error rate: 0.4624277456647399\n",
      "Epoch 67, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.4624277456647399\n",
      "Epoch 69, Error rate: 0.4624277456647399\n",
      "Epoch 70, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.4624277456647399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72, Error rate: 0.4624277456647399\n",
      "Epoch 73, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.4624277456647399\n",
      "Epoch 75, Error rate: 0.4624277456647399\n",
      "Epoch 76, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.4624277456647399\n",
      "Epoch 78, Error rate: 0.4624277456647399\n",
      "Epoch 79, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.4624277456647399\n",
      "Epoch 81, Error rate: 0.4624277456647399\n",
      "Epoch 82, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.4624277456647399\n",
      "Epoch 84, Error rate: 0.4624277456647399\n",
      "Epoch 85, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.4624277456647399\n",
      "Epoch 87, Error rate: 0.4624277456647399\n",
      "Epoch 88, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.4624277456647399\n",
      "Epoch 90, Error rate: 0.4624277456647399\n",
      "Epoch 91, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 92, Error rate: 0.4624277456647399\n",
      "Epoch 93, Error rate: 0.4624277456647399\n",
      "Epoch 94, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.4624277456647399\n",
      "Epoch 96, Error rate: 0.4624277456647399\n",
      "Epoch 97, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.4624277456647399\n",
      "Epoch 99, Error rate: 0.4624277456647399\n",
      "Epoch 100, Error rate: 0.4624277456647399\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Epoch 1, Error rate: 0.367816091954023\n",
      "Epoch 2, Error rate: 0.367816091954023\n",
      "Epoch 3, Error rate: 0.367816091954023\n",
      "Epoch 4, Error rate: 0.367816091954023\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.3735632183908046\n",
      "Epoch 6, Error rate: 0.3735632183908046\n",
      "Epoch 7, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.3735632183908046\n",
      "Epoch 9, Error rate: 0.3735632183908046\n",
      "Epoch 10, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.3735632183908046\n",
      "Epoch 12, Error rate: 0.3735632183908046\n",
      "Epoch 13, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.3735632183908046\n",
      "Epoch 15, Error rate: 0.3735632183908046\n",
      "Epoch 16, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.3735632183908046\n",
      "Epoch 18, Error rate: 0.3735632183908046\n",
      "Epoch 19, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.3735632183908046\n",
      "Epoch 21, Error rate: 0.3735632183908046\n",
      "Epoch 22, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.3735632183908046\n",
      "Epoch 24, Error rate: 0.3735632183908046\n",
      "Epoch 25, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.3735632183908046\n",
      "Epoch 27, Error rate: 0.3735632183908046\n",
      "Epoch 28, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.3735632183908046\n",
      "Epoch 30, Error rate: 0.3735632183908046\n",
      "Epoch 31, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.3735632183908046\n",
      "Epoch 33, Error rate: 0.3735632183908046\n",
      "Epoch 34, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.3735632183908046\n",
      "Epoch 36, Error rate: 0.3735632183908046\n",
      "Epoch 37, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.3735632183908046\n",
      "Epoch 39, Error rate: 0.3735632183908046\n",
      "Epoch 40, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 41, Error rate: 0.3735632183908046\n",
      "Epoch 42, Error rate: 0.3735632183908046\n",
      "Epoch 43, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.3735632183908046\n",
      "Epoch 45, Error rate: 0.3735632183908046\n",
      "Epoch 46, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.3735632183908046\n",
      "Epoch 48, Error rate: 0.3735632183908046\n",
      "Epoch 49, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.3735632183908046\n",
      "Epoch 51, Error rate: 0.3735632183908046\n",
      "Epoch 52, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.3735632183908046\n",
      "Epoch 54, Error rate: 0.3735632183908046\n",
      "Epoch 55, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.3735632183908046\n",
      "Epoch 57, Error rate: 0.3735632183908046\n",
      "Epoch 58, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.3735632183908046\n",
      "Epoch 60, Error rate: 0.3735632183908046\n",
      "Epoch 61, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.3735632183908046\n",
      "Epoch 63, Error rate: 0.3735632183908046\n",
      "Epoch 64, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.3735632183908046\n",
      "Epoch 66, Error rate: 0.3735632183908046\n",
      "Epoch 67, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.3735632183908046\n",
      "Epoch 69, Error rate: 0.3735632183908046\n",
      "Epoch 70, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.3735632183908046\n",
      "Epoch 72, Error rate: 0.3735632183908046\n",
      "Epoch 73, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.3735632183908046\n",
      "Epoch 75, Error rate: 0.3735632183908046\n",
      "Epoch 76, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.3735632183908046\n",
      "Epoch 78, Error rate: 0.3735632183908046\n",
      "Epoch 79, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.3735632183908046\n",
      "Epoch 81, Error rate: 0.3735632183908046\n",
      "Epoch 82, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.3735632183908046\n",
      "Epoch 84, Error rate: 0.3735632183908046\n",
      "Epoch 85, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.3735632183908046\n",
      "Epoch 87, Error rate: 0.3735632183908046\n",
      "Epoch 88, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.3735632183908046\n",
      "Epoch 90, Error rate: 0.3735632183908046\n",
      "Epoch 91, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 92, Error rate: 0.3735632183908046\n",
      "Epoch 93, Error rate: 0.3735632183908046\n",
      "Epoch 94, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.3735632183908046\n",
      "Epoch 96, Error rate: 0.3735632183908046\n",
      "Epoch 97, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.3735632183908046\n",
      "Epoch 99, Error rate: 0.3735632183908046\n",
      "Epoch 100, Error rate: 0.3735632183908046\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Epoch 1, Error rate: 0.4885057471264368\n",
      "Epoch 2, Error rate: 0.4885057471264368\n",
      "Epoch 3, Error rate: 0.4942528735632184\n",
      "Epoch 4, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.4942528735632184\n",
      "Epoch 6, Error rate: 0.4942528735632184\n",
      "Epoch 7, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.4942528735632184\n",
      "Epoch 9, Error rate: 0.4942528735632184\n",
      "Epoch 10, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.4942528735632184\n",
      "Epoch 12, Error rate: 0.4942528735632184\n",
      "Epoch 13, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.4942528735632184\n",
      "Epoch 15, Error rate: 0.4942528735632184\n",
      "Epoch 16, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.4942528735632184\n",
      "Epoch 18, Error rate: 0.4942528735632184\n",
      "Epoch 19, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.4942528735632184\n",
      "Epoch 21, Error rate: 0.4942528735632184\n",
      "Epoch 22, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.4942528735632184\n",
      "Epoch 24, Error rate: 0.4942528735632184\n",
      "Epoch 25, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.4942528735632184\n",
      "Epoch 27, Error rate: 0.4942528735632184\n",
      "Epoch 28, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.4942528735632184\n",
      "Epoch 30, Error rate: 0.4942528735632184\n",
      "Epoch 31, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.4942528735632184\n",
      "Epoch 33, Error rate: 0.4942528735632184\n",
      "Epoch 34, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.4942528735632184\n",
      "Epoch 36, Error rate: 0.4942528735632184\n",
      "Epoch 37, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.4942528735632184\n",
      "Epoch 39, Error rate: 0.4942528735632184\n",
      "Epoch 40, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Error rate: 0.4942528735632184\n",
      "Epoch 42, Error rate: 0.4942528735632184\n",
      "Epoch 43, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.4942528735632184\n",
      "Epoch 45, Error rate: 0.4942528735632184\n",
      "Epoch 46, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.4942528735632184\n",
      "Epoch 48, Error rate: 0.4942528735632184\n",
      "Epoch 49, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.4942528735632184\n",
      "Epoch 51, Error rate: 0.4942528735632184\n",
      "Epoch 52, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.4942528735632184\n",
      "Epoch 54, Error rate: 0.4942528735632184\n",
      "Epoch 55, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.4942528735632184\n",
      "Epoch 57, Error rate: 0.4942528735632184\n",
      "Epoch 58, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.4942528735632184\n",
      "Epoch 60, Error rate: 0.4942528735632184\n",
      "Epoch 61, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.4942528735632184\n",
      "Epoch 63, Error rate: 0.4942528735632184\n",
      "Epoch 64, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.4942528735632184\n",
      "Epoch 66, Error rate: 0.4942528735632184\n",
      "Epoch 67, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.4942528735632184\n",
      "Epoch 69, Error rate: 0.4942528735632184\n",
      "Epoch 70, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.4942528735632184\n",
      "Epoch 72, Error rate: 0.4942528735632184\n",
      "Epoch 73, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.4942528735632184\n",
      "Epoch 75, Error rate: 0.4942528735632184\n",
      "Epoch 76, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.4942528735632184\n",
      "Epoch 78, Error rate: 0.4942528735632184\n",
      "Epoch 79, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.4942528735632184\n",
      "Epoch 81, Error rate: 0.4942528735632184\n",
      "Epoch 82, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.4942528735632184\n",
      "Epoch 84, Error rate: 0.4942528735632184\n",
      "Epoch 85, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.4942528735632184\n",
      "Epoch 87, Error rate: 0.4942528735632184\n",
      "Epoch 88, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.4942528735632184\n",
      "Epoch 90, Error rate: 0.4942528735632184\n",
      "Epoch 91, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 92, Error rate: 0.4942528735632184\n",
      "Epoch 93, Error rate: 0.4942528735632184\n",
      "Epoch 94, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.4942528735632184\n",
      "Epoch 96, Error rate: 0.4942528735632184\n",
      "Epoch 97, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.4942528735632184\n",
      "Epoch 99, Error rate: 0.4942528735632184\n",
      "Epoch 100, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Epoch 1, Error rate: 0.4942528735632184\n",
      "Epoch 2, Error rate: 0.4942528735632184\n",
      "Epoch 3, Error rate: 0.4942528735632184\n",
      "Epoch 4, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.4942528735632184\n",
      "Epoch 6, Error rate: 0.4942528735632184\n",
      "Epoch 7, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.4942528735632184\n",
      "Epoch 9, Error rate: 0.4942528735632184\n",
      "Epoch 10, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.4942528735632184\n",
      "Epoch 12, Error rate: 0.4942528735632184\n",
      "Epoch 13, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.4942528735632184\n",
      "Epoch 15, Error rate: 0.4942528735632184\n",
      "Epoch 16, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.4942528735632184\n",
      "Epoch 18, Error rate: 0.4942528735632184\n",
      "Epoch 19, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.4942528735632184\n",
      "Epoch 21, Error rate: 0.4942528735632184\n",
      "Epoch 22, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.4942528735632184\n",
      "Epoch 24, Error rate: 0.4942528735632184\n",
      "Epoch 25, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.4942528735632184\n",
      "Epoch 27, Error rate: 0.4942528735632184\n",
      "Epoch 28, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.4942528735632184\n",
      "Epoch 30, Error rate: 0.4942528735632184\n",
      "Epoch 31, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.4942528735632184\n",
      "Epoch 33, Error rate: 0.4942528735632184\n",
      "Epoch 34, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.4942528735632184\n",
      "Epoch 36, Error rate: 0.4942528735632184\n",
      "Epoch 37, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.4942528735632184\n",
      "Epoch 39, Error rate: 0.4942528735632184\n",
      "Epoch 40, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 41, Error rate: 0.4942528735632184\n",
      "Epoch 42, Error rate: 0.4942528735632184\n",
      "Epoch 43, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.4942528735632184\n",
      "Epoch 45, Error rate: 0.4942528735632184\n",
      "Epoch 46, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.4942528735632184\n",
      "Epoch 48, Error rate: 0.4942528735632184\n",
      "Epoch 49, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.4942528735632184\n",
      "Epoch 51, Error rate: 0.4942528735632184\n",
      "Epoch 52, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.4942528735632184\n",
      "Epoch 54, Error rate: 0.4942528735632184\n",
      "Epoch 55, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.4942528735632184\n",
      "Epoch 57, Error rate: 0.4942528735632184\n",
      "Epoch 58, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.4942528735632184\n",
      "Epoch 60, Error rate: 0.4942528735632184\n",
      "Epoch 61, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.4942528735632184\n",
      "Epoch 63, Error rate: 0.4942528735632184\n",
      "Epoch 64, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.4942528735632184\n",
      "Epoch 66, Error rate: 0.4942528735632184\n",
      "Epoch 67, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.4942528735632184\n",
      "Epoch 69, Error rate: 0.4942528735632184\n",
      "Epoch 70, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.4942528735632184\n",
      "Epoch 72, Error rate: 0.4942528735632184\n",
      "Epoch 73, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.4942528735632184\n",
      "Epoch 75, Error rate: 0.4942528735632184\n",
      "Epoch 76, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.4942528735632184\n",
      "Epoch 78, Error rate: 0.4942528735632184\n",
      "Epoch 79, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.4942528735632184\n",
      "Epoch 81, Error rate: 0.4942528735632184\n",
      "Epoch 82, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.4942528735632184\n",
      "Epoch 84, Error rate: 0.4942528735632184\n",
      "Epoch 85, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.4942528735632184\n",
      "Epoch 87, Error rate: 0.4942528735632184\n",
      "Epoch 88, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.4942528735632184\n",
      "Epoch 90, Error rate: 0.4942528735632184\n",
      "Epoch 91, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 92, Error rate: 0.4942528735632184\n",
      "Epoch 93, Error rate: 0.4942528735632184\n",
      "Epoch 94, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.4942528735632184\n",
      "Epoch 96, Error rate: 0.4942528735632184\n",
      "Epoch 97, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.4942528735632184\n",
      "Epoch 99, Error rate: 0.4942528735632184\n",
      "Epoch 100, Error rate: 0.4942528735632184\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Reg lambda: 0.01, Average error rate: 0.5121564482029598\n",
      "Epoch 1, Error rate: 0.3872832369942196\n",
      "Epoch 2, Error rate: 0.3872832369942196\n",
      "Epoch 3, Error rate: 0.3872832369942196\n",
      "Epoch 4, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.3872832369942196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Error rate: 0.3872832369942196\n",
      "Epoch 7, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.3872832369942196\n",
      "Epoch 9, Error rate: 0.3872832369942196\n",
      "Epoch 10, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.3872832369942196\n",
      "Epoch 12, Error rate: 0.3872832369942196\n",
      "Epoch 13, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.3872832369942196\n",
      "Epoch 15, Error rate: 0.3872832369942196\n",
      "Epoch 16, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.3872832369942196\n",
      "Epoch 18, Error rate: 0.3872832369942196\n",
      "Epoch 19, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.3872832369942196\n",
      "Epoch 21, Error rate: 0.3872832369942196\n",
      "Epoch 22, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.3872832369942196\n",
      "Epoch 24, Error rate: 0.3872832369942196\n",
      "Epoch 25, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.3872832369942196\n",
      "Epoch 27, Error rate: 0.3872832369942196\n",
      "Epoch 28, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.3872832369942196\n",
      "Epoch 30, Error rate: 0.3872832369942196\n",
      "Epoch 31, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.3872832369942196\n",
      "Epoch 33, Error rate: 0.3872832369942196\n",
      "Epoch 34, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.3872832369942196\n",
      "Epoch 36, Error rate: 0.3872832369942196\n",
      "Epoch 37, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.3872832369942196\n",
      "Epoch 39, Error rate: 0.3872832369942196\n",
      "Epoch 40, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 41, Error rate: 0.3872832369942196\n",
      "Epoch 42, Error rate: 0.3872832369942196\n",
      "Epoch 43, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.3872832369942196\n",
      "Epoch 45, Error rate: 0.3872832369942196\n",
      "Epoch 46, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.3872832369942196\n",
      "Epoch 48, Error rate: 0.3872832369942196\n",
      "Epoch 49, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.3872832369942196\n",
      "Epoch 51, Error rate: 0.3872832369942196\n",
      "Epoch 52, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.3872832369942196\n",
      "Epoch 54, Error rate: 0.3872832369942196\n",
      "Epoch 55, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.3872832369942196\n",
      "Epoch 57, Error rate: 0.3872832369942196\n",
      "Epoch 58, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.3872832369942196\n",
      "Epoch 60, Error rate: 0.3872832369942196\n",
      "Epoch 61, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.3872832369942196\n",
      "Epoch 63, Error rate: 0.3872832369942196\n",
      "Epoch 64, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.3872832369942196\n",
      "Epoch 66, Error rate: 0.3872832369942196\n",
      "Epoch 67, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.3872832369942196\n",
      "Epoch 69, Error rate: 0.3872832369942196\n",
      "Epoch 70, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.3872832369942196\n",
      "Epoch 72, Error rate: 0.3872832369942196\n",
      "Epoch 73, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.3872832369942196\n",
      "Epoch 75, Error rate: 0.3872832369942196\n",
      "Epoch 76, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.3872832369942196\n",
      "Epoch 78, Error rate: 0.3872832369942196\n",
      "Epoch 79, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.3872832369942196\n",
      "Epoch 81, Error rate: 0.3872832369942196\n",
      "Epoch 82, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.3872832369942196\n",
      "Epoch 84, Error rate: 0.3872832369942196\n",
      "Epoch 85, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.3872832369942196\n",
      "Epoch 87, Error rate: 0.3872832369942196\n",
      "Epoch 88, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.3872832369942196\n",
      "Epoch 90, Error rate: 0.3872832369942196\n",
      "Epoch 91, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 92, Error rate: 0.3872832369942196\n",
      "Epoch 93, Error rate: 0.3872832369942196\n",
      "Epoch 94, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.3872832369942196\n",
      "Epoch 96, Error rate: 0.3872832369942196\n",
      "Epoch 97, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.3872832369942196\n",
      "Epoch 99, Error rate: 0.3872832369942196\n",
      "Epoch 100, Error rate: 0.3872832369942196\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Epoch 1, Error rate: 0.4682080924855491\n",
      "Epoch 2, Error rate: 0.4682080924855491\n",
      "Epoch 3, Error rate: 0.4682080924855491\n",
      "Epoch 4, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.4682080924855491\n",
      "Epoch 6, Error rate: 0.4682080924855491\n",
      "Epoch 7, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.4682080924855491\n",
      "Epoch 9, Error rate: 0.4682080924855491\n",
      "Epoch 10, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.4682080924855491\n",
      "Epoch 12, Error rate: 0.4682080924855491\n",
      "Epoch 13, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.4682080924855491\n",
      "Epoch 15, Error rate: 0.4682080924855491\n",
      "Epoch 16, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.4682080924855491\n",
      "Epoch 18, Error rate: 0.4682080924855491\n",
      "Epoch 19, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.4682080924855491\n",
      "Epoch 21, Error rate: 0.4682080924855491\n",
      "Epoch 22, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.4682080924855491\n",
      "Epoch 24, Error rate: 0.4682080924855491\n",
      "Epoch 25, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.4682080924855491\n",
      "Epoch 27, Error rate: 0.4682080924855491\n",
      "Epoch 28, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.4682080924855491\n",
      "Epoch 30, Error rate: 0.4682080924855491\n",
      "Epoch 31, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.4682080924855491\n",
      "Epoch 33, Error rate: 0.4682080924855491\n",
      "Epoch 34, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.4682080924855491\n",
      "Epoch 36, Error rate: 0.4682080924855491\n",
      "Epoch 37, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.4682080924855491\n",
      "Epoch 39, Error rate: 0.4682080924855491\n",
      "Epoch 40, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 41, Error rate: 0.4682080924855491\n",
      "Epoch 42, Error rate: 0.4682080924855491\n",
      "Epoch 43, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.4682080924855491\n",
      "Epoch 45, Error rate: 0.4682080924855491\n",
      "Epoch 46, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.4682080924855491\n",
      "Epoch 48, Error rate: 0.4682080924855491\n",
      "Epoch 49, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.4682080924855491\n",
      "Epoch 51, Error rate: 0.4682080924855491\n",
      "Epoch 52, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.4682080924855491\n",
      "Epoch 54, Error rate: 0.4682080924855491\n",
      "Epoch 55, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.4682080924855491\n",
      "Epoch 57, Error rate: 0.4682080924855491\n",
      "Epoch 58, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.4682080924855491\n",
      "Epoch 60, Error rate: 0.4682080924855491\n",
      "Epoch 61, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.4682080924855491\n",
      "Epoch 63, Error rate: 0.4682080924855491\n",
      "Epoch 64, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.4682080924855491\n",
      "Epoch 66, Error rate: 0.4682080924855491\n",
      "Epoch 67, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.4682080924855491\n",
      "Epoch 69, Error rate: 0.4682080924855491\n",
      "Epoch 70, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.4682080924855491\n",
      "Epoch 72, Error rate: 0.4682080924855491\n",
      "Epoch 73, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.4682080924855491\n",
      "Epoch 75, Error rate: 0.4682080924855491\n",
      "Epoch 76, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.4682080924855491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78, Error rate: 0.4682080924855491\n",
      "Epoch 79, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.4682080924855491\n",
      "Epoch 81, Error rate: 0.4682080924855491\n",
      "Epoch 82, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.4682080924855491\n",
      "Epoch 84, Error rate: 0.4682080924855491\n",
      "Epoch 85, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.4682080924855491\n",
      "Epoch 87, Error rate: 0.4682080924855491\n",
      "Epoch 88, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.4682080924855491\n",
      "Epoch 90, Error rate: 0.4682080924855491\n",
      "Epoch 91, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 92, Error rate: 0.4682080924855491\n",
      "Epoch 93, Error rate: 0.4682080924855491\n",
      "Epoch 94, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.4682080924855491\n",
      "Epoch 96, Error rate: 0.4682080924855491\n",
      "Epoch 97, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.4682080924855491\n",
      "Epoch 99, Error rate: 0.4682080924855491\n",
      "Epoch 100, Error rate: 0.4682080924855491\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Epoch 1, Error rate: 0.5\n",
      "Epoch 2, Error rate: 0.5\n",
      "Epoch 3, Error rate: 0.5\n",
      "Epoch 4, Error rate: 0.5\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.5\n",
      "Epoch 6, Error rate: 0.5\n",
      "Epoch 7, Error rate: 0.5\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.5\n",
      "Epoch 9, Error rate: 0.5\n",
      "Epoch 10, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.5\n",
      "Epoch 12, Error rate: 0.5\n",
      "Epoch 13, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.5\n",
      "Epoch 15, Error rate: 0.5\n",
      "Epoch 16, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.5\n",
      "Epoch 18, Error rate: 0.5\n",
      "Epoch 19, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.5\n",
      "Epoch 21, Error rate: 0.5\n",
      "Epoch 22, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.5\n",
      "Epoch 24, Error rate: 0.5\n",
      "Epoch 25, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.5\n",
      "Epoch 27, Error rate: 0.5\n",
      "Epoch 28, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.5\n",
      "Epoch 30, Error rate: 0.5\n",
      "Epoch 31, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.5\n",
      "Epoch 33, Error rate: 0.5\n",
      "Epoch 34, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.5\n",
      "Epoch 36, Error rate: 0.5\n",
      "Epoch 37, Error rate: 0.5\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.5\n",
      "Epoch 39, Error rate: 0.5\n",
      "Epoch 40, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 41, Error rate: 0.5\n",
      "Epoch 42, Error rate: 0.5\n",
      "Epoch 43, Error rate: 0.5\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.5\n",
      "Epoch 45, Error rate: 0.5\n",
      "Epoch 46, Error rate: 0.5\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.5\n",
      "Epoch 48, Error rate: 0.5\n",
      "Epoch 49, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.5\n",
      "Epoch 51, Error rate: 0.5\n",
      "Epoch 52, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.5\n",
      "Epoch 54, Error rate: 0.5\n",
      "Epoch 55, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.5\n",
      "Epoch 57, Error rate: 0.5\n",
      "Epoch 58, Error rate: 0.5\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.5\n",
      "Epoch 60, Error rate: 0.5\n",
      "Epoch 61, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.5\n",
      "Epoch 63, Error rate: 0.5\n",
      "Epoch 64, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.5\n",
      "Epoch 66, Error rate: 0.5\n",
      "Epoch 67, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.5\n",
      "Epoch 69, Error rate: 0.5\n",
      "Epoch 70, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.5\n",
      "Epoch 72, Error rate: 0.5\n",
      "Epoch 73, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.5\n",
      "Epoch 75, Error rate: 0.5\n",
      "Epoch 76, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.5\n",
      "Epoch 78, Error rate: 0.5\n",
      "Epoch 79, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.5\n",
      "Epoch 81, Error rate: 0.5\n",
      "Epoch 82, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.5\n",
      "Epoch 84, Error rate: 0.5\n",
      "Epoch 85, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.5\n",
      "Epoch 87, Error rate: 0.5\n",
      "Epoch 88, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.5\n",
      "Epoch 90, Error rate: 0.5\n",
      "Epoch 91, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 92, Error rate: 0.5\n",
      "Epoch 93, Error rate: 0.5\n",
      "Epoch 94, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.5\n",
      "Epoch 96, Error rate: 0.5\n",
      "Epoch 97, Error rate: 0.5\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.5\n",
      "Epoch 99, Error rate: 0.5\n",
      "Epoch 100, Error rate: 0.5\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Epoch 1, Error rate: 0.4827586206896552\n",
      "Epoch 2, Error rate: 0.4827586206896552\n",
      "Epoch 3, Error rate: 0.4827586206896552\n",
      "Epoch 4, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.4827586206896552\n",
      "Epoch 6, Error rate: 0.4827586206896552\n",
      "Epoch 7, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.4827586206896552\n",
      "Epoch 9, Error rate: 0.4827586206896552\n",
      "Epoch 10, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.4827586206896552\n",
      "Epoch 12, Error rate: 0.4827586206896552\n",
      "Epoch 13, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.4827586206896552\n",
      "Epoch 15, Error rate: 0.4827586206896552\n",
      "Epoch 16, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.4827586206896552\n",
      "Epoch 18, Error rate: 0.4827586206896552\n",
      "Epoch 19, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.4827586206896552\n",
      "Epoch 21, Error rate: 0.4827586206896552\n",
      "Epoch 22, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.4827586206896552\n",
      "Epoch 24, Error rate: 0.4827586206896552\n",
      "Epoch 25, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.4827586206896552\n",
      "Epoch 27, Error rate: 0.4827586206896552\n",
      "Epoch 28, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.4827586206896552\n",
      "Epoch 30, Error rate: 0.4827586206896552\n",
      "Epoch 31, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.4827586206896552\n",
      "Epoch 33, Error rate: 0.4827586206896552\n",
      "Epoch 34, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.4827586206896552\n",
      "Epoch 36, Error rate: 0.4827586206896552\n",
      "Epoch 37, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.4827586206896552\n",
      "Epoch 39, Error rate: 0.4827586206896552\n",
      "Epoch 40, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 41, Error rate: 0.4827586206896552\n",
      "Epoch 42, Error rate: 0.4827586206896552\n",
      "Epoch 43, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.4827586206896552\n",
      "Epoch 45, Error rate: 0.4827586206896552\n",
      "Epoch 46, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.4827586206896552\n",
      "Epoch 48, Error rate: 0.4827586206896552\n",
      "Epoch 49, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.4827586206896552\n",
      "Epoch 51, Error rate: 0.4827586206896552\n",
      "Epoch 52, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.4827586206896552\n",
      "Epoch 54, Error rate: 0.4827586206896552\n",
      "Epoch 55, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.4827586206896552\n",
      "Epoch 57, Error rate: 0.4827586206896552\n",
      "Epoch 58, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.4827586206896552\n",
      "Epoch 60, Error rate: 0.4827586206896552\n",
      "Epoch 61, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.4827586206896552\n",
      "Epoch 63, Error rate: 0.4827586206896552\n",
      "Epoch 64, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.4827586206896552\n",
      "Epoch 66, Error rate: 0.4827586206896552\n",
      "Epoch 67, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.4827586206896552\n",
      "Epoch 69, Error rate: 0.4827586206896552\n",
      "Epoch 70, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.4827586206896552\n",
      "Epoch 72, Error rate: 0.4827586206896552\n",
      "Epoch 73, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.4827586206896552\n",
      "Epoch 75, Error rate: 0.4827586206896552\n",
      "Epoch 76, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.4827586206896552\n",
      "Epoch 78, Error rate: 0.4827586206896552\n",
      "Epoch 79, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.4827586206896552\n",
      "Epoch 81, Error rate: 0.4827586206896552\n",
      "Epoch 82, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.4827586206896552\n",
      "Epoch 84, Error rate: 0.4827586206896552\n",
      "Epoch 85, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.4827586206896552\n",
      "Epoch 87, Error rate: 0.4827586206896552\n",
      "Epoch 88, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.4827586206896552\n",
      "Epoch 90, Error rate: 0.4827586206896552\n",
      "Epoch 91, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 92, Error rate: 0.4827586206896552\n",
      "Epoch 93, Error rate: 0.4827586206896552\n",
      "Epoch 94, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.4827586206896552\n",
      "Epoch 96, Error rate: 0.4827586206896552\n",
      "Epoch 97, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.4827586206896552\n",
      "Epoch 99, Error rate: 0.4827586206896552\n",
      "Epoch 100, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Epoch 1, Error rate: 0.5057471264367817\n",
      "Epoch 2, Error rate: 0.5114942528735632\n",
      "Epoch 3, Error rate: 0.5172413793103449\n",
      "Epoch 4, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.5229885057471264\n",
      "Epoch 6, Error rate: 0.5229885057471264\n",
      "Epoch 7, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.5229885057471264\n",
      "Epoch 9, Error rate: 0.5229885057471264\n",
      "Epoch 10, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.5229885057471264\n",
      "Epoch 12, Error rate: 0.5229885057471264\n",
      "Epoch 13, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.5229885057471264\n",
      "Epoch 15, Error rate: 0.5229885057471264\n",
      "Epoch 16, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.5229885057471264\n",
      "Epoch 18, Error rate: 0.5229885057471264\n",
      "Epoch 19, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.5229885057471264\n",
      "Epoch 21, Error rate: 0.5229885057471264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.5229885057471264\n",
      "Epoch 24, Error rate: 0.5229885057471264\n",
      "Epoch 25, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.5229885057471264\n",
      "Epoch 27, Error rate: 0.5229885057471264\n",
      "Epoch 28, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.5229885057471264\n",
      "Epoch 30, Error rate: 0.5229885057471264\n",
      "Epoch 31, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.5229885057471264\n",
      "Epoch 33, Error rate: 0.5229885057471264\n",
      "Epoch 34, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.5229885057471264\n",
      "Epoch 36, Error rate: 0.5229885057471264\n",
      "Epoch 37, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.5229885057471264\n",
      "Epoch 39, Error rate: 0.5229885057471264\n",
      "Epoch 40, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 41, Error rate: 0.5229885057471264\n",
      "Epoch 42, Error rate: 0.5229885057471264\n",
      "Epoch 43, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.5229885057471264\n",
      "Epoch 45, Error rate: 0.5229885057471264\n",
      "Epoch 46, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.5229885057471264\n",
      "Epoch 48, Error rate: 0.5229885057471264\n",
      "Epoch 49, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.5229885057471264\n",
      "Epoch 51, Error rate: 0.5229885057471264\n",
      "Epoch 52, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.5229885057471264\n",
      "Epoch 54, Error rate: 0.5229885057471264\n",
      "Epoch 55, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.5229885057471264\n",
      "Epoch 57, Error rate: 0.5229885057471264\n",
      "Epoch 58, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.5229885057471264\n",
      "Epoch 60, Error rate: 0.5229885057471264\n",
      "Epoch 61, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.5229885057471264\n",
      "Epoch 63, Error rate: 0.5229885057471264\n",
      "Epoch 64, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.5229885057471264\n",
      "Epoch 66, Error rate: 0.5229885057471264\n",
      "Epoch 67, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.5229885057471264\n",
      "Epoch 69, Error rate: 0.5229885057471264\n",
      "Epoch 70, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.5229885057471264\n",
      "Epoch 72, Error rate: 0.5229885057471264\n",
      "Epoch 73, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.5229885057471264\n",
      "Epoch 75, Error rate: 0.5229885057471264\n",
      "Epoch 76, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.5229885057471264\n",
      "Epoch 78, Error rate: 0.5229885057471264\n",
      "Epoch 79, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.5229885057471264\n",
      "Epoch 81, Error rate: 0.5229885057471264\n",
      "Epoch 82, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.5229885057471264\n",
      "Epoch 84, Error rate: 0.5229885057471264\n",
      "Epoch 85, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.5229885057471264\n",
      "Epoch 87, Error rate: 0.5229885057471264\n",
      "Epoch 88, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.5229885057471264\n",
      "Epoch 90, Error rate: 0.5229885057471264\n",
      "Epoch 91, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 92, Error rate: 0.5229885057471264\n",
      "Epoch 93, Error rate: 0.5229885057471264\n",
      "Epoch 94, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.5229885057471264\n",
      "Epoch 96, Error rate: 0.5229885057471264\n",
      "Epoch 97, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.5229885057471264\n",
      "Epoch 99, Error rate: 0.5229885057471264\n",
      "Epoch 100, Error rate: 0.5229885057471264\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Reg lambda: 0.1, Average error rate: 0.41490486257928116\n",
      "Epoch 1, Error rate: 0.6763005780346821\n",
      "Epoch 2, Error rate: 0.6820809248554913\n",
      "Epoch 3, Error rate: 0.6878612716763006\n",
      "Epoch 4, Error rate: 0.6820809248554913\n",
      "Epoch 5, Error rate: 0.6878612716763006\n",
      "Epoch 6, Error rate: 0.6936416184971098\n",
      "Epoch 7, Error rate: 0.7052023121387283\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 8, Error rate: 0.7109826589595376\n",
      "Epoch 9, Error rate: 0.7109826589595376\n",
      "Epoch 10, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 11, Error rate: 0.7109826589595376\n",
      "Epoch 12, Error rate: 0.7109826589595376\n",
      "Epoch 13, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 14, Error rate: 0.7109826589595376\n",
      "Epoch 15, Error rate: 0.7109826589595376\n",
      "Epoch 16, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 17, Error rate: 0.7109826589595376\n",
      "Epoch 18, Error rate: 0.7109826589595376\n",
      "Epoch 19, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 20, Error rate: 0.7109826589595376\n",
      "Epoch 21, Error rate: 0.7109826589595376\n",
      "Epoch 22, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 23, Error rate: 0.7109826589595376\n",
      "Epoch 24, Error rate: 0.7109826589595376\n",
      "Epoch 25, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 26, Error rate: 0.7109826589595376\n",
      "Epoch 27, Error rate: 0.7109826589595376\n",
      "Epoch 28, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 29, Error rate: 0.7109826589595376\n",
      "Epoch 30, Error rate: 0.7109826589595376\n",
      "Epoch 31, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 32, Error rate: 0.7109826589595376\n",
      "Epoch 33, Error rate: 0.7109826589595376\n",
      "Epoch 34, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 35, Error rate: 0.7109826589595376\n",
      "Epoch 36, Error rate: 0.7109826589595376\n",
      "Epoch 37, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 38, Error rate: 0.7109826589595376\n",
      "Epoch 39, Error rate: 0.7109826589595376\n",
      "Epoch 40, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 41, Error rate: 0.7109826589595376\n",
      "Epoch 42, Error rate: 0.7109826589595376\n",
      "Epoch 43, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 44, Error rate: 0.7109826589595376\n",
      "Epoch 45, Error rate: 0.7109826589595376\n",
      "Epoch 46, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 47, Error rate: 0.7109826589595376\n",
      "Epoch 48, Error rate: 0.7109826589595376\n",
      "Epoch 49, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 50, Error rate: 0.7109826589595376\n",
      "Epoch 51, Error rate: 0.7109826589595376\n",
      "Epoch 52, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 53, Error rate: 0.7109826589595376\n",
      "Epoch 54, Error rate: 0.7109826589595376\n",
      "Epoch 55, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 56, Error rate: 0.7109826589595376\n",
      "Epoch 57, Error rate: 0.7109826589595376\n",
      "Epoch 58, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 59, Error rate: 0.7109826589595376\n",
      "Epoch 60, Error rate: 0.7109826589595376\n",
      "Epoch 61, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 62, Error rate: 0.7109826589595376\n",
      "Epoch 63, Error rate: 0.7109826589595376\n",
      "Epoch 64, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 65, Error rate: 0.7109826589595376\n",
      "Epoch 66, Error rate: 0.7109826589595376\n",
      "Epoch 67, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 68, Error rate: 0.7109826589595376\n",
      "Epoch 69, Error rate: 0.7109826589595376\n",
      "Epoch 70, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 71, Error rate: 0.7109826589595376\n",
      "Epoch 72, Error rate: 0.7109826589595376\n",
      "Epoch 73, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 74, Error rate: 0.7109826589595376\n",
      "Epoch 75, Error rate: 0.7109826589595376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 77, Error rate: 0.7109826589595376\n",
      "Epoch 78, Error rate: 0.7109826589595376\n",
      "Epoch 79, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 80, Error rate: 0.7109826589595376\n",
      "Epoch 81, Error rate: 0.7109826589595376\n",
      "Epoch 82, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 83, Error rate: 0.7109826589595376\n",
      "Epoch 84, Error rate: 0.7109826589595376\n",
      "Epoch 85, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 86, Error rate: 0.7109826589595376\n",
      "Epoch 87, Error rate: 0.7109826589595376\n",
      "Epoch 88, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 89, Error rate: 0.7109826589595376\n",
      "Epoch 90, Error rate: 0.7109826589595376\n",
      "Epoch 91, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 92, Error rate: 0.7109826589595376\n",
      "Epoch 93, Error rate: 0.7109826589595376\n",
      "Epoch 94, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 95, Error rate: 0.7109826589595376\n",
      "Epoch 96, Error rate: 0.7109826589595376\n",
      "Epoch 97, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 98, Error rate: 0.7109826589595376\n",
      "Epoch 99, Error rate: 0.7109826589595376\n",
      "Epoch 100, Error rate: 0.7109826589595376\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 1, Error rate: 0.4624277456647399\n",
      "Epoch 2, Error rate: 0.4682080924855491\n",
      "Epoch 3, Error rate: 0.4682080924855491\n",
      "Epoch 4, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.47398843930635837\n",
      "Epoch 6, Error rate: 0.47398843930635837\n",
      "Epoch 7, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.47398843930635837\n",
      "Epoch 9, Error rate: 0.47398843930635837\n",
      "Epoch 10, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.47398843930635837\n",
      "Epoch 12, Error rate: 0.47398843930635837\n",
      "Epoch 13, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.47398843930635837\n",
      "Epoch 15, Error rate: 0.47398843930635837\n",
      "Epoch 16, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.47398843930635837\n",
      "Epoch 18, Error rate: 0.47398843930635837\n",
      "Epoch 19, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.47398843930635837\n",
      "Epoch 21, Error rate: 0.47398843930635837\n",
      "Epoch 22, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.47398843930635837\n",
      "Epoch 24, Error rate: 0.47398843930635837\n",
      "Epoch 25, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.47398843930635837\n",
      "Epoch 27, Error rate: 0.47398843930635837\n",
      "Epoch 28, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.47398843930635837\n",
      "Epoch 30, Error rate: 0.47398843930635837\n",
      "Epoch 31, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.47398843930635837\n",
      "Epoch 33, Error rate: 0.47398843930635837\n",
      "Epoch 34, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.47398843930635837\n",
      "Epoch 36, Error rate: 0.47398843930635837\n",
      "Epoch 37, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.47398843930635837\n",
      "Epoch 39, Error rate: 0.47398843930635837\n",
      "Epoch 40, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 41, Error rate: 0.47398843930635837\n",
      "Epoch 42, Error rate: 0.47398843930635837\n",
      "Epoch 43, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.47398843930635837\n",
      "Epoch 45, Error rate: 0.47398843930635837\n",
      "Epoch 46, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.47398843930635837\n",
      "Epoch 48, Error rate: 0.47398843930635837\n",
      "Epoch 49, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.47398843930635837\n",
      "Epoch 51, Error rate: 0.47398843930635837\n",
      "Epoch 52, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.47398843930635837\n",
      "Epoch 54, Error rate: 0.47398843930635837\n",
      "Epoch 55, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.47398843930635837\n",
      "Epoch 57, Error rate: 0.47398843930635837\n",
      "Epoch 58, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.47398843930635837\n",
      "Epoch 60, Error rate: 0.47398843930635837\n",
      "Epoch 61, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.47398843930635837\n",
      "Epoch 63, Error rate: 0.47398843930635837\n",
      "Epoch 64, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.47398843930635837\n",
      "Epoch 66, Error rate: 0.47398843930635837\n",
      "Epoch 67, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.47398843930635837\n",
      "Epoch 69, Error rate: 0.47398843930635837\n",
      "Epoch 70, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.47398843930635837\n",
      "Epoch 72, Error rate: 0.47398843930635837\n",
      "Epoch 73, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.47398843930635837\n",
      "Epoch 75, Error rate: 0.47398843930635837\n",
      "Epoch 76, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.47398843930635837\n",
      "Epoch 78, Error rate: 0.47398843930635837\n",
      "Epoch 79, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.47398843930635837\n",
      "Epoch 81, Error rate: 0.47398843930635837\n",
      "Epoch 82, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.47398843930635837\n",
      "Epoch 84, Error rate: 0.47398843930635837\n",
      "Epoch 85, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.47398843930635837\n",
      "Epoch 87, Error rate: 0.47398843930635837\n",
      "Epoch 88, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.47398843930635837\n",
      "Epoch 90, Error rate: 0.47398843930635837\n",
      "Epoch 91, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 92, Error rate: 0.47398843930635837\n",
      "Epoch 93, Error rate: 0.47398843930635837\n",
      "Epoch 94, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.47398843930635837\n",
      "Epoch 96, Error rate: 0.47398843930635837\n",
      "Epoch 97, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.47398843930635837\n",
      "Epoch 99, Error rate: 0.47398843930635837\n",
      "Epoch 100, Error rate: 0.47398843930635837\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Epoch 1, Error rate: 0.5287356321839081\n",
      "Epoch 2, Error rate: 0.5459770114942529\n",
      "Epoch 3, Error rate: 0.5689655172413793\n",
      "Epoch 4, Error rate: 0.5747126436781609\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.5862068965517241\n",
      "Epoch 6, Error rate: 0.5747126436781609\n",
      "Epoch 7, Error rate: 0.5804597701149425\n",
      "Epoch 8, Error rate: 0.5919540229885057\n",
      "Epoch 9, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 10, Error rate: 0.5919540229885057\n",
      "Epoch 11, Error rate: 0.5919540229885057\n",
      "Epoch 12, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 13, Error rate: 0.5919540229885057\n",
      "Epoch 14, Error rate: 0.5919540229885057\n",
      "Epoch 15, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 16, Error rate: 0.5919540229885057\n",
      "Epoch 17, Error rate: 0.5919540229885057\n",
      "Epoch 18, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 19, Error rate: 0.5919540229885057\n",
      "Epoch 20, Error rate: 0.5919540229885057\n",
      "Epoch 21, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 22, Error rate: 0.5919540229885057\n",
      "Epoch 23, Error rate: 0.5919540229885057\n",
      "Epoch 24, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 25, Error rate: 0.5919540229885057\n",
      "Epoch 26, Error rate: 0.5919540229885057\n",
      "Epoch 27, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 28, Error rate: 0.5919540229885057\n",
      "Epoch 29, Error rate: 0.5919540229885057\n",
      "Epoch 30, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 31, Error rate: 0.5919540229885057\n",
      "Epoch 32, Error rate: 0.5919540229885057\n",
      "Epoch 33, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Error rate: 0.5919540229885057\n",
      "Epoch 35, Error rate: 0.5919540229885057\n",
      "Epoch 36, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 37, Error rate: 0.5919540229885057\n",
      "Epoch 38, Error rate: 0.5919540229885057\n",
      "Epoch 39, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 40, Error rate: 0.5919540229885057\n",
      "Epoch 41, Error rate: 0.5919540229885057\n",
      "Epoch 42, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 43, Error rate: 0.5919540229885057\n",
      "Epoch 44, Error rate: 0.5919540229885057\n",
      "Epoch 45, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 46, Error rate: 0.5919540229885057\n",
      "Epoch 47, Error rate: 0.5919540229885057\n",
      "Epoch 48, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 49, Error rate: 0.5919540229885057\n",
      "Epoch 50, Error rate: 0.5919540229885057\n",
      "Epoch 51, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 52, Error rate: 0.5919540229885057\n",
      "Epoch 53, Error rate: 0.5919540229885057\n",
      "Epoch 54, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 55, Error rate: 0.5919540229885057\n",
      "Epoch 56, Error rate: 0.5919540229885057\n",
      "Epoch 57, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 58, Error rate: 0.5919540229885057\n",
      "Epoch 59, Error rate: 0.5919540229885057\n",
      "Epoch 60, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 61, Error rate: 0.5919540229885057\n",
      "Epoch 62, Error rate: 0.5919540229885057\n",
      "Epoch 63, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 64, Error rate: 0.5919540229885057\n",
      "Epoch 65, Error rate: 0.5919540229885057\n",
      "Epoch 66, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 67, Error rate: 0.5919540229885057\n",
      "Epoch 68, Error rate: 0.5919540229885057\n",
      "Epoch 69, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 70, Error rate: 0.5919540229885057\n",
      "Epoch 71, Error rate: 0.5919540229885057\n",
      "Epoch 72, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 73, Error rate: 0.5919540229885057\n",
      "Epoch 74, Error rate: 0.5919540229885057\n",
      "Epoch 75, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 76, Error rate: 0.5919540229885057\n",
      "Epoch 77, Error rate: 0.5919540229885057\n",
      "Epoch 78, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 79, Error rate: 0.5919540229885057\n",
      "Epoch 80, Error rate: 0.5919540229885057\n",
      "Epoch 81, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 82, Error rate: 0.5919540229885057\n",
      "Epoch 83, Error rate: 0.5919540229885057\n",
      "Epoch 84, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 85, Error rate: 0.5919540229885057\n",
      "Epoch 86, Error rate: 0.5919540229885057\n",
      "Epoch 87, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 88, Error rate: 0.5919540229885057\n",
      "Epoch 89, Error rate: 0.5919540229885057\n",
      "Epoch 90, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 91, Error rate: 0.5919540229885057\n",
      "Epoch 92, Error rate: 0.5919540229885057\n",
      "Epoch 93, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 94, Error rate: 0.5919540229885057\n",
      "Epoch 95, Error rate: 0.5919540229885057\n",
      "Epoch 96, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 97, Error rate: 0.5919540229885057\n",
      "Epoch 98, Error rate: 0.5919540229885057\n",
      "Epoch 99, Error rate: 0.5919540229885057\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 100, Error rate: 0.5919540229885057\n",
      "Epoch 1, Error rate: 0.4827586206896552\n",
      "Epoch 2, Error rate: 0.4827586206896552\n",
      "Epoch 3, Error rate: 0.4827586206896552\n",
      "Epoch 4, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.4827586206896552\n",
      "Epoch 6, Error rate: 0.4827586206896552\n",
      "Epoch 7, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.4827586206896552\n",
      "Epoch 9, Error rate: 0.4827586206896552\n",
      "Epoch 10, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.4827586206896552\n",
      "Epoch 12, Error rate: 0.4827586206896552\n",
      "Epoch 13, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.4827586206896552\n",
      "Epoch 15, Error rate: 0.4827586206896552\n",
      "Epoch 16, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.4827586206896552\n",
      "Epoch 18, Error rate: 0.4827586206896552\n",
      "Epoch 19, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.4827586206896552\n",
      "Epoch 21, Error rate: 0.4827586206896552\n",
      "Epoch 22, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.4827586206896552\n",
      "Epoch 24, Error rate: 0.4827586206896552\n",
      "Epoch 25, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.4827586206896552\n",
      "Epoch 27, Error rate: 0.4827586206896552\n",
      "Epoch 28, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.4827586206896552\n",
      "Epoch 30, Error rate: 0.4827586206896552\n",
      "Epoch 31, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.4827586206896552\n",
      "Epoch 33, Error rate: 0.4827586206896552\n",
      "Epoch 34, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.4827586206896552\n",
      "Epoch 36, Error rate: 0.4827586206896552\n",
      "Epoch 37, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.4827586206896552\n",
      "Epoch 39, Error rate: 0.4827586206896552\n",
      "Epoch 40, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 41, Error rate: 0.4827586206896552\n",
      "Epoch 42, Error rate: 0.4827586206896552\n",
      "Epoch 43, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.4827586206896552\n",
      "Epoch 45, Error rate: 0.4827586206896552\n",
      "Epoch 46, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.4827586206896552\n",
      "Epoch 48, Error rate: 0.4827586206896552\n",
      "Epoch 49, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.4827586206896552\n",
      "Epoch 51, Error rate: 0.4827586206896552\n",
      "Epoch 52, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.4827586206896552\n",
      "Epoch 54, Error rate: 0.4827586206896552\n",
      "Epoch 55, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.4827586206896552\n",
      "Epoch 57, Error rate: 0.4827586206896552\n",
      "Epoch 58, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.4827586206896552\n",
      "Epoch 60, Error rate: 0.4827586206896552\n",
      "Epoch 61, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.4827586206896552\n",
      "Epoch 63, Error rate: 0.4827586206896552\n",
      "Epoch 64, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.4827586206896552\n",
      "Epoch 66, Error rate: 0.4827586206896552\n",
      "Epoch 67, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.4827586206896552\n",
      "Epoch 69, Error rate: 0.4827586206896552\n",
      "Epoch 70, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.4827586206896552\n",
      "Epoch 72, Error rate: 0.4827586206896552\n",
      "Epoch 73, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.4827586206896552\n",
      "Epoch 75, Error rate: 0.4827586206896552\n",
      "Epoch 76, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.4827586206896552\n",
      "Epoch 78, Error rate: 0.4827586206896552\n",
      "Epoch 79, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.4827586206896552\n",
      "Epoch 81, Error rate: 0.4827586206896552\n",
      "Epoch 82, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.4827586206896552\n",
      "Epoch 84, Error rate: 0.4827586206896552\n",
      "Epoch 85, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.4827586206896552\n",
      "Epoch 87, Error rate: 0.4827586206896552\n",
      "Epoch 88, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.4827586206896552\n",
      "Epoch 90, Error rate: 0.4827586206896552\n",
      "Epoch 91, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92, Error rate: 0.4827586206896552\n",
      "Epoch 93, Error rate: 0.4827586206896552\n",
      "Epoch 94, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.4827586206896552\n",
      "Epoch 96, Error rate: 0.4827586206896552\n",
      "Epoch 97, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.4827586206896552\n",
      "Epoch 99, Error rate: 0.4827586206896552\n",
      "Epoch 100, Error rate: 0.4827586206896552\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Epoch 1, Error rate: 0.5114942528735632\n",
      "Epoch 2, Error rate: 0.5114942528735632\n",
      "Epoch 3, Error rate: 0.5172413793103449\n",
      "Epoch 4, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 5, Error rate: 0.5172413793103449\n",
      "Epoch 6, Error rate: 0.5172413793103449\n",
      "Epoch 7, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 8, Error rate: 0.5172413793103449\n",
      "Epoch 9, Error rate: 0.5172413793103449\n",
      "Epoch 10, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 11, Error rate: 0.5172413793103449\n",
      "Epoch 12, Error rate: 0.5172413793103449\n",
      "Epoch 13, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 14, Error rate: 0.5172413793103449\n",
      "Epoch 15, Error rate: 0.5172413793103449\n",
      "Epoch 16, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 17, Error rate: 0.5172413793103449\n",
      "Epoch 18, Error rate: 0.5172413793103449\n",
      "Epoch 19, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 20, Error rate: 0.5172413793103449\n",
      "Epoch 21, Error rate: 0.5172413793103449\n",
      "Epoch 22, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 23, Error rate: 0.5172413793103449\n",
      "Epoch 24, Error rate: 0.5172413793103449\n",
      "Epoch 25, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 26, Error rate: 0.5172413793103449\n",
      "Epoch 27, Error rate: 0.5172413793103449\n",
      "Epoch 28, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 29, Error rate: 0.5172413793103449\n",
      "Epoch 30, Error rate: 0.5172413793103449\n",
      "Epoch 31, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 32, Error rate: 0.5172413793103449\n",
      "Epoch 33, Error rate: 0.5172413793103449\n",
      "Epoch 34, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 35, Error rate: 0.5172413793103449\n",
      "Epoch 36, Error rate: 0.5172413793103449\n",
      "Epoch 37, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 38, Error rate: 0.5172413793103449\n",
      "Epoch 39, Error rate: 0.5172413793103449\n",
      "Epoch 40, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 41, Error rate: 0.5172413793103449\n",
      "Epoch 42, Error rate: 0.5172413793103449\n",
      "Epoch 43, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 44, Error rate: 0.5172413793103449\n",
      "Epoch 45, Error rate: 0.5172413793103449\n",
      "Epoch 46, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 47, Error rate: 0.5172413793103449\n",
      "Epoch 48, Error rate: 0.5172413793103449\n",
      "Epoch 49, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 50, Error rate: 0.5172413793103449\n",
      "Epoch 51, Error rate: 0.5172413793103449\n",
      "Epoch 52, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 53, Error rate: 0.5172413793103449\n",
      "Epoch 54, Error rate: 0.5172413793103449\n",
      "Epoch 55, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 56, Error rate: 0.5172413793103449\n",
      "Epoch 57, Error rate: 0.5172413793103449\n",
      "Epoch 58, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 59, Error rate: 0.5172413793103449\n",
      "Epoch 60, Error rate: 0.5172413793103449\n",
      "Epoch 61, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 62, Error rate: 0.5172413793103449\n",
      "Epoch 63, Error rate: 0.5172413793103449\n",
      "Epoch 64, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 65, Error rate: 0.5172413793103449\n",
      "Epoch 66, Error rate: 0.5172413793103449\n",
      "Epoch 67, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 68, Error rate: 0.5172413793103449\n",
      "Epoch 69, Error rate: 0.5172413793103449\n",
      "Epoch 70, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 71, Error rate: 0.5172413793103449\n",
      "Epoch 72, Error rate: 0.5172413793103449\n",
      "Epoch 73, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 74, Error rate: 0.5172413793103449\n",
      "Epoch 75, Error rate: 0.5172413793103449\n",
      "Epoch 76, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 77, Error rate: 0.5172413793103449\n",
      "Epoch 78, Error rate: 0.5172413793103449\n",
      "Epoch 79, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 80, Error rate: 0.5172413793103449\n",
      "Epoch 81, Error rate: 0.5172413793103449\n",
      "Epoch 82, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 83, Error rate: 0.5172413793103449\n",
      "Epoch 84, Error rate: 0.5172413793103449\n",
      "Epoch 85, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 86, Error rate: 0.5172413793103449\n",
      "Epoch 87, Error rate: 0.5172413793103449\n",
      "Epoch 88, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 89, Error rate: 0.5172413793103449\n",
      "Epoch 90, Error rate: 0.5172413793103449\n",
      "Epoch 91, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000008e-33\n",
      "Epoch 92, Error rate: 0.5172413793103449\n",
      "Epoch 93, Error rate: 0.5172413793103449\n",
      "Epoch 94, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000007e-34\n",
      "Epoch 95, Error rate: 0.5172413793103449\n",
      "Epoch 96, Error rate: 0.5172413793103449\n",
      "Epoch 97, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.0000000000000008e-35\n",
      "Epoch 98, Error rate: 0.5172413793103449\n",
      "Epoch 99, Error rate: 0.5172413793103449\n",
      "Epoch 100, Error rate: 0.5172413793103449\n",
      "Adjusting learning rate to 2.000000000000001e-36\n",
      "Reg lambda: 1, Average error rate: 0.5524312896405918\n",
      "Epoch 1, Error rate: 0.5606936416184971\n",
      "Epoch 2, Error rate: 0.5202312138728323\n",
      "Epoch 3, Error rate: 0.5028901734104047\n",
      "Epoch 4, Error rate: 0.49710982658959535\n",
      "Epoch 5, Error rate: 0.48554913294797686\n",
      "Epoch 6, Error rate: 0.4682080924855491\n",
      "Epoch 7, Error rate: 0.3872832369942196\n",
      "Epoch 8, Error rate: 0.34104046242774566\n",
      "Epoch 9, Error rate: 0.30057803468208094\n",
      "Epoch 10, Error rate: 0.26011560693641617\n",
      "Epoch 11, Error rate: 0.23121387283236994\n",
      "Epoch 12, Error rate: 0.2138728323699422\n",
      "Epoch 13, Error rate: 0.20809248554913296\n",
      "Epoch 14, Error rate: 0.18497109826589594\n",
      "Epoch 15, Error rate: 0.15028901734104047\n",
      "Epoch 16, Error rate: 0.12716763005780346\n",
      "Epoch 17, Error rate: 0.1329479768786127\n",
      "Epoch 18, Error rate: 0.13872832369942195\n",
      "Epoch 19, Error rate: 0.12138728323699421\n",
      "Epoch 20, Error rate: 0.12716763005780346\n",
      "Epoch 21, Error rate: 0.10982658959537572\n",
      "Epoch 22, Error rate: 0.09248554913294797\n",
      "Epoch 23, Error rate: 0.09826589595375723\n",
      "Epoch 24, Error rate: 0.09248554913294797\n",
      "Epoch 25, Error rate: 0.08092485549132948\n",
      "Epoch 26, Error rate: 0.08092485549132948\n",
      "Epoch 27, Error rate: 0.06936416184971098\n",
      "Epoch 28, Error rate: 0.046242774566473986\n",
      "Epoch 29, Error rate: 0.057803468208092484\n",
      "Epoch 30, Error rate: 0.057803468208092484\n",
      "Epoch 31, Error rate: 0.057803468208092484\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 32, Error rate: 0.09248554913294797\n",
      "Epoch 33, Error rate: 0.08670520231213873\n",
      "Epoch 34, Error rate: 0.08670520231213873\n",
      "Epoch 35, Error rate: 0.09248554913294797\n",
      "Epoch 36, Error rate: 0.09248554913294797\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 37, Error rate: 0.08670520231213873\n",
      "Epoch 38, Error rate: 0.08670520231213873\n",
      "Epoch 39, Error rate: 0.08670520231213873\n",
      "Epoch 40, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 41, Error rate: 0.08670520231213873\n",
      "Epoch 42, Error rate: 0.08670520231213873\n",
      "Epoch 43, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 44, Error rate: 0.08670520231213873\n",
      "Epoch 45, Error rate: 0.08670520231213873\n",
      "Epoch 46, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 47, Error rate: 0.08670520231213873\n",
      "Epoch 48, Error rate: 0.08670520231213873\n",
      "Epoch 49, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 50, Error rate: 0.08670520231213873\n",
      "Epoch 51, Error rate: 0.08670520231213873\n",
      "Epoch 52, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 53, Error rate: 0.08670520231213873\n",
      "Epoch 54, Error rate: 0.08670520231213873\n",
      "Epoch 55, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 56, Error rate: 0.08670520231213873\n",
      "Epoch 57, Error rate: 0.08670520231213873\n",
      "Epoch 58, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 59, Error rate: 0.08670520231213873\n",
      "Epoch 60, Error rate: 0.08670520231213873\n",
      "Epoch 61, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 62, Error rate: 0.08670520231213873\n",
      "Epoch 63, Error rate: 0.08670520231213873\n",
      "Epoch 64, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 65, Error rate: 0.08670520231213873\n",
      "Epoch 66, Error rate: 0.08670520231213873\n",
      "Epoch 67, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 68, Error rate: 0.08670520231213873\n",
      "Epoch 69, Error rate: 0.08670520231213873\n",
      "Epoch 70, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 71, Error rate: 0.08670520231213873\n",
      "Epoch 72, Error rate: 0.08670520231213873\n",
      "Epoch 73, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 74, Error rate: 0.08670520231213873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, Error rate: 0.08670520231213873\n",
      "Epoch 76, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 77, Error rate: 0.08670520231213873\n",
      "Epoch 78, Error rate: 0.08670520231213873\n",
      "Epoch 79, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 80, Error rate: 0.08670520231213873\n",
      "Epoch 81, Error rate: 0.08670520231213873\n",
      "Epoch 82, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 83, Error rate: 0.08670520231213873\n",
      "Epoch 84, Error rate: 0.08670520231213873\n",
      "Epoch 85, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 86, Error rate: 0.08670520231213873\n",
      "Epoch 87, Error rate: 0.08670520231213873\n",
      "Epoch 88, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 89, Error rate: 0.08670520231213873\n",
      "Epoch 90, Error rate: 0.08670520231213873\n",
      "Epoch 91, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 92, Error rate: 0.08670520231213873\n",
      "Epoch 93, Error rate: 0.08670520231213873\n",
      "Epoch 94, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 95, Error rate: 0.08670520231213873\n",
      "Epoch 96, Error rate: 0.08670520231213873\n",
      "Epoch 97, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 98, Error rate: 0.08670520231213873\n",
      "Epoch 99, Error rate: 0.08670520231213873\n",
      "Epoch 100, Error rate: 0.08670520231213873\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 1, Error rate: 0.34104046242774566\n",
      "Epoch 2, Error rate: 0.32947976878612717\n",
      "Epoch 3, Error rate: 0.30057803468208094\n",
      "Epoch 4, Error rate: 0.27167630057803466\n",
      "Epoch 5, Error rate: 0.2658959537572254\n",
      "Epoch 6, Error rate: 0.2658959537572254\n",
      "Epoch 7, Error rate: 0.2543352601156069\n",
      "Epoch 8, Error rate: 0.23699421965317918\n",
      "Epoch 9, Error rate: 0.23699421965317918\n",
      "Epoch 10, Error rate: 0.23121387283236994\n",
      "Epoch 11, Error rate: 0.23121387283236994\n",
      "Epoch 12, Error rate: 0.23121387283236994\n",
      "Epoch 13, Error rate: 0.21965317919075145\n",
      "Epoch 14, Error rate: 0.19653179190751446\n",
      "Epoch 15, Error rate: 0.1907514450867052\n",
      "Epoch 16, Error rate: 0.18497109826589594\n",
      "Epoch 17, Error rate: 0.17341040462427745\n",
      "Epoch 18, Error rate: 0.16184971098265896\n",
      "Epoch 19, Error rate: 0.14450867052023122\n",
      "Epoch 20, Error rate: 0.11560693641618497\n",
      "Epoch 21, Error rate: 0.10982658959537572\n",
      "Epoch 22, Error rate: 0.09248554913294797\n",
      "Epoch 23, Error rate: 0.07514450867052024\n",
      "Epoch 24, Error rate: 0.08092485549132948\n",
      "Epoch 25, Error rate: 0.09248554913294797\n",
      "Epoch 26, Error rate: 0.06936416184971098\n",
      "Epoch 27, Error rate: 0.07514450867052024\n",
      "Epoch 28, Error rate: 0.09248554913294797\n",
      "Epoch 29, Error rate: 0.057803468208092484\n",
      "Epoch 30, Error rate: 0.057803468208092484\n",
      "Epoch 31, Error rate: 0.06936416184971098\n",
      "Epoch 32, Error rate: 0.06358381502890173\n",
      "Epoch 33, Error rate: 0.06936416184971098\n",
      "Epoch 34, Error rate: 0.06936416184971098\n",
      "Epoch 35, Error rate: 0.07514450867052024\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 36, Error rate: 0.07514450867052024\n",
      "Epoch 37, Error rate: 0.06936416184971098\n",
      "Epoch 38, Error rate: 0.07514450867052024\n",
      "Epoch 39, Error rate: 0.07514450867052024\n",
      "Epoch 40, Error rate: 0.07514450867052024\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 41, Error rate: 0.06358381502890173\n",
      "Epoch 42, Error rate: 0.06358381502890173\n",
      "Epoch 43, Error rate: 0.06358381502890173\n",
      "Epoch 44, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 45, Error rate: 0.06358381502890173\n",
      "Epoch 46, Error rate: 0.06358381502890173\n",
      "Epoch 47, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 48, Error rate: 0.06358381502890173\n",
      "Epoch 49, Error rate: 0.06358381502890173\n",
      "Epoch 50, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 51, Error rate: 0.06358381502890173\n",
      "Epoch 52, Error rate: 0.06358381502890173\n",
      "Epoch 53, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 54, Error rate: 0.06358381502890173\n",
      "Epoch 55, Error rate: 0.06358381502890173\n",
      "Epoch 56, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 57, Error rate: 0.06358381502890173\n",
      "Epoch 58, Error rate: 0.06358381502890173\n",
      "Epoch 59, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 60, Error rate: 0.06358381502890173\n",
      "Epoch 61, Error rate: 0.06358381502890173\n",
      "Epoch 62, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 63, Error rate: 0.06358381502890173\n",
      "Epoch 64, Error rate: 0.06358381502890173\n",
      "Epoch 65, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 66, Error rate: 0.06358381502890173\n",
      "Epoch 67, Error rate: 0.06358381502890173\n",
      "Epoch 68, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 69, Error rate: 0.06358381502890173\n",
      "Epoch 70, Error rate: 0.06358381502890173\n",
      "Epoch 71, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 72, Error rate: 0.06358381502890173\n",
      "Epoch 73, Error rate: 0.06358381502890173\n",
      "Epoch 74, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 75, Error rate: 0.06358381502890173\n",
      "Epoch 76, Error rate: 0.06358381502890173\n",
      "Epoch 77, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 78, Error rate: 0.06358381502890173\n",
      "Epoch 79, Error rate: 0.06358381502890173\n",
      "Epoch 80, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 81, Error rate: 0.06358381502890173\n",
      "Epoch 82, Error rate: 0.06358381502890173\n",
      "Epoch 83, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 84, Error rate: 0.06358381502890173\n",
      "Epoch 85, Error rate: 0.06358381502890173\n",
      "Epoch 86, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 87, Error rate: 0.06358381502890173\n",
      "Epoch 88, Error rate: 0.06358381502890173\n",
      "Epoch 89, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 90, Error rate: 0.06358381502890173\n",
      "Epoch 91, Error rate: 0.06358381502890173\n",
      "Epoch 92, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 93, Error rate: 0.06358381502890173\n",
      "Epoch 94, Error rate: 0.06358381502890173\n",
      "Epoch 95, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 96, Error rate: 0.06358381502890173\n",
      "Epoch 97, Error rate: 0.06358381502890173\n",
      "Epoch 98, Error rate: 0.06358381502890173\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 99, Error rate: 0.06358381502890173\n",
      "Epoch 100, Error rate: 0.06358381502890173\n",
      "Epoch 1, Error rate: 0.4885057471264368\n",
      "Epoch 2, Error rate: 0.47701149425287354\n",
      "Epoch 3, Error rate: 0.5229885057471264\n",
      "Epoch 4, Error rate: 0.5459770114942529\n",
      "Epoch 5, Error rate: 0.5172413793103449\n",
      "Epoch 6, Error rate: 0.47701149425287354\n",
      "Epoch 7, Error rate: 0.43103448275862066\n",
      "Epoch 8, Error rate: 0.3793103448275862\n",
      "Epoch 9, Error rate: 0.3275862068965517\n",
      "Epoch 10, Error rate: 0.3103448275862069\n",
      "Epoch 11, Error rate: 0.26436781609195403\n",
      "Epoch 12, Error rate: 0.2413793103448276\n",
      "Epoch 13, Error rate: 0.20689655172413793\n",
      "Epoch 14, Error rate: 0.16091954022988506\n",
      "Epoch 15, Error rate: 0.13218390804597702\n",
      "Epoch 16, Error rate: 0.13218390804597702\n",
      "Epoch 17, Error rate: 0.13218390804597702\n",
      "Epoch 18, Error rate: 0.11494252873563218\n",
      "Epoch 19, Error rate: 0.09195402298850575\n",
      "Epoch 20, Error rate: 0.09770114942528736\n",
      "Epoch 21, Error rate: 0.08620689655172414\n",
      "Epoch 22, Error rate: 0.08620689655172414\n",
      "Epoch 23, Error rate: 0.08045977011494253\n",
      "Epoch 24, Error rate: 0.09195402298850575\n",
      "Epoch 25, Error rate: 0.08045977011494253\n",
      "Epoch 26, Error rate: 0.09770114942528736\n",
      "Epoch 27, Error rate: 0.07471264367816093\n",
      "Epoch 28, Error rate: 0.08045977011494253\n",
      "Epoch 29, Error rate: 0.07471264367816093\n",
      "Epoch 30, Error rate: 0.05747126436781609\n",
      "Epoch 31, Error rate: 0.07471264367816093\n",
      "Epoch 32, Error rate: 0.06321839080459771\n",
      "Epoch 33, Error rate: 0.07471264367816093\n",
      "Epoch 34, Error rate: 0.08045977011494253\n",
      "Epoch 35, Error rate: 0.06321839080459771\n",
      "Epoch 36, Error rate: 0.06896551724137931\n",
      "Epoch 37, Error rate: 0.04597701149425287\n",
      "Epoch 38, Error rate: 0.08045977011494253\n",
      "Epoch 39, Error rate: 0.05747126436781609\n",
      "Epoch 40, Error rate: 0.06896551724137931\n",
      "Epoch 41, Error rate: 0.08045977011494253\n",
      "Epoch 42, Error rate: 0.08045977011494253\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 43, Error rate: 0.07471264367816093\n",
      "Epoch 44, Error rate: 0.040229885057471264\n",
      "Epoch 45, Error rate: 0.034482758620689655\n",
      "Epoch 46, Error rate: 0.034482758620689655\n",
      "Epoch 47, Error rate: 0.034482758620689655\n",
      "Epoch 48, Error rate: 0.034482758620689655\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 49, Error rate: 0.06321839080459771\n",
      "Epoch 50, Error rate: 0.05172413793103448\n",
      "Epoch 51, Error rate: 0.05172413793103448\n",
      "Epoch 52, Error rate: 0.040229885057471264\n",
      "Epoch 53, Error rate: 0.040229885057471264\n",
      "Epoch 54, Error rate: 0.040229885057471264\n",
      "Epoch 55, Error rate: 0.040229885057471264\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 56, Error rate: 0.040229885057471264\n",
      "Epoch 57, Error rate: 0.040229885057471264\n",
      "Epoch 58, Error rate: 0.040229885057471264\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 59, Error rate: 0.040229885057471264\n",
      "Epoch 60, Error rate: 0.040229885057471264\n",
      "Epoch 61, Error rate: 0.040229885057471264\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 62, Error rate: 0.040229885057471264\n",
      "Epoch 63, Error rate: 0.040229885057471264\n",
      "Epoch 64, Error rate: 0.040229885057471264\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 65, Error rate: 0.040229885057471264\n",
      "Epoch 66, Error rate: 0.040229885057471264\n",
      "Epoch 67, Error rate: 0.040229885057471264\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 68, Error rate: 0.040229885057471264\n",
      "Epoch 69, Error rate: 0.040229885057471264\n",
      "Epoch 70, Error rate: 0.040229885057471264\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 71, Error rate: 0.040229885057471264\n",
      "Epoch 72, Error rate: 0.040229885057471264\n",
      "Epoch 73, Error rate: 0.040229885057471264\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 74, Error rate: 0.040229885057471264\n",
      "Epoch 75, Error rate: 0.040229885057471264\n",
      "Epoch 76, Error rate: 0.040229885057471264\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 77, Error rate: 0.040229885057471264\n",
      "Epoch 78, Error rate: 0.040229885057471264\n",
      "Epoch 79, Error rate: 0.040229885057471264\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 80, Error rate: 0.040229885057471264\n",
      "Epoch 81, Error rate: 0.040229885057471264\n",
      "Epoch 82, Error rate: 0.040229885057471264\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 83, Error rate: 0.040229885057471264\n",
      "Epoch 84, Error rate: 0.040229885057471264\n",
      "Epoch 85, Error rate: 0.040229885057471264\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 86, Error rate: 0.040229885057471264\n",
      "Epoch 87, Error rate: 0.040229885057471264\n",
      "Epoch 88, Error rate: 0.040229885057471264\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 89, Error rate: 0.040229885057471264\n",
      "Epoch 90, Error rate: 0.040229885057471264\n",
      "Epoch 91, Error rate: 0.040229885057471264\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 92, Error rate: 0.040229885057471264\n",
      "Epoch 93, Error rate: 0.040229885057471264\n",
      "Epoch 94, Error rate: 0.040229885057471264\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 95, Error rate: 0.040229885057471264\n",
      "Epoch 96, Error rate: 0.040229885057471264\n",
      "Epoch 97, Error rate: 0.040229885057471264\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 98, Error rate: 0.040229885057471264\n",
      "Epoch 99, Error rate: 0.040229885057471264\n",
      "Epoch 100, Error rate: 0.040229885057471264\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 1, Error rate: 0.6494252873563219\n",
      "Epoch 2, Error rate: 0.632183908045977\n",
      "Epoch 3, Error rate: 0.5689655172413793\n",
      "Epoch 4, Error rate: 0.45977011494252873\n",
      "Epoch 5, Error rate: 0.3735632183908046\n",
      "Epoch 6, Error rate: 0.3045977011494253\n",
      "Epoch 7, Error rate: 0.25862068965517243\n",
      "Epoch 8, Error rate: 0.20114942528735633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Error rate: 0.16666666666666666\n",
      "Epoch 10, Error rate: 0.13218390804597702\n",
      "Epoch 11, Error rate: 0.10344827586206896\n",
      "Epoch 12, Error rate: 0.09195402298850575\n",
      "Epoch 13, Error rate: 0.06896551724137931\n",
      "Epoch 14, Error rate: 0.06896551724137931\n",
      "Epoch 15, Error rate: 0.06896551724137931\n",
      "Epoch 16, Error rate: 0.06896551724137931\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 17, Error rate: 0.09195402298850575\n",
      "Epoch 18, Error rate: 0.06896551724137931\n",
      "Epoch 19, Error rate: 0.06321839080459771\n",
      "Epoch 20, Error rate: 0.06321839080459771\n",
      "Epoch 21, Error rate: 0.05747126436781609\n",
      "Epoch 22, Error rate: 0.06321839080459771\n",
      "Epoch 23, Error rate: 0.05747126436781609\n",
      "Epoch 24, Error rate: 0.05747126436781609\n",
      "Epoch 25, Error rate: 0.06321839080459771\n",
      "Epoch 26, Error rate: 0.05747126436781609\n",
      "Epoch 27, Error rate: 0.06321839080459771\n",
      "Epoch 28, Error rate: 0.05747126436781609\n",
      "Epoch 29, Error rate: 0.06321839080459771\n",
      "Epoch 30, Error rate: 0.05747126436781609\n",
      "Epoch 31, Error rate: 0.05747126436781609\n",
      "Epoch 32, Error rate: 0.06321839080459771\n",
      "Epoch 33, Error rate: 0.05747126436781609\n",
      "Epoch 34, Error rate: 0.06321839080459771\n",
      "Epoch 35, Error rate: 0.05747126436781609\n",
      "Epoch 36, Error rate: 0.06321839080459771\n",
      "Epoch 37, Error rate: 0.05747126436781609\n",
      "Epoch 38, Error rate: 0.06321839080459771\n",
      "Epoch 39, Error rate: 0.05747126436781609\n",
      "Epoch 40, Error rate: 0.05747126436781609\n",
      "Epoch 41, Error rate: 0.06321839080459771\n",
      "Epoch 42, Error rate: 0.05172413793103448\n",
      "Epoch 43, Error rate: 0.05747126436781609\n",
      "Epoch 44, Error rate: 0.06321839080459771\n",
      "Epoch 45, Error rate: 0.05172413793103448\n",
      "Epoch 46, Error rate: 0.05747126436781609\n",
      "Epoch 47, Error rate: 0.05172413793103448\n",
      "Epoch 48, Error rate: 0.05172413793103448\n",
      "Epoch 49, Error rate: 0.05747126436781609\n",
      "Epoch 50, Error rate: 0.05172413793103448\n",
      "Epoch 51, Error rate: 0.05747126436781609\n",
      "Epoch 52, Error rate: 0.05172413793103448\n",
      "Epoch 53, Error rate: 0.05747126436781609\n",
      "Epoch 54, Error rate: 0.05172413793103448\n",
      "Epoch 55, Error rate: 0.05172413793103448\n",
      "Epoch 56, Error rate: 0.04597701149425287\n",
      "Epoch 57, Error rate: 0.05172413793103448\n",
      "Epoch 58, Error rate: 0.040229885057471264\n",
      "Epoch 59, Error rate: 0.04597701149425287\n",
      "Epoch 60, Error rate: 0.040229885057471264\n",
      "Epoch 61, Error rate: 0.04597701149425287\n",
      "Epoch 62, Error rate: 0.04597701149425287\n",
      "Epoch 63, Error rate: 0.05172413793103448\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 64, Error rate: 0.04597701149425287\n",
      "Epoch 65, Error rate: 0.04597701149425287\n",
      "Epoch 66, Error rate: 0.04597701149425287\n",
      "Epoch 67, Error rate: 0.04597701149425287\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 68, Error rate: 0.04597701149425287\n",
      "Epoch 69, Error rate: 0.04597701149425287\n",
      "Epoch 70, Error rate: 0.04597701149425287\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 71, Error rate: 0.04597701149425287\n",
      "Epoch 72, Error rate: 0.04597701149425287\n",
      "Epoch 73, Error rate: 0.04597701149425287\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 74, Error rate: 0.04597701149425287\n",
      "Epoch 75, Error rate: 0.04597701149425287\n",
      "Epoch 76, Error rate: 0.04597701149425287\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 77, Error rate: 0.04597701149425287\n",
      "Epoch 78, Error rate: 0.04597701149425287\n",
      "Epoch 79, Error rate: 0.04597701149425287\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 80, Error rate: 0.04597701149425287\n",
      "Epoch 81, Error rate: 0.04597701149425287\n",
      "Epoch 82, Error rate: 0.04597701149425287\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 83, Error rate: 0.04597701149425287\n",
      "Epoch 84, Error rate: 0.04597701149425287\n",
      "Epoch 85, Error rate: 0.04597701149425287\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 86, Error rate: 0.04597701149425287\n",
      "Epoch 87, Error rate: 0.04597701149425287\n",
      "Epoch 88, Error rate: 0.04597701149425287\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 89, Error rate: 0.04597701149425287\n",
      "Epoch 90, Error rate: 0.04597701149425287\n",
      "Epoch 91, Error rate: 0.04597701149425287\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 92, Error rate: 0.04597701149425287\n",
      "Epoch 93, Error rate: 0.04597701149425287\n",
      "Epoch 94, Error rate: 0.04597701149425287\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 95, Error rate: 0.04597701149425287\n",
      "Epoch 96, Error rate: 0.04597701149425287\n",
      "Epoch 97, Error rate: 0.04597701149425287\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 98, Error rate: 0.04597701149425287\n",
      "Epoch 99, Error rate: 0.04597701149425287\n",
      "Epoch 100, Error rate: 0.04597701149425287\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 1, Error rate: 0.46551724137931033\n",
      "Epoch 2, Error rate: 0.3850574712643678\n",
      "Epoch 3, Error rate: 0.3390804597701149\n",
      "Epoch 4, Error rate: 0.3103448275862069\n",
      "Epoch 5, Error rate: 0.3103448275862069\n",
      "Epoch 6, Error rate: 0.2988505747126437\n",
      "Epoch 7, Error rate: 0.27011494252873564\n",
      "Epoch 8, Error rate: 0.25287356321839083\n",
      "Epoch 9, Error rate: 0.2413793103448276\n",
      "Epoch 10, Error rate: 0.22988505747126436\n",
      "Epoch 11, Error rate: 0.19540229885057472\n",
      "Epoch 12, Error rate: 0.1839080459770115\n",
      "Epoch 13, Error rate: 0.1724137931034483\n",
      "Epoch 14, Error rate: 0.14367816091954022\n",
      "Epoch 15, Error rate: 0.13218390804597702\n",
      "Epoch 16, Error rate: 0.12643678160919541\n",
      "Epoch 17, Error rate: 0.12643678160919541\n",
      "Epoch 18, Error rate: 0.10919540229885058\n",
      "Epoch 19, Error rate: 0.09195402298850575\n",
      "Epoch 20, Error rate: 0.10344827586206896\n",
      "Epoch 21, Error rate: 0.08620689655172414\n",
      "Epoch 22, Error rate: 0.08620689655172414\n",
      "Epoch 23, Error rate: 0.08045977011494253\n",
      "Epoch 24, Error rate: 0.08045977011494253\n",
      "Epoch 25, Error rate: 0.08045977011494253\n",
      "Epoch 26, Error rate: 0.08045977011494253\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 27, Error rate: 0.06896551724137931\n",
      "Epoch 28, Error rate: 0.06896551724137931\n",
      "Epoch 29, Error rate: 0.06896551724137931\n",
      "Epoch 30, Error rate: 0.06896551724137931\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 31, Error rate: 0.05747126436781609\n",
      "Epoch 32, Error rate: 0.05747126436781609\n",
      "Epoch 33, Error rate: 0.05747126436781609\n",
      "Epoch 34, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 35, Error rate: 0.05747126436781609\n",
      "Epoch 36, Error rate: 0.05747126436781609\n",
      "Epoch 37, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 38, Error rate: 0.05747126436781609\n",
      "Epoch 39, Error rate: 0.05747126436781609\n",
      "Epoch 40, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 41, Error rate: 0.05747126436781609\n",
      "Epoch 42, Error rate: 0.05747126436781609\n",
      "Epoch 43, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 44, Error rate: 0.05747126436781609\n",
      "Epoch 45, Error rate: 0.05747126436781609\n",
      "Epoch 46, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 47, Error rate: 0.05747126436781609\n",
      "Epoch 48, Error rate: 0.05747126436781609\n",
      "Epoch 49, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 50, Error rate: 0.05747126436781609\n",
      "Epoch 51, Error rate: 0.05747126436781609\n",
      "Epoch 52, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 53, Error rate: 0.05747126436781609\n",
      "Epoch 54, Error rate: 0.05747126436781609\n",
      "Epoch 55, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 56, Error rate: 0.05747126436781609\n",
      "Epoch 57, Error rate: 0.05747126436781609\n",
      "Epoch 58, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 59, Error rate: 0.05747126436781609\n",
      "Epoch 60, Error rate: 0.05747126436781609\n",
      "Epoch 61, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 62, Error rate: 0.05747126436781609\n",
      "Epoch 63, Error rate: 0.05747126436781609\n",
      "Epoch 64, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 65, Error rate: 0.05747126436781609\n",
      "Epoch 66, Error rate: 0.05747126436781609\n",
      "Epoch 67, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 68, Error rate: 0.05747126436781609\n",
      "Epoch 69, Error rate: 0.05747126436781609\n",
      "Epoch 70, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 71, Error rate: 0.05747126436781609\n",
      "Epoch 72, Error rate: 0.05747126436781609\n",
      "Epoch 73, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 74, Error rate: 0.05747126436781609\n",
      "Epoch 75, Error rate: 0.05747126436781609\n",
      "Epoch 76, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 77, Error rate: 0.05747126436781609\n",
      "Epoch 78, Error rate: 0.05747126436781609\n",
      "Epoch 79, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 80, Error rate: 0.05747126436781609\n",
      "Epoch 81, Error rate: 0.05747126436781609\n",
      "Epoch 82, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 83, Error rate: 0.05747126436781609\n",
      "Epoch 84, Error rate: 0.05747126436781609\n",
      "Epoch 85, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 86, Error rate: 0.05747126436781609\n",
      "Epoch 87, Error rate: 0.05747126436781609\n",
      "Epoch 88, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 89, Error rate: 0.05747126436781609\n",
      "Epoch 90, Error rate: 0.05747126436781609\n",
      "Epoch 91, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 92, Error rate: 0.05747126436781609\n",
      "Epoch 93, Error rate: 0.05747126436781609\n",
      "Epoch 94, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 95, Error rate: 0.05747126436781609\n",
      "Epoch 96, Error rate: 0.05747126436781609\n",
      "Epoch 97, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 98, Error rate: 0.05747126436781609\n",
      "Epoch 99, Error rate: 0.05747126436781609\n",
      "Epoch 100, Error rate: 0.05747126436781609\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Reg lambda: 10, Average error rate: 0.09714587737843551\n",
      "Epoch 1, Error rate: 0.36416184971098264\n",
      "Epoch 2, Error rate: 0.23121387283236994\n",
      "Epoch 3, Error rate: 0.1676300578034682\n",
      "Epoch 4, Error rate: 0.10982658959537572\n",
      "Epoch 5, Error rate: 0.06358381502890173\n",
      "Epoch 6, Error rate: 0.057803468208092484\n",
      "Epoch 7, Error rate: 0.06358381502890173\n",
      "Epoch 8, Error rate: 0.057803468208092484\n",
      "Epoch 9, Error rate: 0.04046242774566474\n",
      "Epoch 10, Error rate: 0.046242774566473986\n",
      "Epoch 11, Error rate: 0.06936416184971098\n",
      "Epoch 12, Error rate: 0.046242774566473986\n",
      "Epoch 13, Error rate: 0.057803468208092484\n",
      "Epoch 14, Error rate: 0.06936416184971098\n",
      "Epoch 15, Error rate: 0.06358381502890173\n",
      "Epoch 16, Error rate: 0.09248554913294797\n",
      "Epoch 17, Error rate: 0.03468208092485549\n",
      "Epoch 18, Error rate: 0.03468208092485549\n",
      "Epoch 19, Error rate: 0.057803468208092484\n",
      "Epoch 20, Error rate: 0.057803468208092484\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 21, Error rate: 0.06358381502890173\n",
      "Epoch 22, Error rate: 0.023121387283236993\n",
      "Epoch 23, Error rate: 0.03468208092485549\n",
      "Epoch 24, Error rate: 0.017341040462427744\n",
      "Epoch 25, Error rate: 0.023121387283236993\n",
      "Epoch 26, Error rate: 0.04046242774566474\n",
      "Epoch 27, Error rate: 0.017341040462427744\n",
      "Epoch 28, Error rate: 0.028901734104046242\n",
      "Epoch 29, Error rate: 0.023121387283236993\n",
      "Epoch 30, Error rate: 0.046242774566473986\n",
      "Epoch 31, Error rate: 0.03468208092485549\n",
      "Epoch 32, Error rate: 0.023121387283236993\n",
      "Epoch 33, Error rate: 0.03468208092485549\n",
      "Epoch 34, Error rate: 0.023121387283236993\n",
      "Epoch 35, Error rate: 0.03468208092485549\n",
      "Epoch 36, Error rate: 0.03468208092485549\n",
      "Epoch 37, Error rate: 0.046242774566473986\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 38, Error rate: 0.06358381502890173\n",
      "Epoch 39, Error rate: 0.028901734104046242\n",
      "Epoch 40, Error rate: 0.011560693641618497\n",
      "Epoch 41, Error rate: 0.017341040462427744\n",
      "Epoch 42, Error rate: 0.017341040462427744\n",
      "Epoch 43, Error rate: 0.011560693641618497\n",
      "Epoch 44, Error rate: 0.017341040462427744\n",
      "Epoch 45, Error rate: 0.028901734104046242\n",
      "Epoch 46, Error rate: 0.011560693641618497\n",
      "Epoch 47, Error rate: 0.023121387283236993\n",
      "Epoch 48, Error rate: 0.028901734104046242\n",
      "Epoch 49, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 50, Error rate: 0.028901734104046242\n",
      "Epoch 51, Error rate: 0.017341040462427744\n",
      "Epoch 52, Error rate: 0.023121387283236993\n",
      "Epoch 53, Error rate: 0.023121387283236993\n",
      "Epoch 54, Error rate: 0.017341040462427744\n",
      "Epoch 55, Error rate: 0.017341040462427744\n",
      "Epoch 56, Error rate: 0.017341040462427744\n",
      "Epoch 57, Error rate: 0.017341040462427744\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 58, Error rate: 0.023121387283236993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Error rate: 0.023121387283236993\n",
      "Epoch 60, Error rate: 0.023121387283236993\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 61, Error rate: 0.017341040462427744\n",
      "Epoch 62, Error rate: 0.017341040462427744\n",
      "Epoch 63, Error rate: 0.017341040462427744\n",
      "Epoch 64, Error rate: 0.017341040462427744\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 65, Error rate: 0.017341040462427744\n",
      "Epoch 66, Error rate: 0.017341040462427744\n",
      "Epoch 67, Error rate: 0.017341040462427744\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 68, Error rate: 0.017341040462427744\n",
      "Epoch 69, Error rate: 0.017341040462427744\n",
      "Epoch 70, Error rate: 0.017341040462427744\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 71, Error rate: 0.017341040462427744\n",
      "Epoch 72, Error rate: 0.017341040462427744\n",
      "Epoch 73, Error rate: 0.017341040462427744\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 74, Error rate: 0.017341040462427744\n",
      "Epoch 75, Error rate: 0.017341040462427744\n",
      "Epoch 76, Error rate: 0.017341040462427744\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 77, Error rate: 0.017341040462427744\n",
      "Epoch 78, Error rate: 0.017341040462427744\n",
      "Epoch 79, Error rate: 0.017341040462427744\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 80, Error rate: 0.017341040462427744\n",
      "Epoch 81, Error rate: 0.017341040462427744\n",
      "Epoch 82, Error rate: 0.017341040462427744\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 83, Error rate: 0.017341040462427744\n",
      "Epoch 84, Error rate: 0.017341040462427744\n",
      "Epoch 85, Error rate: 0.017341040462427744\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 86, Error rate: 0.017341040462427744\n",
      "Epoch 87, Error rate: 0.017341040462427744\n",
      "Epoch 88, Error rate: 0.017341040462427744\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 89, Error rate: 0.017341040462427744\n",
      "Epoch 90, Error rate: 0.017341040462427744\n",
      "Epoch 91, Error rate: 0.017341040462427744\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 92, Error rate: 0.017341040462427744\n",
      "Epoch 93, Error rate: 0.017341040462427744\n",
      "Epoch 94, Error rate: 0.017341040462427744\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 95, Error rate: 0.017341040462427744\n",
      "Epoch 96, Error rate: 0.017341040462427744\n",
      "Epoch 97, Error rate: 0.017341040462427744\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 98, Error rate: 0.017341040462427744\n",
      "Epoch 99, Error rate: 0.017341040462427744\n",
      "Epoch 100, Error rate: 0.017341040462427744\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 1, Error rate: 0.4393063583815029\n",
      "Epoch 2, Error rate: 0.2832369942196532\n",
      "Epoch 3, Error rate: 0.16184971098265896\n",
      "Epoch 4, Error rate: 0.09248554913294797\n",
      "Epoch 5, Error rate: 0.06358381502890173\n",
      "Epoch 6, Error rate: 0.06358381502890173\n",
      "Epoch 7, Error rate: 0.06358381502890173\n",
      "Epoch 8, Error rate: 0.06936416184971098\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 9, Error rate: 0.07514450867052024\n",
      "Epoch 10, Error rate: 0.028901734104046242\n",
      "Epoch 11, Error rate: 0.023121387283236993\n",
      "Epoch 12, Error rate: 0.017341040462427744\n",
      "Epoch 13, Error rate: 0.023121387283236993\n",
      "Epoch 14, Error rate: 0.023121387283236993\n",
      "Epoch 15, Error rate: 0.023121387283236993\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 16, Error rate: 0.028901734104046242\n",
      "Epoch 17, Error rate: 0.023121387283236993\n",
      "Epoch 18, Error rate: 0.023121387283236993\n",
      "Epoch 19, Error rate: 0.028901734104046242\n",
      "Epoch 20, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 21, Error rate: 0.028901734104046242\n",
      "Epoch 22, Error rate: 0.028901734104046242\n",
      "Epoch 23, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 24, Error rate: 0.028901734104046242\n",
      "Epoch 25, Error rate: 0.028901734104046242\n",
      "Epoch 26, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 27, Error rate: 0.028901734104046242\n",
      "Epoch 28, Error rate: 0.028901734104046242\n",
      "Epoch 29, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 30, Error rate: 0.028901734104046242\n",
      "Epoch 31, Error rate: 0.028901734104046242\n",
      "Epoch 32, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 33, Error rate: 0.028901734104046242\n",
      "Epoch 34, Error rate: 0.028901734104046242\n",
      "Epoch 35, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 36, Error rate: 0.028901734104046242\n",
      "Epoch 37, Error rate: 0.028901734104046242\n",
      "Epoch 38, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 39, Error rate: 0.028901734104046242\n",
      "Epoch 40, Error rate: 0.028901734104046242\n",
      "Epoch 41, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 42, Error rate: 0.028901734104046242\n",
      "Epoch 43, Error rate: 0.028901734104046242\n",
      "Epoch 44, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 45, Error rate: 0.028901734104046242\n",
      "Epoch 46, Error rate: 0.028901734104046242\n",
      "Epoch 47, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 48, Error rate: 0.028901734104046242\n",
      "Epoch 49, Error rate: 0.028901734104046242\n",
      "Epoch 50, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 51, Error rate: 0.028901734104046242\n",
      "Epoch 52, Error rate: 0.028901734104046242\n",
      "Epoch 53, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 54, Error rate: 0.028901734104046242\n",
      "Epoch 55, Error rate: 0.028901734104046242\n",
      "Epoch 56, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 57, Error rate: 0.028901734104046242\n",
      "Epoch 58, Error rate: 0.028901734104046242\n",
      "Epoch 59, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 60, Error rate: 0.028901734104046242\n",
      "Epoch 61, Error rate: 0.028901734104046242\n",
      "Epoch 62, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 63, Error rate: 0.028901734104046242\n",
      "Epoch 64, Error rate: 0.028901734104046242\n",
      "Epoch 65, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 66, Error rate: 0.028901734104046242\n",
      "Epoch 67, Error rate: 0.028901734104046242\n",
      "Epoch 68, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 69, Error rate: 0.028901734104046242\n",
      "Epoch 70, Error rate: 0.028901734104046242\n",
      "Epoch 71, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 72, Error rate: 0.028901734104046242\n",
      "Epoch 73, Error rate: 0.028901734104046242\n",
      "Epoch 74, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 75, Error rate: 0.028901734104046242\n",
      "Epoch 76, Error rate: 0.028901734104046242\n",
      "Epoch 77, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 78, Error rate: 0.028901734104046242\n",
      "Epoch 79, Error rate: 0.028901734104046242\n",
      "Epoch 80, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 81, Error rate: 0.028901734104046242\n",
      "Epoch 82, Error rate: 0.028901734104046242\n",
      "Epoch 83, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 84, Error rate: 0.028901734104046242\n",
      "Epoch 85, Error rate: 0.028901734104046242\n",
      "Epoch 86, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 87, Error rate: 0.028901734104046242\n",
      "Epoch 88, Error rate: 0.028901734104046242\n",
      "Epoch 89, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 90, Error rate: 0.028901734104046242\n",
      "Epoch 91, Error rate: 0.028901734104046242\n",
      "Epoch 92, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 93, Error rate: 0.028901734104046242\n",
      "Epoch 94, Error rate: 0.028901734104046242\n",
      "Epoch 95, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 96, Error rate: 0.028901734104046242\n",
      "Epoch 97, Error rate: 0.028901734104046242\n",
      "Epoch 98, Error rate: 0.028901734104046242\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 99, Error rate: 0.028901734104046242\n",
      "Epoch 100, Error rate: 0.028901734104046242\n",
      "Epoch 1, Error rate: 0.40229885057471265\n",
      "Epoch 2, Error rate: 0.3103448275862069\n",
      "Epoch 3, Error rate: 0.22988505747126436\n",
      "Epoch 4, Error rate: 0.16091954022988506\n",
      "Epoch 5, Error rate: 0.13218390804597702\n",
      "Epoch 6, Error rate: 0.09195402298850575\n",
      "Epoch 7, Error rate: 0.06896551724137931\n",
      "Epoch 8, Error rate: 0.06321839080459771\n",
      "Epoch 9, Error rate: 0.05172413793103448\n",
      "Epoch 10, Error rate: 0.05747126436781609\n",
      "Epoch 11, Error rate: 0.07471264367816093\n",
      "Epoch 12, Error rate: 0.06896551724137931\n",
      "Epoch 13, Error rate: 0.04597701149425287\n",
      "Epoch 14, Error rate: 0.040229885057471264\n",
      "Epoch 15, Error rate: 0.05172413793103448\n",
      "Epoch 16, Error rate: 0.08045977011494253\n",
      "Epoch 17, Error rate: 0.06896551724137931\n",
      "Epoch 18, Error rate: 0.08045977011494253\n",
      "Epoch 19, Error rate: 0.08045977011494253\n",
      "Epoch 20, Error rate: 0.06896551724137931\n",
      "Epoch 21, Error rate: 0.06896551724137931\n",
      "Epoch 22, Error rate: 0.05747126436781609\n",
      "Epoch 23, Error rate: 0.05747126436781609\n",
      "Epoch 24, Error rate: 0.06896551724137931\n",
      "Epoch 25, Error rate: 0.06896551724137931\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 26, Error rate: 0.05747126436781609\n",
      "Epoch 27, Error rate: 0.017241379310344827\n",
      "Epoch 28, Error rate: 0.011494252873563218\n",
      "Epoch 29, Error rate: 0.005747126436781609\n",
      "Epoch 30, Error rate: 0.011494252873563218\n",
      "Epoch 31, Error rate: 0.011494252873563218\n",
      "Epoch 32, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 33, Error rate: 0.017241379310344827\n",
      "Epoch 34, Error rate: 0.011494252873563218\n",
      "Epoch 35, Error rate: 0.011494252873563218\n",
      "Epoch 36, Error rate: 0.011494252873563218\n",
      "Epoch 37, Error rate: 0.022988505747126436\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 38, Error rate: 0.017241379310344827\n",
      "Epoch 39, Error rate: 0.011494252873563218\n",
      "Epoch 40, Error rate: 0.011494252873563218\n",
      "Epoch 41, Error rate: 0.011494252873563218\n",
      "Epoch 42, Error rate: 0.017241379310344827\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 43, Error rate: 0.011494252873563218\n",
      "Epoch 44, Error rate: 0.011494252873563218\n",
      "Epoch 45, Error rate: 0.011494252873563218\n",
      "Epoch 46, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 47, Error rate: 0.011494252873563218\n",
      "Epoch 48, Error rate: 0.011494252873563218\n",
      "Epoch 49, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 50, Error rate: 0.011494252873563218\n",
      "Epoch 51, Error rate: 0.011494252873563218\n",
      "Epoch 52, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 53, Error rate: 0.011494252873563218\n",
      "Epoch 54, Error rate: 0.011494252873563218\n",
      "Epoch 55, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 56, Error rate: 0.011494252873563218\n",
      "Epoch 57, Error rate: 0.011494252873563218\n",
      "Epoch 58, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 59, Error rate: 0.011494252873563218\n",
      "Epoch 60, Error rate: 0.011494252873563218\n",
      "Epoch 61, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 62, Error rate: 0.011494252873563218\n",
      "Epoch 63, Error rate: 0.011494252873563218\n",
      "Epoch 64, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 65, Error rate: 0.011494252873563218\n",
      "Epoch 66, Error rate: 0.011494252873563218\n",
      "Epoch 67, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 68, Error rate: 0.011494252873563218\n",
      "Epoch 69, Error rate: 0.011494252873563218\n",
      "Epoch 70, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 71, Error rate: 0.011494252873563218\n",
      "Epoch 72, Error rate: 0.011494252873563218\n",
      "Epoch 73, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 74, Error rate: 0.011494252873563218\n",
      "Epoch 75, Error rate: 0.011494252873563218\n",
      "Epoch 76, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 77, Error rate: 0.011494252873563218\n",
      "Epoch 78, Error rate: 0.011494252873563218\n",
      "Epoch 79, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 80, Error rate: 0.011494252873563218\n",
      "Epoch 81, Error rate: 0.011494252873563218\n",
      "Epoch 82, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 83, Error rate: 0.011494252873563218\n",
      "Epoch 84, Error rate: 0.011494252873563218\n",
      "Epoch 85, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 86, Error rate: 0.011494252873563218\n",
      "Epoch 87, Error rate: 0.011494252873563218\n",
      "Epoch 88, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 89, Error rate: 0.011494252873563218\n",
      "Epoch 90, Error rate: 0.011494252873563218\n",
      "Epoch 91, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 92, Error rate: 0.011494252873563218\n",
      "Epoch 93, Error rate: 0.011494252873563218\n",
      "Epoch 94, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 95, Error rate: 0.011494252873563218\n",
      "Epoch 96, Error rate: 0.011494252873563218\n",
      "Epoch 97, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 98, Error rate: 0.011494252873563218\n",
      "Epoch 99, Error rate: 0.011494252873563218\n",
      "Epoch 100, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 1, Error rate: 0.5287356321839081\n",
      "Epoch 2, Error rate: 0.3160919540229885\n",
      "Epoch 3, Error rate: 0.14367816091954022\n",
      "Epoch 4, Error rate: 0.08045977011494253\n",
      "Epoch 5, Error rate: 0.08045977011494253\n",
      "Epoch 6, Error rate: 0.06321839080459771\n",
      "Epoch 7, Error rate: 0.04597701149425287\n",
      "Epoch 8, Error rate: 0.040229885057471264\n",
      "Epoch 9, Error rate: 0.040229885057471264\n",
      "Epoch 10, Error rate: 0.040229885057471264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Error rate: 0.04597701149425287\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 12, Error rate: 0.06321839080459771\n",
      "Epoch 13, Error rate: 0.034482758620689655\n",
      "Epoch 14, Error rate: 0.005747126436781609\n",
      "Epoch 15, Error rate: 0.034482758620689655\n",
      "Epoch 16, Error rate: 0.011494252873563218\n",
      "Epoch 17, Error rate: 0.011494252873563218\n",
      "Epoch 18, Error rate: 0.011494252873563218\n",
      "Epoch 19, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 20, Error rate: 0.011494252873563218\n",
      "Epoch 21, Error rate: 0.011494252873563218\n",
      "Epoch 22, Error rate: 0.0\n",
      "SVM Converged!\n",
      "Epoch 1, Error rate: 0.5862068965517241\n",
      "Epoch 2, Error rate: 0.39655172413793105\n",
      "Epoch 3, Error rate: 0.25287356321839083\n",
      "Epoch 4, Error rate: 0.15517241379310345\n",
      "Epoch 5, Error rate: 0.11494252873563218\n",
      "Epoch 6, Error rate: 0.05747126436781609\n",
      "Epoch 7, Error rate: 0.04597701149425287\n",
      "Epoch 8, Error rate: 0.04597701149425287\n",
      "Epoch 9, Error rate: 0.08045977011494253\n",
      "Epoch 10, Error rate: 0.08045977011494253\n",
      "Adjusting learning rate to 0.0002\n",
      "Epoch 11, Error rate: 0.017241379310344827\n",
      "Epoch 12, Error rate: 0.022988505747126436\n",
      "Epoch 13, Error rate: 0.022988505747126436\n",
      "Epoch 14, Error rate: 0.022988505747126436\n",
      "Adjusting learning rate to 2e-05\n",
      "Epoch 15, Error rate: 0.011494252873563218\n",
      "Epoch 16, Error rate: 0.011494252873563218\n",
      "Epoch 17, Error rate: 0.011494252873563218\n",
      "Epoch 18, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000003e-06\n",
      "Epoch 19, Error rate: 0.017241379310344827\n",
      "Epoch 20, Error rate: 0.011494252873563218\n",
      "Epoch 21, Error rate: 0.011494252873563218\n",
      "Epoch 22, Error rate: 0.011494252873563218\n",
      "Epoch 23, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000004e-07\n",
      "Epoch 24, Error rate: 0.011494252873563218\n",
      "Epoch 25, Error rate: 0.011494252873563218\n",
      "Epoch 26, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000004e-08\n",
      "Epoch 27, Error rate: 0.011494252873563218\n",
      "Epoch 28, Error rate: 0.011494252873563218\n",
      "Epoch 29, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000005e-09\n",
      "Epoch 30, Error rate: 0.011494252873563218\n",
      "Epoch 31, Error rate: 0.011494252873563218\n",
      "Epoch 32, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000006e-10\n",
      "Epoch 33, Error rate: 0.011494252873563218\n",
      "Epoch 34, Error rate: 0.011494252873563218\n",
      "Epoch 35, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000005e-11\n",
      "Epoch 36, Error rate: 0.011494252873563218\n",
      "Epoch 37, Error rate: 0.011494252873563218\n",
      "Epoch 38, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000004e-12\n",
      "Epoch 39, Error rate: 0.011494252873563218\n",
      "Epoch 40, Error rate: 0.011494252873563218\n",
      "Epoch 41, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000003e-13\n",
      "Epoch 42, Error rate: 0.011494252873563218\n",
      "Epoch 43, Error rate: 0.011494252873563218\n",
      "Epoch 44, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000003e-14\n",
      "Epoch 45, Error rate: 0.011494252873563218\n",
      "Epoch 46, Error rate: 0.011494252873563218\n",
      "Epoch 47, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2e-15\n",
      "Epoch 48, Error rate: 0.011494252873563218\n",
      "Epoch 49, Error rate: 0.011494252873563218\n",
      "Epoch 50, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000002e-16\n",
      "Epoch 51, Error rate: 0.011494252873563218\n",
      "Epoch 52, Error rate: 0.011494252873563218\n",
      "Epoch 53, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2e-17\n",
      "Epoch 54, Error rate: 0.011494252873563218\n",
      "Epoch 55, Error rate: 0.011494252873563218\n",
      "Epoch 56, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2e-18\n",
      "Epoch 57, Error rate: 0.011494252873563218\n",
      "Epoch 58, Error rate: 0.011494252873563218\n",
      "Epoch 59, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000002e-19\n",
      "Epoch 60, Error rate: 0.011494252873563218\n",
      "Epoch 61, Error rate: 0.011494252873563218\n",
      "Epoch 62, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000002e-20\n",
      "Epoch 63, Error rate: 0.011494252873563218\n",
      "Epoch 64, Error rate: 0.011494252873563218\n",
      "Epoch 65, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000002e-21\n",
      "Epoch 66, Error rate: 0.011494252873563218\n",
      "Epoch 67, Error rate: 0.011494252873563218\n",
      "Epoch 68, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2e-22\n",
      "Epoch 69, Error rate: 0.011494252873563218\n",
      "Epoch 70, Error rate: 0.011494252873563218\n",
      "Epoch 71, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000002e-23\n",
      "Epoch 72, Error rate: 0.011494252873563218\n",
      "Epoch 73, Error rate: 0.011494252873563218\n",
      "Epoch 74, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000002e-24\n",
      "Epoch 75, Error rate: 0.011494252873563218\n",
      "Epoch 76, Error rate: 0.011494252873563218\n",
      "Epoch 77, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000003e-25\n",
      "Epoch 78, Error rate: 0.011494252873563218\n",
      "Epoch 79, Error rate: 0.011494252873563218\n",
      "Epoch 80, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000004e-26\n",
      "Epoch 81, Error rate: 0.011494252873563218\n",
      "Epoch 82, Error rate: 0.011494252873563218\n",
      "Epoch 83, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000004e-27\n",
      "Epoch 84, Error rate: 0.011494252873563218\n",
      "Epoch 85, Error rate: 0.011494252873563218\n",
      "Epoch 86, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000004e-28\n",
      "Epoch 87, Error rate: 0.011494252873563218\n",
      "Epoch 88, Error rate: 0.011494252873563218\n",
      "Epoch 89, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000004e-29\n",
      "Epoch 90, Error rate: 0.011494252873563218\n",
      "Epoch 91, Error rate: 0.011494252873563218\n",
      "Epoch 92, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000005e-30\n",
      "Epoch 93, Error rate: 0.011494252873563218\n",
      "Epoch 94, Error rate: 0.011494252873563218\n",
      "Epoch 95, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000006e-31\n",
      "Epoch 96, Error rate: 0.011494252873563218\n",
      "Epoch 97, Error rate: 0.011494252873563218\n",
      "Epoch 98, Error rate: 0.011494252873563218\n",
      "Adjusting learning rate to 2.0000000000000007e-32\n",
      "Epoch 99, Error rate: 0.011494252873563218\n",
      "Epoch 100, Error rate: 0.011494252873563218\n",
      "Reg lambda: 100, Average error rate: 0.06025369978858351\n",
      "Best regularization factor: 100, Best error rate: 0.06025369978858351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate_svm(X_train, y_svm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_svm(X, beta, b):\n",
    "    predictions = np.sign(np.dot(X, beta) + b)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 98.63013698630137 %\n"
     ]
    }
   ],
   "source": [
    "correct_pred = 0\n",
    "\n",
    "for i, X in enumerate(X_test):\n",
    "    pred = predict_svm(X, beta, b)\n",
    "    if y_svm_test[i] == pred:\n",
    "        correct_pred +=1\n",
    "\n",
    "print(f\"Accuracy : {correct_pred * 100 / y_svm_test.shape[0]} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.63013698630137 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\\Uni\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm = LinearSVC()\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100} %\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
